{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "18f03e0a",
   "metadata": {},
   "source": [
    "# IMPORTS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5f98c2c",
   "metadata": {},
   "source": [
    "Por incompatibilidades entre librerias nos vemos obligados a hacer este workaround para que solucionar los problemas de dependencias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e43a3d70",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nicov\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pytorch_forecasting\\models\\base_model.py:30: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    }
   ],
   "source": [
    "import  scipy.signal.signaltools\n",
    "import numpy as np\n",
    "\n",
    "def _centered(arr, newsize):\n",
    "    # Return the center newsize portion of the array.\n",
    "    newsize = np.asarray(newsize)\n",
    "    currsize = np.array(arr.shape)\n",
    "    startind = (currsize - newsize) // 2\n",
    "    endind = startind + newsize\n",
    "    myslice = [slice(startind[k], endind[k]) for k in range(len(endind))]\n",
    "    return arr[tuple(myslice)]\n",
    "\n",
    "scipy.signal.signaltools._centered = _centered\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "# import os\n",
    "# import pickle\n",
    "import pytorch_forecasting\n",
    "from pytorch_forecasting.data import GroupNormalizer\n",
    "from pytorch_forecasting.models.temporal_fusion_transformer.tuning import optimize_hyperparameters\n",
    "from pytorch_forecasting import TemporalFusionTransformer, TimeSeriesDataSet\n",
    "from lightning.pytorch.callbacks import EarlyStopping, LearningRateMonitor\n",
    "import lightning.pytorch as pl\n",
    "from lightning.pytorch.loggers import TensorBoardLogger\n",
    "import torch\n",
    "from pytorch_forecasting.metrics import MAE, SMAPE, PoissonLoss, QuantileLoss, MAPE, MASE\n",
    "from lightning.pytorch.tuner import Tuner\n",
    "from scipy.ndimage import gaussian_filter1d\n",
    "from  scipy.signal.signaltools import _centered\n",
    "from tft_helper import *\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "torch.backends.cudnn.benchmark = True # Enables cuDNN auto-tuner for faster runtime when input sizes are consistent\n",
    "\n",
    "basepath = os.path.abspath(\"\")  # script directory\n",
    "\n",
    "sys.path.insert(1, os.path.join(basepath, \"..\\\\\"))\n",
    "from datetime import datetime, timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "018de99c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install optuna==3.4.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdf5d2e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "82736cf5",
   "metadata": {},
   "source": [
    "# PARAMS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "62f8001a",
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "seq_len = 5 #sequence lenght: how many timesteps does a sequence have. For example a week could be considered a single sequence, therefore seq_len would be 5 as as the stock market opens 5 days a week.\n",
    "pred_len = seq_len * 5 # prediction lenght: How many timesteps does a prediction sequence have. For example if each prediction is a full week pred_len should be 5 as the stock market opens 5 days a week.\n",
    "n_prev_len = 100 # Number of previous timesteps to take for inference. \n",
    "n_preds = 5 # number of predictions with test data\n",
    "test_len = pred_len * n_preds  # Number of timesteps to use for test data.\n",
    "group = \"group\" # If a same model should predict different stores, indices etc specify how to group them. If theres only one time series the set group col to one full of the same value.\n",
    "loss = QuantileLoss() # Loss function. \n",
    "epochs = 75 # Epochs to train the model.\n",
    "\n",
    "# Set ts date range\n",
    "date_start = '2010-01-04' #None #\"2023-06-01\"\n",
    "date_end = \"2024-7-29\"\n",
    "shift = 1 # How many times to shift values. Useful for using last indicator values (RSI, MACD...) for inference\n",
    "ts_indicator_params = {\n",
    "    \"moving_average_windows\": [5, 10, 20, 50, 100, 200], # Moving averages periods\n",
    "    \"sigma_gaussian_filter\": [1,2],\n",
    "    \"n_lags\": 10,\n",
    "                     \n",
    "                     }\n",
    "# cols_to_shift = [2:]\n",
    "\n",
    "# Set training config.\n",
    "lr_finder = False\n",
    "grid_search = \"random\"\n",
    "early_stop_callback = EarlyStopping(monitor=\"val_loss\", min_delta=1e-4, patience=10, verbose=False, mode=\"min\")\n",
    "lr_logger = LearningRateMonitor()  # log the learning rate\n",
    "# logger = TensorBoardLogger(\"lightning_logs\")  # logging results to a tensorboard\n",
    "\n",
    "# TFT training params.\n",
    "tft_params =  {\"gradient_clip_val\": 0.03, \"hidden_size\": 24, \"dropout\": 0.25, \"hidden_continuous_size\": 24, \"attention_head_size\": 4, \"learning_rate\": 0.01, \"loss\": loss, \"early_stop_callback\": early_stop_callback}\n",
    "\n",
    "\n",
    "PIB_relevant_countries = ['USA',\n",
    " 'CHN',\n",
    " 'EMU',\n",
    " 'DEU',\n",
    " 'FRA',\n",
    " 'GBR',\n",
    " 'JPN',\n",
    " 'IND',\n",
    " 'BRA',\n",
    " 'CAN',\n",
    " 'AUS',\n",
    " 'ITA',\n",
    " 'KOR',\n",
    " 'MEX',\n",
    " 'IDN',\n",
    " 'SAU',\n",
    " 'ZAF',\n",
    " 'TUR',\n",
    " 'ESP']\n",
    "\n",
    "# If grid search, set param grid.\n",
    "# param_grid = {\n",
    "#     \"gradient_clip_val\": [0.01, 0.03, 0.05],\n",
    "#     \"hidden_size\": [8, 16, 32],\n",
    "#     \"dropout\": [0.1, 0.25, 0.4],\n",
    "#     \"hidden_continuous_size\": [8, 16, 32],\n",
    "#     \"attention_head_size\": [2, 4, 8],\n",
    "#     \"learning_rate\": [0.005, 0.01, 0.03],\n",
    "#     \"loss\": [loss],\n",
    "#     \"test_len\": [test_len],\n",
    "#     \"pred_len\": [pred_len],\n",
    "#     \"n_prev_len\": [n_prev_len],\n",
    "# }\n",
    "\n",
    "param_grid = {\n",
    "    \"gradient_clip_val\": [0.01, 0.03, 0.05],\n",
    "    \"hidden_size\": [8, 16, 32],\n",
    "    \"dropout\": [0.1, 0.2, 0.3],\n",
    "    \"hidden_continuous_size\": [16, 64, 128],\n",
    "    \"attention_head_size\": [4,8,16],\n",
    "    \"learning_rate\": [0.005, 0.01, 0.03],\n",
    "    \"loss\": [loss],\n",
    "    \"test_len\": [test_len],\n",
    "    \"pred_len\": [pred_len],\n",
    "    \"n_prev_len\": [n_prev_len],\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8032f7e1",
   "metadata": {
    "id": "8032f7e1"
   },
   "source": [
    "# LOAD DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cbf23d4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset does not contain volume data.\n"
     ]
    }
   ],
   "source": [
    "# Load time series data.\n",
    "df_nasdaq = load_file(file_name=\"Nasdaq\", path=\"./data/\", ftype=\"csv\")\n",
    "df_nasdaq = investing_preprocessing(df_nasdaq)\n",
    "df_nasdaq = df_nasdaq.rename(columns={\"target\": \"exog_nasdaq\"})\n",
    "\n",
    "df_ibex35 = load_file(file_name=\"Datos hist√≥ricos del IBEX 35\", path=\"./data/\", ftype=\"csv\")\n",
    "df_ibex35 = investing_preprocessing(df_ibex35)\n",
    "df_ibex35 = df_ibex35.rename(columns={\"target\": \"exog_ibex35\"})\n",
    "\n",
    "df_eustoxx = load_file(file_name=\"EUStoxx50\", path=\"./data/\", ftype=\"csv\")\n",
    "df_eustoxx = investing_preprocessing(df_eustoxx)\n",
    "df_eustoxx = df_eustoxx.rename(columns={\"target\": \"exog_eustoxx\"})\n",
    "\n",
    "df_syp500 = load_file(file_name=\"S&P500\", path=\"./data/\", ftype=\"csv\")\n",
    "df_syp500 = investing_preprocessing(df_syp500)\n",
    "\n",
    "df = add_ts_as_exog(df_syp500, [df_ibex35, df_nasdaq, df_eustoxx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5340bdf5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>target</th>\n",
       "      <th>open</th>\n",
       "      <th>max</th>\n",
       "      <th>min</th>\n",
       "      <th>var</th>\n",
       "      <th>exog_ibex35</th>\n",
       "      <th>exog_nasdaq</th>\n",
       "      <th>exog_eustoxx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2010-01-04</td>\n",
       "      <td>1133.00</td>\n",
       "      <td>1116.60</td>\n",
       "      <td>1133.90</td>\n",
       "      <td>1116.60</td>\n",
       "      <td>1.61</td>\n",
       "      <td>12145.1</td>\n",
       "      <td>1886.70</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2010-01-05</td>\n",
       "      <td>1136.50</td>\n",
       "      <td>1132.70</td>\n",
       "      <td>1136.60</td>\n",
       "      <td>1129.70</td>\n",
       "      <td>0.31</td>\n",
       "      <td>12204.4</td>\n",
       "      <td>1888.43</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2010-01-06</td>\n",
       "      <td>1137.10</td>\n",
       "      <td>1135.70</td>\n",
       "      <td>1139.20</td>\n",
       "      <td>1134.00</td>\n",
       "      <td>0.05</td>\n",
       "      <td>12222.5</td>\n",
       "      <td>1878.42</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2010-01-07</td>\n",
       "      <td>1141.70</td>\n",
       "      <td>1136.30</td>\n",
       "      <td>1142.50</td>\n",
       "      <td>1131.30</td>\n",
       "      <td>0.40</td>\n",
       "      <td>12166.3</td>\n",
       "      <td>1876.72</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2010-01-08</td>\n",
       "      <td>1145.00</td>\n",
       "      <td>1140.50</td>\n",
       "      <td>1145.40</td>\n",
       "      <td>1136.20</td>\n",
       "      <td>0.29</td>\n",
       "      <td>12163.0</td>\n",
       "      <td>1892.59</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3724</th>\n",
       "      <td>2024-10-21</td>\n",
       "      <td>5853.98</td>\n",
       "      <td>5857.82</td>\n",
       "      <td>5866.92</td>\n",
       "      <td>5824.79</td>\n",
       "      <td>-0.18</td>\n",
       "      <td>11841.1</td>\n",
       "      <td>20361.47</td>\n",
       "      <td>4941.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3725</th>\n",
       "      <td>2024-10-22</td>\n",
       "      <td>5851.20</td>\n",
       "      <td>5832.70</td>\n",
       "      <td>5863.04</td>\n",
       "      <td>5821.17</td>\n",
       "      <td>-0.05</td>\n",
       "      <td>11832.7</td>\n",
       "      <td>20383.64</td>\n",
       "      <td>4939.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3726</th>\n",
       "      <td>2024-10-23</td>\n",
       "      <td>5797.42</td>\n",
       "      <td>5834.50</td>\n",
       "      <td>5834.85</td>\n",
       "      <td>5762.41</td>\n",
       "      <td>-0.92</td>\n",
       "      <td>11865.2</td>\n",
       "      <td>20066.96</td>\n",
       "      <td>4922.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3727</th>\n",
       "      <td>2024-10-24</td>\n",
       "      <td>5809.86</td>\n",
       "      <td>5817.80</td>\n",
       "      <td>5817.80</td>\n",
       "      <td>5784.92</td>\n",
       "      <td>0.21</td>\n",
       "      <td>11839.8</td>\n",
       "      <td>20232.87</td>\n",
       "      <td>4935.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3728</th>\n",
       "      <td>2024-10-25</td>\n",
       "      <td>5808.12</td>\n",
       "      <td>5826.75</td>\n",
       "      <td>5862.82</td>\n",
       "      <td>5799.98</td>\n",
       "      <td>-0.03</td>\n",
       "      <td>11812.5</td>\n",
       "      <td>20352.02</td>\n",
       "      <td>4943.09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3729 rows √ó 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Date   target     open      max      min   var  exog_ibex35  \\\n",
       "0    2010-01-04  1133.00  1116.60  1133.90  1116.60  1.61      12145.1   \n",
       "1    2010-01-05  1136.50  1132.70  1136.60  1129.70  0.31      12204.4   \n",
       "2    2010-01-06  1137.10  1135.70  1139.20  1134.00  0.05      12222.5   \n",
       "3    2010-01-07  1141.70  1136.30  1142.50  1131.30  0.40      12166.3   \n",
       "4    2010-01-08  1145.00  1140.50  1145.40  1136.20  0.29      12163.0   \n",
       "...         ...      ...      ...      ...      ...   ...          ...   \n",
       "3724 2024-10-21  5853.98  5857.82  5866.92  5824.79 -0.18      11841.1   \n",
       "3725 2024-10-22  5851.20  5832.70  5863.04  5821.17 -0.05      11832.7   \n",
       "3726 2024-10-23  5797.42  5834.50  5834.85  5762.41 -0.92      11865.2   \n",
       "3727 2024-10-24  5809.86  5817.80  5817.80  5784.92  0.21      11839.8   \n",
       "3728 2024-10-25  5808.12  5826.75  5862.82  5799.98 -0.03      11812.5   \n",
       "\n",
       "      exog_nasdaq  exog_eustoxx  \n",
       "0         1886.70           NaN  \n",
       "1         1888.43           NaN  \n",
       "2         1878.42           NaN  \n",
       "3         1876.72           NaN  \n",
       "4         1892.59           NaN  \n",
       "...           ...           ...  \n",
       "3724     20361.47       4941.22  \n",
       "3725     20383.64       4939.31  \n",
       "3726     20066.96       4922.55  \n",
       "3727     20232.87       4935.45  \n",
       "3728     20352.02       4943.09  \n",
       "\n",
       "[3729 rows x 9 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56b5f849",
   "metadata": {},
   "source": [
    "## ADD INDICATORS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1fec0805",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nicov\\Documents\\Github\\QuantTrader-TFT\\tft_helper.py:1058: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df = df.ffill()\n"
     ]
    }
   ],
   "source": [
    "df = add_global_indicators(df, PIB_relevant_countries, date_start, date_end)\n",
    "df = add_indicators(df, ts_indicator_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8103608c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>target</th>\n",
       "      <th>open</th>\n",
       "      <th>max</th>\n",
       "      <th>min</th>\n",
       "      <th>var</th>\n",
       "      <th>exog_ibex35</th>\n",
       "      <th>exog_nasdaq</th>\n",
       "      <th>exog_eustoxx</th>\n",
       "      <th>AAII_Bullish</th>\n",
       "      <th>...</th>\n",
       "      <th>bullish_rsi</th>\n",
       "      <th>bearish_rsi</th>\n",
       "      <th>bullish_bollinger</th>\n",
       "      <th>bearish_bollinger</th>\n",
       "      <th>bullish_macd</th>\n",
       "      <th>bearish_macd</th>\n",
       "      <th>bullish_atr</th>\n",
       "      <th>bearish_atr</th>\n",
       "      <th>bullish_trend</th>\n",
       "      <th>bearish_trend</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2010-01-04</td>\n",
       "      <td>1133.00</td>\n",
       "      <td>1116.60</td>\n",
       "      <td>1133.90</td>\n",
       "      <td>1116.60</td>\n",
       "      <td>1.61</td>\n",
       "      <td>12145.1</td>\n",
       "      <td>1886.70</td>\n",
       "      <td>2324.48</td>\n",
       "      <td>0.410000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2010-01-05</td>\n",
       "      <td>1136.50</td>\n",
       "      <td>1132.70</td>\n",
       "      <td>1136.60</td>\n",
       "      <td>1129.70</td>\n",
       "      <td>0.31</td>\n",
       "      <td>12204.4</td>\n",
       "      <td>1888.43</td>\n",
       "      <td>2324.48</td>\n",
       "      <td>0.410000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2010-01-06</td>\n",
       "      <td>1137.10</td>\n",
       "      <td>1135.70</td>\n",
       "      <td>1139.20</td>\n",
       "      <td>1134.00</td>\n",
       "      <td>0.05</td>\n",
       "      <td>12222.5</td>\n",
       "      <td>1878.42</td>\n",
       "      <td>2324.48</td>\n",
       "      <td>0.410000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2010-01-07</td>\n",
       "      <td>1141.70</td>\n",
       "      <td>1136.30</td>\n",
       "      <td>1142.50</td>\n",
       "      <td>1131.30</td>\n",
       "      <td>0.40</td>\n",
       "      <td>12166.3</td>\n",
       "      <td>1876.72</td>\n",
       "      <td>2324.48</td>\n",
       "      <td>0.410000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2010-01-08</td>\n",
       "      <td>1145.00</td>\n",
       "      <td>1140.50</td>\n",
       "      <td>1145.40</td>\n",
       "      <td>1136.20</td>\n",
       "      <td>0.29</td>\n",
       "      <td>12163.0</td>\n",
       "      <td>1892.59</td>\n",
       "      <td>2324.48</td>\n",
       "      <td>0.410000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3661</th>\n",
       "      <td>2024-07-23</td>\n",
       "      <td>5555.74</td>\n",
       "      <td>5565.30</td>\n",
       "      <td>5585.34</td>\n",
       "      <td>5550.90</td>\n",
       "      <td>-0.16</td>\n",
       "      <td>11212.7</td>\n",
       "      <td>19754.34</td>\n",
       "      <td>4916.80</td>\n",
       "      <td>0.527473</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3662</th>\n",
       "      <td>2024-07-24</td>\n",
       "      <td>5427.13</td>\n",
       "      <td>5505.84</td>\n",
       "      <td>5508.04</td>\n",
       "      <td>5419.98</td>\n",
       "      <td>-2.31</td>\n",
       "      <td>11210.1</td>\n",
       "      <td>19032.39</td>\n",
       "      <td>4861.87</td>\n",
       "      <td>0.527473</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3663</th>\n",
       "      <td>2024-07-25</td>\n",
       "      <td>5399.22</td>\n",
       "      <td>5428.70</td>\n",
       "      <td>5491.59</td>\n",
       "      <td>5390.95</td>\n",
       "      <td>-0.51</td>\n",
       "      <td>11145.6</td>\n",
       "      <td>18830.59</td>\n",
       "      <td>4811.28</td>\n",
       "      <td>0.431734</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3664</th>\n",
       "      <td>2024-07-26</td>\n",
       "      <td>5459.10</td>\n",
       "      <td>5433.67</td>\n",
       "      <td>5488.32</td>\n",
       "      <td>5430.70</td>\n",
       "      <td>1.11</td>\n",
       "      <td>11165.9</td>\n",
       "      <td>19023.66</td>\n",
       "      <td>4862.50</td>\n",
       "      <td>0.431734</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3665</th>\n",
       "      <td>2024-07-29</td>\n",
       "      <td>5463.54</td>\n",
       "      <td>5476.55</td>\n",
       "      <td>5487.74</td>\n",
       "      <td>5444.44</td>\n",
       "      <td>0.08</td>\n",
       "      <td>11117.8</td>\n",
       "      <td>19059.49</td>\n",
       "      <td>4815.39</td>\n",
       "      <td>0.431734</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3666 rows √ó 84 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Date   target     open      max      min   var  exog_ibex35  \\\n",
       "0    2010-01-04  1133.00  1116.60  1133.90  1116.60  1.61      12145.1   \n",
       "1    2010-01-05  1136.50  1132.70  1136.60  1129.70  0.31      12204.4   \n",
       "2    2010-01-06  1137.10  1135.70  1139.20  1134.00  0.05      12222.5   \n",
       "3    2010-01-07  1141.70  1136.30  1142.50  1131.30  0.40      12166.3   \n",
       "4    2010-01-08  1145.00  1140.50  1145.40  1136.20  0.29      12163.0   \n",
       "...         ...      ...      ...      ...      ...   ...          ...   \n",
       "3661 2024-07-23  5555.74  5565.30  5585.34  5550.90 -0.16      11212.7   \n",
       "3662 2024-07-24  5427.13  5505.84  5508.04  5419.98 -2.31      11210.1   \n",
       "3663 2024-07-25  5399.22  5428.70  5491.59  5390.95 -0.51      11145.6   \n",
       "3664 2024-07-26  5459.10  5433.67  5488.32  5430.70  1.11      11165.9   \n",
       "3665 2024-07-29  5463.54  5476.55  5487.74  5444.44  0.08      11117.8   \n",
       "\n",
       "      exog_nasdaq  exog_eustoxx  AAII_Bullish  ...  bullish_rsi  bearish_rsi  \\\n",
       "0         1886.70       2324.48      0.410000  ...            0            0   \n",
       "1         1888.43       2324.48      0.410000  ...            0            0   \n",
       "2         1878.42       2324.48      0.410000  ...            0            0   \n",
       "3         1876.72       2324.48      0.410000  ...            0            0   \n",
       "4         1892.59       2324.48      0.410000  ...            0            0   \n",
       "...           ...           ...           ...  ...          ...          ...   \n",
       "3661     19754.34       4916.80      0.527473  ...            0            0   \n",
       "3662     19032.39       4861.87      0.527473  ...            0            0   \n",
       "3663     18830.59       4811.28      0.431734  ...            0            0   \n",
       "3664     19023.66       4862.50      0.431734  ...            0            0   \n",
       "3665     19059.49       4815.39      0.431734  ...            0            0   \n",
       "\n",
       "      bullish_bollinger bearish_bollinger  bullish_macd  bearish_macd  \\\n",
       "0                     0                 0             0             0   \n",
       "1                     0                 0             1             0   \n",
       "2                     0                 0             1             0   \n",
       "3                     0                 0             1             0   \n",
       "4                     0                 0             1             0   \n",
       "...                 ...               ...           ...           ...   \n",
       "3661                  0                 0             0             1   \n",
       "3662                  0                 0             0             1   \n",
       "3663                  1                 0             0             1   \n",
       "3664                  0                 0             0             1   \n",
       "3665                  0                 0             0             1   \n",
       "\n",
       "      bullish_atr  bearish_atr  bullish_trend  bearish_trend  \n",
       "0               0            0              0              0  \n",
       "1               0            0              0              0  \n",
       "2               0            0              0              0  \n",
       "3               0            0              0              0  \n",
       "4               0            0              0              0  \n",
       "...           ...          ...            ...            ...  \n",
       "3661            1            0              0              0  \n",
       "3662            1            0              0              0  \n",
       "3663            1            0              1              0  \n",
       "3664            1            0              0              0  \n",
       "3665            1            0              0              0  \n",
       "\n",
       "[3666 rows x 84 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f2bef641",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SHift indicator values\n",
    "cols_to_shift = [col for col in df.columns[3:] if not (col.startswith('AAII') or col.startswith('PIB'))]\n",
    "df[cols_to_shift] = df[cols_to_shift].shift(shift)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "179a60de",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df.copy()\n",
    "data[\"group\"] = 1\n",
    "\n",
    "# Supongamos que tu DataFrame se llama 'data' y que la columna 'Date' tiene las fechas\n",
    "# Crear una lista de d√≠as festivos (ejemplo, agrega tus d√≠as festivos)\n",
    "dias_festivos = pd.to_datetime([\"2024-01-01\", \"2024-12-25\", ])  # A√±ade m√°s d√≠as festivos\n",
    "\n",
    "# Meses del a√±o (convertir a nombres de meses)\n",
    "data[\"month\"] = data[\"Date\"].dt.strftime('%B')  # Ejemplo: \"January\", \"February\", etc.\n",
    "\n",
    "# D√≠as del a√±o (de 1 a 365 o 366 en a√±os bisiestos), convertir en cadena\n",
    "data[\"day_of_year\"] = data[\"Date\"].dt.dayofyear.astype(str)  # Convertir el n√∫mero de d√≠a a cadena\n",
    "\n",
    "# D√≠as de la semana (de lunes a viernes: 0 = lunes, 4 = viernes), convertir a nombre de d√≠a\n",
    "data[\"weekday\"] = data[\"Date\"].dt.strftime('%A')  # Ejemplo: \"Monday\", \"Tuesday\", etc.\n",
    "\n",
    "# Filtrar para eliminar s√°bados y domingos\n",
    "data = data[data[\"weekday\"].isin([\"Monday\", \"Tuesday\", \"Wednesday\", \"Thursday\", \"Friday\"])]\n",
    "\n",
    "# Identificar si el d√≠a es festivo (usar \"Yes\" o \"No\" en lugar de 1 o 0)\n",
    "data[\"is_holiday\"] = data[\"Date\"].isin(dias_festivos).map({True: \"Yes\", False: \"No\"})\n",
    "\n",
    "data[\"time_idx\"] = data.index\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0651f8e",
   "metadata": {},
   "source": [
    " VARIABLES GROUPING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aa586286",
   "metadata": {},
   "outputs": [],
   "source": [
    "rest=['Date', 'target',\n",
    "'FEDFUNDS', 'open', 'max', 'min', 'var',\n",
    "'MACD', 'Signal_Line',\n",
    "'group', 'month', 'day_of_year', 'weekday','is_holiday', 'time_idx']\n",
    "PIB_cols = [col for col in df.columns if col.startswith('PIB')]\n",
    "AAII_cols = [col for col in df.columns if col.startswith('AAII')]\n",
    "VIX_cols = [col for col in df.columns if col.endswith('VIX')]\n",
    "SMA_cols = [col for col in df.columns if col.startswith('SMA')]\n",
    "EMA_cols = [col for col in df.columns if col.startswith('EMA')]\n",
    "lag_cols = [col for col in df.columns if col.startswith('target_lag')]\n",
    "target_smoothed_cols = [col for col in df.columns if col.startswith('target_smoothed')]\n",
    "RSI_cols = [col for col in df.columns if col.startswith('RSI')]\n",
    "Bollinger_cols = [col for col in df.columns if col.startswith('Bollinger')]\n",
    "ATR_cols = [col for col in df.columns if col.startswith('ATR')]\n",
    "CCI_cols = [col for col in df.columns if col.startswith('CCI')]\n",
    "ROC_cols = [col for col in df.columns if col.startswith('ROC')]\n",
    "Williams_cols = [col for col in df.columns if col.startswith('Williams')]\n",
    "Stochastic_cols = [col for col in df.columns if col.startswith('Stochastic')]\n",
    "bullish_cols = [col for col in df.columns if col.startswith('bullish')]\n",
    "bearish_cols = [col for col in df.columns if col.startswith('bearish')]\n",
    "exog_ts = [col for col in df.columns if col.startswith('exog')]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fa86e03",
   "metadata": {},
   "source": [
    "## TRAIN - TEST SPLIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c2fd2fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "full = data.copy()\n",
    "cols_to_convert = [\"target\", \"open\", \"max\", \"min\", \"var\", \"MACD\", \"Signal_Line\"] + SMA_cols + EMA_cols + Bollinger_cols + ATR_cols + CCI_cols + ROC_cols + Williams_cols + Stochastic_cols + exog_ts + VIX_cols + lag_cols + target_smoothed_cols + RSI_cols\n",
    "full[cols_to_convert] = full[cols_to_convert].apply(pd.to_numeric, errors='coerce')\n",
    "full = full.ffill().bfill()\n",
    "\n",
    "data = full[:-test_len]\n",
    "test = full[-test_len:]\n",
    "data = data.reset_index(drop=True)\n",
    "data = data.dropna()\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(data[\"Date\"], data[\"target\"], color=\"blue\", label=\"Train\")\n",
    "plt.plot(test[\"Date\"], test[\"target\"], color=\"green\", label=\"Test\")\n",
    "\n",
    "plt.xlabel(\"Fecha y Hora\")\n",
    "plt.ylabel(\"Precio Spot\")\n",
    "plt.title(\"Precio Spot en funci√≥n de Fecha y Hora\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "740262e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>target</th>\n",
       "      <th>open</th>\n",
       "      <th>max</th>\n",
       "      <th>min</th>\n",
       "      <th>var</th>\n",
       "      <th>exog_ibex35</th>\n",
       "      <th>exog_nasdaq</th>\n",
       "      <th>exog_eustoxx</th>\n",
       "      <th>AAII_Bullish</th>\n",
       "      <th>...</th>\n",
       "      <th>bullish_atr</th>\n",
       "      <th>bearish_atr</th>\n",
       "      <th>bullish_trend</th>\n",
       "      <th>bearish_trend</th>\n",
       "      <th>group</th>\n",
       "      <th>month</th>\n",
       "      <th>day_of_year</th>\n",
       "      <th>weekday</th>\n",
       "      <th>is_holiday</th>\n",
       "      <th>time_idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2010-01-04</td>\n",
       "      <td>1133.00</td>\n",
       "      <td>1116.60</td>\n",
       "      <td>1133.90</td>\n",
       "      <td>1116.60</td>\n",
       "      <td>1.61</td>\n",
       "      <td>12145.1</td>\n",
       "      <td>1886.70</td>\n",
       "      <td>2324.48</td>\n",
       "      <td>0.410000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>January</td>\n",
       "      <td>4</td>\n",
       "      <td>Monday</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2010-01-05</td>\n",
       "      <td>1136.50</td>\n",
       "      <td>1132.70</td>\n",
       "      <td>1133.90</td>\n",
       "      <td>1116.60</td>\n",
       "      <td>1.61</td>\n",
       "      <td>12145.1</td>\n",
       "      <td>1886.70</td>\n",
       "      <td>2324.48</td>\n",
       "      <td>0.410000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>January</td>\n",
       "      <td>5</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>No</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2010-01-06</td>\n",
       "      <td>1137.10</td>\n",
       "      <td>1135.70</td>\n",
       "      <td>1136.60</td>\n",
       "      <td>1129.70</td>\n",
       "      <td>0.31</td>\n",
       "      <td>12204.4</td>\n",
       "      <td>1888.43</td>\n",
       "      <td>2324.48</td>\n",
       "      <td>0.410000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>January</td>\n",
       "      <td>6</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>No</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2010-01-07</td>\n",
       "      <td>1141.70</td>\n",
       "      <td>1136.30</td>\n",
       "      <td>1139.20</td>\n",
       "      <td>1134.00</td>\n",
       "      <td>0.05</td>\n",
       "      <td>12222.5</td>\n",
       "      <td>1878.42</td>\n",
       "      <td>2324.48</td>\n",
       "      <td>0.410000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>January</td>\n",
       "      <td>7</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>No</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2010-01-08</td>\n",
       "      <td>1145.00</td>\n",
       "      <td>1140.50</td>\n",
       "      <td>1142.50</td>\n",
       "      <td>1131.30</td>\n",
       "      <td>0.40</td>\n",
       "      <td>12166.3</td>\n",
       "      <td>1876.72</td>\n",
       "      <td>2324.48</td>\n",
       "      <td>0.410000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>January</td>\n",
       "      <td>8</td>\n",
       "      <td>Friday</td>\n",
       "      <td>No</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3411</th>\n",
       "      <td>2023-07-25</td>\n",
       "      <td>4567.46</td>\n",
       "      <td>4555.19</td>\n",
       "      <td>4563.41</td>\n",
       "      <td>4541.29</td>\n",
       "      <td>0.40</td>\n",
       "      <td>9543.5</td>\n",
       "      <td>15448.02</td>\n",
       "      <td>4383.03</td>\n",
       "      <td>0.513575</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>July</td>\n",
       "      <td>206</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>No</td>\n",
       "      <td>3411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3412</th>\n",
       "      <td>2023-07-26</td>\n",
       "      <td>4566.75</td>\n",
       "      <td>4558.96</td>\n",
       "      <td>4580.62</td>\n",
       "      <td>4552.42</td>\n",
       "      <td>0.28</td>\n",
       "      <td>9519.2</td>\n",
       "      <td>15561.42</td>\n",
       "      <td>4391.30</td>\n",
       "      <td>0.513575</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>July</td>\n",
       "      <td>207</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>No</td>\n",
       "      <td>3412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3413</th>\n",
       "      <td>2023-07-27</td>\n",
       "      <td>4537.41</td>\n",
       "      <td>4598.26</td>\n",
       "      <td>4582.47</td>\n",
       "      <td>4547.58</td>\n",
       "      <td>-0.02</td>\n",
       "      <td>9600.5</td>\n",
       "      <td>15499.26</td>\n",
       "      <td>4346.15</td>\n",
       "      <td>0.449064</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>July</td>\n",
       "      <td>208</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>No</td>\n",
       "      <td>3413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3414</th>\n",
       "      <td>2023-07-28</td>\n",
       "      <td>4582.23</td>\n",
       "      <td>4565.75</td>\n",
       "      <td>4607.07</td>\n",
       "      <td>4528.56</td>\n",
       "      <td>-0.64</td>\n",
       "      <td>9694.7</td>\n",
       "      <td>15464.93</td>\n",
       "      <td>4447.44</td>\n",
       "      <td>0.449064</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>July</td>\n",
       "      <td>209</td>\n",
       "      <td>Friday</td>\n",
       "      <td>No</td>\n",
       "      <td>3414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3415</th>\n",
       "      <td>2023-07-31</td>\n",
       "      <td>4588.96</td>\n",
       "      <td>4584.82</td>\n",
       "      <td>4590.16</td>\n",
       "      <td>4564.01</td>\n",
       "      <td>0.99</td>\n",
       "      <td>9685.1</td>\n",
       "      <td>15750.93</td>\n",
       "      <td>4466.50</td>\n",
       "      <td>0.449064</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>July</td>\n",
       "      <td>212</td>\n",
       "      <td>Monday</td>\n",
       "      <td>No</td>\n",
       "      <td>3415</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3416 rows √ó 90 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Date   target     open      max      min   var  exog_ibex35  \\\n",
       "0    2010-01-04  1133.00  1116.60  1133.90  1116.60  1.61      12145.1   \n",
       "1    2010-01-05  1136.50  1132.70  1133.90  1116.60  1.61      12145.1   \n",
       "2    2010-01-06  1137.10  1135.70  1136.60  1129.70  0.31      12204.4   \n",
       "3    2010-01-07  1141.70  1136.30  1139.20  1134.00  0.05      12222.5   \n",
       "4    2010-01-08  1145.00  1140.50  1142.50  1131.30  0.40      12166.3   \n",
       "...         ...      ...      ...      ...      ...   ...          ...   \n",
       "3411 2023-07-25  4567.46  4555.19  4563.41  4541.29  0.40       9543.5   \n",
       "3412 2023-07-26  4566.75  4558.96  4580.62  4552.42  0.28       9519.2   \n",
       "3413 2023-07-27  4537.41  4598.26  4582.47  4547.58 -0.02       9600.5   \n",
       "3414 2023-07-28  4582.23  4565.75  4607.07  4528.56 -0.64       9694.7   \n",
       "3415 2023-07-31  4588.96  4584.82  4590.16  4564.01  0.99       9685.1   \n",
       "\n",
       "      exog_nasdaq  exog_eustoxx  AAII_Bullish  ...  bullish_atr  bearish_atr  \\\n",
       "0         1886.70       2324.48      0.410000  ...            0            0   \n",
       "1         1886.70       2324.48      0.410000  ...            0            0   \n",
       "2         1888.43       2324.48      0.410000  ...            0            0   \n",
       "3         1878.42       2324.48      0.410000  ...            0            0   \n",
       "4         1876.72       2324.48      0.410000  ...            0            0   \n",
       "...           ...           ...           ...  ...          ...          ...   \n",
       "3411     15448.02       4383.03      0.513575  ...            0            1   \n",
       "3412     15561.42       4391.30      0.513575  ...            0            1   \n",
       "3413     15499.26       4346.15      0.449064  ...            0            1   \n",
       "3414     15464.93       4447.44      0.449064  ...            0            1   \n",
       "3415     15750.93       4466.50      0.449064  ...            1            0   \n",
       "\n",
       "      bullish_trend  bearish_trend  group    month  day_of_year    weekday  \\\n",
       "0                 0              0      1  January            4     Monday   \n",
       "1                 0              0      1  January            5    Tuesday   \n",
       "2                 0              0      1  January            6  Wednesday   \n",
       "3                 0              0      1  January            7   Thursday   \n",
       "4                 0              0      1  January            8     Friday   \n",
       "...             ...            ...    ...      ...          ...        ...   \n",
       "3411              0              0      1     July          206    Tuesday   \n",
       "3412              0              0      1     July          207  Wednesday   \n",
       "3413              0              0      1     July          208   Thursday   \n",
       "3414              0              1      1     July          209     Friday   \n",
       "3415              0              0      1     July          212     Monday   \n",
       "\n",
       "      is_holiday  time_idx  \n",
       "0             No         0  \n",
       "1             No         1  \n",
       "2             No         2  \n",
       "3             No         3  \n",
       "4             No         4  \n",
       "...          ...       ...  \n",
       "3411          No      3411  \n",
       "3412          No      3412  \n",
       "3413          No      3413  \n",
       "3414          No      3414  \n",
       "3415          No      3415  \n",
       "\n",
       "[3416 rows x 90 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45a04371",
   "metadata": {},
   "source": [
    "<!-- ## DF FINL -->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da4fc650",
   "metadata": {},
   "source": [
    "## TimeSeriesDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "afdbea69",
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "max_prediction_length = pred_len\n",
    "max_encoder_length = n_prev_len \n",
    "# Ajusta training_cutoff para reservar un rango m√°s amplio para la validaci√≥n\n",
    "# validation_size = 50  # ajusta seg√∫n el tama√±o deseado para el conjunto de validaci√≥n\n",
    "training_cutoff = data[\"time_idx\"].max() - max_prediction_length #- validation_size\n",
    "\n",
    "train = TimeSeriesDataSet(\n",
    "    data[lambda x: x.time_idx <= training_cutoff],\n",
    "    time_idx=\"time_idx\",\n",
    "    target=\"target\",\n",
    "    group_ids=[group],\n",
    "    min_encoder_length=max_encoder_length,  # keep encoder length long (as it is in the validation set)\n",
    "    max_encoder_length=max_encoder_length,\n",
    "    # min_prediction_length=24,\n",
    "    max_prediction_length=max_prediction_length,\n",
    "    static_categoricals=[],\n",
    "    static_reals=[],\n",
    "    time_varying_known_categoricals=[\"month\", \"weekday\", \"day_of_year\", \"is_holiday\"],  # group of categorical variables can be treated as one variable\n",
    "    time_varying_known_reals=[\"Date\", \"time_idx\", 'FEDFUNDS'] + AAII_cols + PIB_cols,\n",
    "                                        \n",
    "    time_varying_unknown_categoricals=  bullish_cols +  bearish_cols,\n",
    "    time_varying_unknown_reals=[\n",
    "        \"target\",\n",
    "        \"open\",\n",
    "        \"max\",\n",
    "        \"min\",\n",
    "        # \"vol\",\n",
    "        \"var\",\n",
    "        \"MACD\",\n",
    "        \"Signal_Line\",\n",
    "    ]     + \n",
    "    lag_cols + \n",
    "    SMA_cols +\n",
    "    EMA_cols +\n",
    "    RSI_cols +\n",
    "    Bollinger_cols +\n",
    "    ATR_cols +\n",
    "    CCI_cols +\n",
    "    ROC_cols +\n",
    "    Stochastic_cols +\n",
    "    Williams_cols +\n",
    "    VIX_cols +\n",
    "    exog_ts +\n",
    "    target_smoothed_cols\n",
    "    ,\n",
    "    # lags={\"target\": list(range(1, 5))},\n",
    "    # target_normalizer=GroupNormalizer(\"standard\", groups=[group], transformation=\"softplus\"),\n",
    "    # use softplus and normalize by group\n",
    "    add_relative_time_idx=True,\n",
    "    add_target_scales=True,\n",
    "    allow_missing_timesteps=True,\n",
    "    # add_encoder_length=True,\n",
    "    categorical_encoders={\n",
    "        \"month\": pytorch_forecasting.data.encoders.NaNLabelEncoder(add_nan=True),\n",
    "        \"weekday\": pytorch_forecasting.data.encoders.NaNLabelEncoder(add_nan=True),\n",
    "        \"day_of_year\": pytorch_forecasting.data.encoders.NaNLabelEncoder(add_nan=True),\n",
    "    },\n",
    ")\n",
    "\n",
    "validation = TimeSeriesDataSet.from_dataset(train,  data, predict=True, stop_randomization=True)\n",
    "# test = TimeSeriesDataSet.from_dataset(training, test_data, predict=True, stop_randomization=True)\n",
    "\n",
    "# create dataloaders for model\n",
    "batch_size = 32  # set this between 32 to 128\n",
    "train_dataloader = train.to_dataloader(\n",
    "    train=True, batch_size=batch_size, num_workers=7, persistent_workers=True\n",
    ")\n",
    "val_dataloader = validation.to_dataloader(\n",
    "    train=False, batch_size=batch_size, num_workers=7, persistent_workers=True\n",
    ")\n",
    "# test_dataloader = test.to_dataloader(train=False, batch_size=batch_size, num_workers=11, persistent_workers=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9b716d2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25\n"
     ]
    }
   ],
   "source": [
    "validation_data = data[lambda x: x.time_idx > training_cutoff]\n",
    "print(len(validation_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1db5ef6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TimeSeriesDataSet[length=1](\n",
       "\ttime_idx='time_idx',\n",
       "\ttarget='target',\n",
       "\tgroup_ids=['group'],\n",
       "\tweight=None,\n",
       "\tmax_encoder_length=100,\n",
       "\tmin_encoder_length=100,\n",
       "\tmin_prediction_idx=0,\n",
       "\tmin_prediction_length=25,\n",
       "\tmax_prediction_length=25,\n",
       "\tstatic_categoricals=[],\n",
       "\tstatic_reals=['target_center', 'target_scale'],\n",
       "\ttime_varying_known_categoricals=['month', 'weekday', 'day_of_year', 'is_holiday'],\n",
       "\ttime_varying_known_reals=['Date', 'time_idx', 'FEDFUNDS', 'AAII_Bullish', 'AAII_Neutral', 'AAII_Bearish', 'PIB_USA', 'PIB_CHN', 'PIB_EMU', 'PIB_DEU', 'PIB_FRA', 'PIB_GBR', 'PIB_JPN', 'PIB_IND', 'PIB_BRA', 'PIB_CAN', 'PIB_AUS', 'PIB_ITA', 'PIB_KOR', 'PIB_MEX', 'PIB_IDN', 'PIB_SAU', 'PIB_ZAF', 'PIB_TUR', 'PIB_ESP', 'relative_time_idx'],\n",
       "\ttime_varying_unknown_categoricals=['bullish_sma_50_200', 'bullish_rsi', 'bullish_bollinger', 'bullish_macd', 'bullish_atr', 'bullish_trend', 'bearish_sma_50_200', 'bearish_rsi', 'bearish_bollinger', 'bearish_macd', 'bearish_atr', 'bearish_trend'],\n",
       "\ttime_varying_unknown_reals=['target', 'open', 'max', 'min', 'var', 'MACD', 'Signal_Line', 'target_lag1', 'target_lag2', 'target_lag3', 'target_lag4', 'target_lag5', 'target_lag6', 'target_lag7', 'target_lag8', 'target_lag9', 'target_lag10', 'SMA_5', 'SMA_10', 'SMA_20', 'SMA_50', 'SMA_100', 'SMA_200', 'EMA_5', 'EMA_10', 'EMA_20', 'EMA_50', 'EMA_100', 'EMA_200', 'RSI_14', 'Bollinger_Upper_20', 'Bollinger_Lower_20', 'ATR_14', 'CCI_10', 'CCI_20', 'ROC_10', 'ROC_14', 'ROC_20', 'Stochastic_14_K', 'Stochastic_14_D', 'Williams_%R_14', 'VIX', 'EUVIX', 'exog_ibex35', 'exog_nasdaq', 'exog_eustoxx', 'target_smoothed_1', 'target_smoothed_2'],\n",
       "\tvariable_groups={},\n",
       "\tconstant_fill_strategy={},\n",
       "\tallow_missing_timesteps=True,\n",
       "\tlags={},\n",
       "\tadd_relative_time_idx=True,\n",
       "\tadd_target_scales=True,\n",
       "\tadd_encoder_length=False,\n",
       "\ttarget_normalizer=EncoderNormalizer(\n",
       "\tmethod='standard',\n",
       "\tcenter=True,\n",
       "\tmax_length=None,\n",
       "\ttransformation='relu',\n",
       "\tmethod_kwargs={}\n",
       "),\n",
       "\tcategorical_encoders={'month': NaNLabelEncoder(add_nan=True, warn=True), 'weekday': NaNLabelEncoder(add_nan=True, warn=True), 'day_of_year': NaNLabelEncoder(add_nan=True, warn=True), '__group_id__group': NaNLabelEncoder(add_nan=False, warn=True), 'is_holiday': NaNLabelEncoder(add_nan=False, warn=True), 'bullish_sma_50_200': NaNLabelEncoder(add_nan=False, warn=True), 'bullish_rsi': NaNLabelEncoder(add_nan=False, warn=True), 'bullish_bollinger': NaNLabelEncoder(add_nan=False, warn=True), 'bullish_macd': NaNLabelEncoder(add_nan=False, warn=True), 'bullish_atr': NaNLabelEncoder(add_nan=False, warn=True), 'bullish_trend': NaNLabelEncoder(add_nan=False, warn=True), 'bearish_sma_50_200': NaNLabelEncoder(add_nan=False, warn=True), 'bearish_rsi': NaNLabelEncoder(add_nan=False, warn=True), 'bearish_bollinger': NaNLabelEncoder(add_nan=False, warn=True), 'bearish_macd': NaNLabelEncoder(add_nan=False, warn=True), 'bearish_atr': NaNLabelEncoder(add_nan=False, warn=True), 'bearish_trend': NaNLabelEncoder(add_nan=False, warn=True)},\n",
       "\tscalers={'target_center': StandardScaler(), 'target_scale': StandardScaler(), 'Date': StandardScaler(), 'time_idx': StandardScaler(), 'FEDFUNDS': StandardScaler(), 'AAII_Bullish': StandardScaler(), 'AAII_Neutral': StandardScaler(), 'AAII_Bearish': StandardScaler(), 'PIB_USA': StandardScaler(), 'PIB_CHN': StandardScaler(), 'PIB_EMU': StandardScaler(), 'PIB_DEU': StandardScaler(), 'PIB_FRA': StandardScaler(), 'PIB_GBR': StandardScaler(), 'PIB_JPN': StandardScaler(), 'PIB_IND': StandardScaler(), 'PIB_BRA': StandardScaler(), 'PIB_CAN': StandardScaler(), 'PIB_AUS': StandardScaler(), 'PIB_ITA': StandardScaler(), 'PIB_KOR': StandardScaler(), 'PIB_MEX': StandardScaler(), 'PIB_IDN': StandardScaler(), 'PIB_SAU': StandardScaler(), 'PIB_ZAF': StandardScaler(), 'PIB_TUR': StandardScaler(), 'PIB_ESP': StandardScaler(), 'relative_time_idx': StandardScaler(), 'open': StandardScaler(), 'max': StandardScaler(), 'min': StandardScaler(), 'var': StandardScaler(), 'MACD': StandardScaler(), 'Signal_Line': StandardScaler(), 'target_lag1': StandardScaler(), 'target_lag2': StandardScaler(), 'target_lag3': StandardScaler(), 'target_lag4': StandardScaler(), 'target_lag5': StandardScaler(), 'target_lag6': StandardScaler(), 'target_lag7': StandardScaler(), 'target_lag8': StandardScaler(), 'target_lag9': StandardScaler(), 'target_lag10': StandardScaler(), 'SMA_5': StandardScaler(), 'SMA_10': StandardScaler(), 'SMA_20': StandardScaler(), 'SMA_50': StandardScaler(), 'SMA_100': StandardScaler(), 'SMA_200': StandardScaler(), 'EMA_5': StandardScaler(), 'EMA_10': StandardScaler(), 'EMA_20': StandardScaler(), 'EMA_50': StandardScaler(), 'EMA_100': StandardScaler(), 'EMA_200': StandardScaler(), 'RSI_14': StandardScaler(), 'Bollinger_Upper_20': StandardScaler(), 'Bollinger_Lower_20': StandardScaler(), 'ATR_14': StandardScaler(), 'CCI_10': StandardScaler(), 'CCI_20': StandardScaler(), 'ROC_10': StandardScaler(), 'ROC_14': StandardScaler(), 'ROC_20': StandardScaler(), 'Stochastic_14_K': StandardScaler(), 'Stochastic_14_D': StandardScaler(), 'Williams_%R_14': StandardScaler(), 'VIX': StandardScaler(), 'EUVIX': StandardScaler(), 'exog_ibex35': StandardScaler(), 'exog_nasdaq': StandardScaler(), 'exog_eustoxx': StandardScaler(), 'target_smoothed_1': StandardScaler(), 'target_smoothed_2': StandardScaler()},\n",
       "\trandomize_length=None,\n",
       "\tpredict_mode=True\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c2a24e8",
   "metadata": {},
   "source": [
    "\n",
    "# LEARNIG RATE FINDER"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44fa807d",
   "metadata": {},
   "source": [
    "En primer lugar realizamos un estudio para hallar de forma aproximada el valor optimo de tasa de aprendizaje.  No es recomendable al 100% usar el valor sugerido directamente pues a veces no encuentra el mejor, sin embargo si que da un muy buen punto de partida por donde empezar a probar. Para ello usamos un modelo TFT cualquiera basico."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "54055c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if lr_finder:\n",
    "    res = get_best_lr(train, train_dataloader, val_dataloader, **tft_params)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "008a1fdd",
   "metadata": {},
   "source": [
    "# MODELLING"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "927621bc",
   "metadata": {},
   "source": [
    "## TRAIN MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "152ce290",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not grid_search:\n",
    "    # tft_params[\"learning_rate\"] = 0.01\n",
    "    tft, val_loss = tft_trainer(train, train_dataloader, val_dataloader, max_epochs=epochs, **tft_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f0f0114",
   "metadata": {},
   "source": [
    "### EVAL MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ba6ae28f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not grid_search:\n",
    "    preds = tft_predict(tft, val_dataloader)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54f4ad1d",
   "metadata": {},
   "source": [
    "## GRID SEARCH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "45763d2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " -------------------------------------------------------- \n",
      " Probando combinaci√≥n aleatoria 1/100: {'gradient_clip_val': 0.01, 'hidden_size': 32, 'dropout': 0.2, 'hidden_continuous_size': 16, 'attention_head_size': 4, 'learning_rate': 0.03, 'loss': QuantileLoss(quantiles=[0.02, 0.1, 0.25, 0.5, 0.75, 0.9, 0.98]), 'test_len': 125, 'pred_len': 25, 'n_prev_len': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "Detected KeyboardInterrupt, attempting graceful shutdown ...\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'exit' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\nicov\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorboard\\compat\\__init__.py:42\u001b[0m, in \u001b[0;36mtf\u001b[1;34m()\u001b[0m\n\u001b[0;32m     41\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 42\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorboard\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompat\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m notf  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[0;32m     43\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'notf' from 'tensorboard.compat' (c:\\Users\\nicov\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorboard\\compat\\__init__.py)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\nicov\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\lightning\\pytorch\\trainer\\call.py:47\u001b[0m, in \u001b[0;36m_call_and_handle_interrupt\u001b[1;34m(trainer, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[0;32m     46\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39mlauncher\u001b[38;5;241m.\u001b[39mlaunch(trainer_fn, \u001b[38;5;241m*\u001b[39margs, trainer\u001b[38;5;241m=\u001b[39mtrainer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m---> 47\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m trainer_fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     49\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _TunerExitException:\n",
      "File \u001b[1;32mc:\\Users\\nicov\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\lightning\\pytorch\\trainer\\trainer.py:574\u001b[0m, in \u001b[0;36mTrainer._fit_impl\u001b[1;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[0;32m    568\u001b[0m ckpt_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_checkpoint_connector\u001b[38;5;241m.\u001b[39m_select_ckpt_path(\n\u001b[0;32m    569\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mfn,\n\u001b[0;32m    570\u001b[0m     ckpt_path,\n\u001b[0;32m    571\u001b[0m     model_provided\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    572\u001b[0m     model_connected\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlightning_module \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    573\u001b[0m )\n\u001b[1;32m--> 574\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mckpt_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    576\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mstopped\n",
      "File \u001b[1;32mc:\\Users\\nicov\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\lightning\\pytorch\\trainer\\trainer.py:943\u001b[0m, in \u001b[0;36mTrainer._run\u001b[1;34m(self, model, ckpt_path)\u001b[0m\n\u001b[0;32m    941\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data_connector\u001b[38;5;241m.\u001b[39mprepare_data()\n\u001b[1;32m--> 943\u001b[0m \u001b[43mcall\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_setup_hook\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# allow user to set up LightningModule in accelerator environment\u001b[39;00m\n\u001b[0;32m    944\u001b[0m log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: configuring model\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\nicov\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\lightning\\pytorch\\trainer\\call.py:96\u001b[0m, in \u001b[0;36m_call_setup_hook\u001b[1;34m(trainer)\u001b[0m\n\u001b[0;32m     95\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m logger \u001b[38;5;129;01min\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mloggers:\n\u001b[1;32m---> 96\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;43mhasattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mlogger\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mexperiment\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m:\n\u001b[0;32m     97\u001b[0m         _ \u001b[38;5;241m=\u001b[39m logger\u001b[38;5;241m.\u001b[39mexperiment\n",
      "File \u001b[1;32mc:\\Users\\nicov\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\lightning\\fabric\\loggers\\logger.py:118\u001b[0m, in \u001b[0;36mrank_zero_experiment.<locals>.experiment\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _DummyExperiment()\n\u001b[1;32m--> 118\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\nicov\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\lightning\\fabric\\loggers\\tensorboard.py:190\u001b[0m, in \u001b[0;36mTensorBoardLogger.experiment\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    189\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _TENSORBOARD_AVAILABLE:\n\u001b[1;32m--> 190\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtensorboard\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SummaryWriter\n\u001b[0;32m    191\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\nicov\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\utils\\tensorboard\\__init__.py:12\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m tensorboard\n\u001b[1;32m---> 12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mwriter\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m FileWriter, SummaryWriter  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorboard\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msummary\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mwriter\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mrecord_writer\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m RecordWriter\n",
      "File \u001b[1;32mc:\\Users\\nicov\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\utils\\tensorboard\\writer.py:19\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_convert_np\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m make_np\n\u001b[1;32m---> 19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_embedding\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_embedding_info, make_mat, make_sprite, make_tsv, write_pbtxt\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_onnx_graph\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m load_onnx_graph\n",
      "File \u001b[1;32mc:\\Users\\nicov\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\utils\\tensorboard\\_embedding.py:10\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorboard\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mplugins\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprojector\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprojector_config_pb2\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m EmbeddingInfo\n\u001b[1;32m---> 10\u001b[0m _HAS_GFILE_JOIN \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mhasattr\u001b[39m(\u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mio\u001b[49m\u001b[38;5;241m.\u001b[39mgfile, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mjoin\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_gfile_join\u001b[39m(a, b):\n\u001b[0;32m     14\u001b[0m     \u001b[38;5;66;03m# The join API is different between tensorboard's TF stub and TF:\u001b[39;00m\n\u001b[0;32m     15\u001b[0m     \u001b[38;5;66;03m# https://github.com/tensorflow/tensorboard/issues/6080\u001b[39;00m\n\u001b[0;32m     16\u001b[0m     \u001b[38;5;66;03m# We need to try both because `tf` may point to either the stub or the real TF.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\nicov\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorboard\\lazy.py:65\u001b[0m, in \u001b[0;36mlazy_load.<locals>.wrapper.<locals>.LazyModule.__getattr__\u001b[1;34m(self, attr_name)\u001b[0m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getattr__\u001b[39m(\u001b[38;5;28mself\u001b[39m, attr_name):\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[43mload_once\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m, attr_name)\n",
      "File \u001b[1;32mc:\\Users\\nicov\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorboard\\lazy.py:97\u001b[0m, in \u001b[0;36m_memoize.<locals>.wrapper\u001b[1;34m(arg)\u001b[0m\n\u001b[0;32m     96\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m cache\u001b[38;5;241m.\u001b[39mget(arg, nothing) \u001b[38;5;129;01mis\u001b[39;00m nothing:\n\u001b[1;32m---> 97\u001b[0m             cache[arg] \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43marg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     98\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m cache[arg]\n",
      "File \u001b[1;32mc:\\Users\\nicov\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorboard\\lazy.py:50\u001b[0m, in \u001b[0;36mlazy_load.<locals>.wrapper.<locals>.load_once\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 50\u001b[0m     module \u001b[38;5;241m=\u001b[39m \u001b[43mload_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\nicov\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorboard\\compat\\__init__.py:45\u001b[0m, in \u001b[0;36mtf\u001b[1;34m()\u001b[0m\n\u001b[0;32m     44\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 45\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\n\u001b[0;32m     47\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m tensorflow\n",
      "File \u001b[1;32mc:\\Users\\nicov\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\__init__.py:41\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msys\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01m_sys\u001b[39;00m\n\u001b[1;32m---> 41\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtools\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m module_util \u001b[38;5;28;01mas\u001b[39;00m _module_util\n\u001b[0;32m     42\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlazy_loader\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LazyLoader \u001b[38;5;28;01mas\u001b[39;00m _LazyLoader\n",
      "File \u001b[1;32mc:\\Users\\nicov\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\__init__.py:46\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[38;5;66;03m# pylint: enable=wildcard-import\u001b[39;00m\n\u001b[0;32m     44\u001b[0m \n\u001b[0;32m     45\u001b[0m \u001b[38;5;66;03m# Bring in subpackages.\u001b[39;00m\n\u001b[1;32m---> 46\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m data\n\u001b[0;32m     47\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m distribute\n",
      "File \u001b[1;32mc:\\Users\\nicov\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\data\\__init__.py:25\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;66;03m# pylint: disable=unused-import\u001b[39;00m\n\u001b[1;32m---> 25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m experimental\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdataset_ops\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AUTOTUNE\n",
      "File \u001b[1;32mc:\\Users\\nicov\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\data\\experimental\\__init__.py:122\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    121\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexperimental\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mio\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m save\n\u001b[1;32m--> 122\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexperimental\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01miterator_ops\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m CheckpointInputPipelineHook\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexperimental\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01miterator_ops\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m make_saveable_from_iterator\n",
      "File \u001b[1;32mc:\\Users\\nicov\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\data\\experimental\\ops\\iterator_ops.py:24\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mframework\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ops\n\u001b[1;32m---> 24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtraining\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m basic_session_run_hooks\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtraining\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m checkpoint_management\n",
      "File \u001b[1;32mc:\\Users\\nicov\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\training\\basic_session_run_hooks.py:47\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtraining\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msession_run_hook\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SessionRunArgs\n\u001b[1;32m---> 47\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtraining\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msummary_io\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SummaryWriterCache\n\u001b[0;32m     48\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtf_export\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tf_export\n",
      "File \u001b[1;32mc:\\Users\\nicov\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\training\\summary_io.py:23\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msummary\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msummary_iterator\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m summary_iterator\n\u001b[1;32m---> 23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msummary\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mwriter\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mwriter\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m FileWriter \u001b[38;5;28;01mas\u001b[39;00m _FileWriter\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msummary\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mwriter\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mwriter_cache\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m FileWriterCache \u001b[38;5;28;01mas\u001b[39;00m SummaryWriterCache\n",
      "File \u001b[1;32mc:\\Users\\nicov\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\summary\\writer\\writer.py:35\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msummary\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m plugin_asset\n\u001b[1;32m---> 35\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msummary\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mwriter\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mevent_file_writer\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m EventFileWriter\n\u001b[0;32m     36\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msummary\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mwriter\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mevent_file_writer_v2\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m EventFileWriterV2\n",
      "File \u001b[1;32mc:\\Users\\nicov\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow\\python\\summary\\writer\\event_file_writer.py:29\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msix\u001b[39;00m\n\u001b[1;32m---> 29\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mclient\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _pywrap_events_writer\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mplatform\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m gfile\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [20]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m warnings\u001b[38;5;241m.\u001b[39mfilterwarnings(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Llamada a la funci√≥n de b√∫squeda aleatoria\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m best_model, best_params, best_val_loss \u001b[38;5;241m=\u001b[39m \u001b[43mrandom_hyperparameter_search\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mval_dataloader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparam_grid\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_iterations\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[43msave_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m./plots/multiexog_syp500_-\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mn_prev_len\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43md-\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mdate_start\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreplace\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m-\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m-\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mdate_end\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreplace\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m-\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m-lessFilters\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     16\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcsv_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m./results/multiexog_syp500_-\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mn_prev_len\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43md-\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mdate_start\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m-\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mdate_end\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m.csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     17\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\nicov\\Documents\\Github\\QuantTrader-TFT\\tft_helper.py:333\u001b[0m, in \u001b[0;36mrandom_hyperparameter_search\u001b[1;34m(data, train, train_dataloader, val_dataloader, test, param_grid, n_iterations, max_epochs, save_dir, csv_file)\u001b[0m\n\u001b[0;32m    330\u001b[0m start_time \u001b[38;5;241m=\u001b[39m datetime\u001b[38;5;241m.\u001b[39mnow()\n\u001b[0;32m    332\u001b[0m \u001b[38;5;66;03m# Entrenar el modelo con la combinaci√≥n actual de hiperpar√°metros\u001b[39;00m\n\u001b[1;32m--> 333\u001b[0m tft, val_loss \u001b[38;5;241m=\u001b[39m tft_trainer(\n\u001b[0;32m    334\u001b[0m     train, train_dataloader, val_dataloader, max_epochs\u001b[38;5;241m=\u001b[39mmax_epochs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams\n\u001b[0;32m    335\u001b[0m )\n\u001b[0;32m    337\u001b[0m \u001b[38;5;66;03m# Medir el tiempo de finalizaci√≥n del entrenamiento\u001b[39;00m\n\u001b[0;32m    338\u001b[0m end_time \u001b[38;5;241m=\u001b[39m datetime\u001b[38;5;241m.\u001b[39mnow()\n",
      "File \u001b[1;32mc:\\Users\\nicov\\Documents\\Github\\QuantTrader-TFT\\tft_helper.py:123\u001b[0m, in \u001b[0;36mtft_trainer\u001b[1;34m(train, train_dataloader, val_dataloader, max_epochs, model_path, **kwargs)\u001b[0m\n\u001b[0;32m     93\u001b[0m trainer \u001b[38;5;241m=\u001b[39m pl\u001b[38;5;241m.\u001b[39mTrainer(\n\u001b[0;32m     94\u001b[0m     max_epochs\u001b[38;5;241m=\u001b[39mmax_epochs,\n\u001b[0;32m     95\u001b[0m     accelerator\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgpu\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    107\u001b[0m     ],\n\u001b[0;32m    108\u001b[0m )\n\u001b[0;32m    110\u001b[0m tft \u001b[38;5;241m=\u001b[39m TemporalFusionTransformer\u001b[38;5;241m.\u001b[39mfrom_dataset(\n\u001b[0;32m    111\u001b[0m     train,\n\u001b[0;32m    112\u001b[0m     learning_rate\u001b[38;5;241m=\u001b[39mkwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlearning_rate\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m0.15\u001b[39m),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    120\u001b[0m     reduce_on_plateau_patience\u001b[38;5;241m=\u001b[39mkwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreduce_on_plateau_patience\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m4\u001b[39m),\n\u001b[0;32m    121\u001b[0m )\n\u001b[1;32m--> 123\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtft\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_dataloader\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    125\u001b[0m \u001b[38;5;66;03m# Guardar el modelo entrenado\u001b[39;00m\n\u001b[0;32m    126\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m model_path:\n",
      "File \u001b[1;32mc:\\Users\\nicov\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\lightning\\pytorch\\trainer\\trainer.py:538\u001b[0m, in \u001b[0;36mTrainer.fit\u001b[1;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[0;32m    536\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m=\u001b[39m TrainerStatus\u001b[38;5;241m.\u001b[39mRUNNING\n\u001b[0;32m    537\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m--> 538\u001b[0m \u001b[43mcall\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_and_handle_interrupt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    539\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit_impl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatamodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\n\u001b[0;32m    540\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\nicov\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\lightning\\pytorch\\trainer\\call.py:64\u001b[0m, in \u001b[0;36m_call_and_handle_interrupt\u001b[1;34m(trainer, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(launcher, _SubprocessScriptLauncher):\n\u001b[0;32m     63\u001b[0m         launcher\u001b[38;5;241m.\u001b[39mkill(_get_sigkill_signal())\n\u001b[1;32m---> 64\u001b[0m     \u001b[43mexit\u001b[49m(\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exception:\n\u001b[0;32m     67\u001b[0m     _interrupt(trainer, exception)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'exit' is not defined"
     ]
    }
   ],
   "source": [
    "if grid_search == \"random\":\n",
    "    # Suprime todos los warnings\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "    # Llamada a la funci√≥n de b√∫squeda aleatoria\n",
    "    best_model, best_params, best_val_loss = random_hyperparameter_search(\n",
    "        data,\n",
    "        train,\n",
    "        train_dataloader,\n",
    "        val_dataloader,\n",
    "        test,\n",
    "        param_grid,\n",
    "        n_iterations=100,\n",
    "        max_epochs=50,\n",
    "        save_dir=f'./plots/multiexog_syp500_-{n_prev_len}d-{date_start.replace(\"-\",\"\")}-{date_end.replace(\"-\",\"\")}-lessFilters',\n",
    "        csv_file=f\"./results/multiexog_syp500_-{n_prev_len}d-{date_start}-{date_end}.csv\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40e9473e",
   "metadata": {},
   "outputs": [],
   "source": [
    "if grid_search == \"exhaustive\":\n",
    "    \n",
    "    # Suprime todos los warnings \n",
    "\n",
    "    \n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "    \n",
    "    # Llamada a la funci√≥n de b√∫squeda de hiperpar√°metros\n",
    "    best_model, best_params, best_val_loss = exhaustive_hyperparameter_search(\n",
    "        data, train, train_dataloader, val_dataloader, test, param_grid, max_epochs=1\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bebd5b9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if grid_search:\n",
    "    tft_predict(best_model, val_dataloader, n_preds=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f03dd31",
   "metadata": {},
   "source": [
    "# TEST EVAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3272e531",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_preds(\n",
    "    train,\n",
    "    test,\n",
    "    model,\n",
    "    encoder_lenght,\n",
    "    test_lenght,\n",
    "    pred_lenght,\n",
    "    quantiles: bool = True,\n",
    "):\n",
    "    # group = model.output_transformer.groups[0]\n",
    "    if quantiles:\n",
    "        try:  # for Quantileloss\n",
    "            preds = []\n",
    "            preds_data = pd.concat([train[-encoder_lenght:], test])\n",
    "            for i in range(0, test_lenght, pred_lenght):\n",
    "                new_data = preds_data[i : i + encoder_lenght + pred_lenght]\n",
    "                new_data.loc[:, group] = new_data.iloc[0, new_data.columns.get_loc(group)]\n",
    "                new_raw_predictions = model.predict(new_data, mode=\"raw\", return_x=True)\n",
    "                prediction = []\n",
    "                for i in range(pred_lenght):\n",
    "                    prediction.append(float(new_raw_predictions.output.prediction[0][i][3]))\n",
    "                preds.append(prediction)\n",
    "        except:  # for MQF2DistributionLoss\n",
    "            preds = []\n",
    "            preds_data = pd.concat([train[-encoder_lenght:], test])\n",
    "            for i in range(0, test_lenght, pred_lenght):\n",
    "                new_data = preds_data[i : i + encoder_lenght + pred_lenght]\n",
    "                new_data.loc[:, group] = new_data.iloc[0, new_data.columns.get_loc(group)]\n",
    "                prediction = model.to_prediction(new_raw_predictions.output)[0].flatten().tolist()\n",
    "                preds.append(prediction)\n",
    "    else:\n",
    "        preds = []\n",
    "        preds_data = pd.concat([train[-encoder_lenght:], test])\n",
    "        for i in range(0, test_lenght, pred_lenght):\n",
    "            new_data = preds_data[i : i + encoder_lenght + pred_lenght]\n",
    "            new_data.loc[:, group] = new_data.iloc[0, new_data.columns.get_loc(group)]\n",
    "            new_raw_predictions = model.predict(new_data, mode=\"raw\", return_x=True)\n",
    "            prediction = new_raw_predictions.output.prediction[0].flatten().tolist()\n",
    "            preds.append(prediction)\n",
    "\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ed3276c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preds = []\n",
    "# preds_data = pd.concat([data[-n_prev_len:], test])\n",
    "# # preds_data = preds_data.ffill()\n",
    "# preds_data[\"target\"] = float(1)\n",
    "# # preds_data.drop(columns=[\"target\"], inplace=True)\n",
    "# for i in range(0, test_len, pred_len):\n",
    "#     new_data = preds_data[i : i + n_prev_len + pred_len]\n",
    "#     new_data.loc[:, group] = new_data.iloc[0, new_data.columns.get_loc(group)]\n",
    "#     new_raw_predictions = tft.predict(new_data, mode=\"raw\", return_x=True)\n",
    "#     prediction = new_raw_predictions.output.prediction[0].flatten().tolist()\n",
    "#     preds.append(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a408112",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = make_preds(\n",
    "    train=data,\n",
    "    test=test,\n",
    "    model=tft,\n",
    "    encoder_lenght=n_prev_len,\n",
    "    test_lenght=test_len,\n",
    "    pred_lenght=pred_len,\n",
    "    quantiles=True if isinstance(loss, QuantileLoss) else False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9847a87",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mThe kernel died. Error: ... View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_absolute_percentage_error, root_mean_squared_error\n",
    "\n",
    "dates = test[\"Date\"].to_list()\n",
    "preds_flat = [item for sublist in preds for item in sublist]\n",
    "\n",
    "# real_vals = list(data[-n_preds * pred_len :][\"target\"])\n",
    "real_vals = test[\"target\"].to_list()\n",
    "\n",
    "print(f\"MAE: {mean_absolute_error(real_vals, preds_flat)}\")\n",
    "print(f\"MAPE: {mean_absolute_percentage_error(real_vals, preds_flat)}\")\n",
    "print(f\"RMSE: {root_mean_squared_error(real_vals, preds_flat)}\")\n",
    "\n",
    "plt.plot(dates, preds_flat, color=\"r\")\n",
    "plt.plot(dates, real_vals, color=\"g\")\n",
    "plt.title(\"Real vs Preds\")\n",
    "plt.xlabel(\"√çndice\")\n",
    "plt.ylabel(\"Valor\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96b460c4",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mThe kernel died. Error: ... View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_absolute_error, mean_absolute_percentage_error, mean_squared_error\n",
    "import matplotlib.dates as mdates\n",
    "\n",
    "# Convertir las fechas a formato de datetime si no est√°n ya\n",
    "dates = pd.to_datetime(test[\"Date\"]).to_list()\n",
    "\n",
    "# Aplanar las predicciones si es necesario\n",
    "preds_flat = [item for sublist in preds for item in sublist]\n",
    "\n",
    "# Valores reales\n",
    "real_vals = test[\"target\"].to_list()\n",
    "\n",
    "# M√©tricas de error\n",
    "print(f\"MAE: {mean_absolute_error(real_vals, preds_flat)}\")\n",
    "print(f\"MAPE: {mean_absolute_percentage_error(real_vals, preds_flat)}\")\n",
    "print(f\"RMSE: {mean_squared_error(real_vals, preds_flat, squared=False)}\")\n",
    "\n",
    "# Gr√°fico\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(dates, real_vals, color=\"g\", label=\"Valores Reales\")\n",
    "plt.plot(dates, preds_flat, color=\"r\", label=\"Predicciones\")\n",
    "plt.title(\"Valores Reales vs Predicciones\")\n",
    "plt.xlabel(\"Fecha\")\n",
    "plt.ylabel(\"Valor (‚Ç¨)\")\n",
    "\n",
    "# Formato de fecha en el eje x\n",
    "plt.gca().xaxis.set_major_formatter(mdates.DateFormatter(\"%Y-%m-%d\"))\n",
    "plt.gca().xaxis.set_major_locator(mdates.AutoDateLocator())\n",
    "plt.gcf().autofmt_xdate()  # Rotar fechas para mejor visualizaci√≥n\n",
    "\n",
    "# A√±adir leyenda\n",
    "plt.legend()\n",
    "\n",
    "# Mostrar gr√°fico\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f373476",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mThe kernel died. Error: ... View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "\n",
    "# Supongamos que `preds`, `test`, y `dates` ya est√°n definidos en tu entorno\n",
    "\n",
    "# Aplanar la lista de predicciones\n",
    "preds_flat = [item for sublist in preds for item in sublist]\n",
    "\n",
    "# Convertir los valores reales a una lista\n",
    "real_vals = test[\"target\"].to_list()\n",
    "\n",
    "# Lista de fechas (timestamps)\n",
    "\n",
    "\n",
    "# Calcular el error absoluto medio\n",
    "print(f\"MAE: {mean_absolute_error(real_vals, preds_flat)}\")\n",
    "print(f\"MAPE: {mean_absolute_percentage_error(real_vals, preds_flat)}\")\n",
    "print(f\"RMSE: {root_mean_squared_error(real_vals, preds_flat)}\")\n",
    "# Crear la gr√°fica\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(dates, preds_flat, color=\"r\", label=\"Predicciones\", marker=\"o\", linestyle=\"--\")\n",
    "plt.plot(dates, real_vals, color=\"g\", label=\"Valores Reales\", marker=\"x\", linestyle=\"-\")\n",
    "\n",
    "# A√±adir t√≠tulo y etiquetas\n",
    "plt.title(\"Predicciones vs Valores Reales\")\n",
    "plt.xlabel(\"Fecha\")\n",
    "plt.ylabel(\"Valor\")\n",
    "\n",
    "# Formatear las fechas en el eje x\n",
    "plt.gca().xaxis.set_major_formatter(mdates.DateFormatter(\"%Y-%m-%d\"))\n",
    "# plt.gca().xaxis.set_major_locator(mdates.HourLocator(interval=6))\n",
    "plt.gcf().autofmt_xdate()  # Rotar las etiquetas de fecha\n",
    "\n",
    "# A√±adir cuadr√≠cula y leyenda\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "\n",
    "# Mostrar la gr√°fica\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "081d3ac6",
   "metadata": {},
   "source": [
    "# INFERENCE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "584a21f5",
   "metadata": {},
   "source": [
    "## Retrain for inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d680c22",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mThe kernel died. Error: ... View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "features = [\n",
    "    col for col in data.columns if col != \"target\"\n",
    "]  # Columnas de caracter√≠sticas and col != \"Date\"\n",
    "\n",
    "max_prediction_length = pred_len\n",
    "max_encoder_length = n_prev_len  # 48\n",
    "# training_cutoff = data[\"Date\"].max() - pd.Timedelta(hours=max_encoder_length)\n",
    "training_cutoff = data[\"time_idx\"].max() - max_prediction_length\n",
    "\n",
    "retrain = TimeSeriesDataSet(\n",
    "    full.dropna()[lambda x: x.time_idx <= training_cutoff],\n",
    "    time_idx=\"time_idx\",\n",
    "    target=\"target\",\n",
    "    group_ids=[group],\n",
    "    min_encoder_length=max_encoder_length,  # keep encoder length long (as it is in the validation set)\n",
    "    max_encoder_length=max_encoder_length,\n",
    "    # min_prediction_length=24,\n",
    "    max_prediction_length=max_prediction_length,\n",
    "    static_categoricals=[],\n",
    "    static_reals=[],\n",
    "    time_varying_known_categoricals=[],  # group of categorical variables can be treated as one variable\n",
    "    time_varying_known_reals=[\"Date\", \"month\", \"week\", \"day\", \"time_idx\"],\n",
    "    time_varying_unknown_categoricals=[],\n",
    "    time_varying_unknown_reals=[\n",
    "        \"target\",\n",
    "        \"open\",\n",
    "        \"max\",\n",
    "        \"min\",\n",
    "        \"vol\",\n",
    "        \"var\",\n",
    "        \"SMA_5\",\n",
    "        \"EMA_5\",\n",
    "        \"SMA_10\",\n",
    "        \"EMA_10\",\n",
    "        \"SMA_15\",\n",
    "        \"EMA_15\",\n",
    "        \"SMA_20\",\n",
    "        \"EMA_20\",\n",
    "        \"RSI_6\",\n",
    "        \"RSI_10\",\n",
    "        \"RSI_14\",\n",
    "        \"Bollinger_Upper_5\",\n",
    "        \"Bollinger_Lower_5\",\n",
    "        \"Bollinger_Upper_10\",\n",
    "        \"Bollinger_Lower_10\",\n",
    "        \"Bollinger_Upper_15\",\n",
    "        \"Bollinger_Lower_15\",\n",
    "        \"Bollinger_Upper_20\",\n",
    "        \"Bollinger_Lower_20\",\n",
    "        \"MACD\",\n",
    "        \"Signal_Line\",\n",
    "        \"ATR_5\",\n",
    "        \"ATR_10\",\n",
    "        \"ATR_15\",\n",
    "        \"ATR_20\",\n",
    "        \"CCI_5\",\n",
    "        \"CCI_10\",\n",
    "        \"CCI_15\",\n",
    "        \"CCI_20\",\n",
    "        \"ROC_10\",\n",
    "        \"ROC_14\",\n",
    "        \"ROC_20\",\n",
    "        \"ROC_50\",\n",
    "        \"Stochastic_10_K\",\n",
    "        \"Stochastic_10_D\",\n",
    "        \"Stochastic_14_K\",\n",
    "        \"Stochastic_14_D\",\n",
    "        \"Stochastic_20_K\",\n",
    "        \"Stochastic_20_D\",\n",
    "        \"Stochastic_25_K\",\n",
    "        \"Stochastic_25_D\",\n",
    "        \"Stochastic_50_K\",\n",
    "        \"Stochastic_50_D\",\n",
    "        \"Williams_%R_10\",\n",
    "        \"Williams_%R_14\",\n",
    "    ],\n",
    "    # lags={\"target\": list(range(1, 5))},\n",
    "    # target_normalizer=GroupNormalizer(\"standard\", groups=[group], transformation=\"softplus\"),\n",
    "    # use softplus and normalize by group\n",
    "    add_relative_time_idx=True,\n",
    "    add_target_scales=True,\n",
    "    allow_missing_timesteps=True,\n",
    "    # add_encoder_length=True,\n",
    "    # categorical_encoders={\n",
    "    #     \"month\": pytorch_forecasting.data.encoders.NaNLabelEncoder(add_nan=True),\n",
    "    #     \"week\": pytorch_forecasting.data.encoders.NaNLabelEncoder(add_nan=True),\n",
    "    #     \"day\": pytorch_forecasting.data.encoders.NaNLabelEncoder(add_nan=True),\n",
    "    # },\n",
    ")\n",
    "\n",
    "revalidation = TimeSeriesDataSet.from_dataset(retrain, full.dropna(), predict=True, stop_randomization=True)\n",
    "\n",
    "# test = TimeSeriesDataSet.from_dataset(training, test_data, predict=True, stop_randomization=True)\n",
    "\n",
    "\n",
    "# create dataloaders for model\n",
    "\n",
    "batch_size = 64  # set this between 32 to 128\n",
    "\n",
    "retrain_dataloader = retrain.to_dataloader(\n",
    "\n",
    "    train=True, batch_size=batch_size, num_workers=7, persistent_workers=True\n",
    "\n",
    ")\n",
    "\n",
    "reval_dataloader = revalidation.to_dataloader(\n",
    "\n",
    "    train=False, batch_size=batch_size, num_workers=7, persistent_workers=True\n",
    "\n",
    ")\n",
    "\n",
    "# test_dataloader = test.to_dataloader(train=False, batch_size=batch_size, num_workers=11, persistent_workers=True)\n",
    "\n",
    "if not grid_search:\n",
    "\n",
    "    # tft_params[\"learning_rate\"] = 0.01\n",
    "\n",
    "    retft, val_loss = tft_trainer(\n",
    "\n",
    "        retrain, retrain_dataloader, reval_dataloader, max_epochs=epochs, **tft_params\n",
    "\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16c3c38f",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mThe kernel died. Error: ... View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "encoder_data = full[-n_prev_len:]\n",
    "last_row = full.iloc[-1]\n",
    "# Creamos nuevas filas\n",
    "new_rows = []\n",
    "for i in range(1, 6):\n",
    "    new_row = last_row.copy()\n",
    "    new_row[\"Date\"] += timedelta(days=i)\n",
    "    new_row[\"day\"] += i\n",
    "    new_row[\"time_idx\"] += i\n",
    "    new_rows.append(new_row)\n",
    "\n",
    "# Concatenamos las nuevas filas al DataFrame original\n",
    "decoder_data = pd.DataFrame(new_rows)\n",
    "\n",
    "new_data = pd.concat([encoder_data, decoder_data], ignore_index=True)\n",
    "new_data.loc[:, group] = new_data.iloc[0, new_data.columns.get_loc(group)]\n",
    "# new_data.loc[-pred_len: ,\"target\"] = 1\n",
    "new_raw_predictions = retft.predict(new_data, mode=\"raw\", return_x=True)\n",
    "if isinstance(loss, QuantileLoss):\n",
    "    prediction = []\n",
    "    for i in range(pred_len):\n",
    "        prediction.append(float(new_raw_predictions.output.prediction[0][i][3]))\n",
    "else:\n",
    "    prediction = new_raw_predictions.output.prediction[0].flatten().tolist()\n",
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "162b0a6e",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mThe kernel died. Error: ... View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# prediction = [11233.22265625, 11129.837890625, 11228.3486328125, 11315.59375, 11555.85546875]\n",
    "last_vals = full[-10:]\n",
    "last_vals = last_vals[[\"Date\", \"target\"]]\n",
    "fechas_azul = pd.date_range(start=\"2024-08-26\", periods=len(prediction))\n",
    "predictions = pd.DataFrame({\"Date\": fechas_azul, \"target\": prediction})\n",
    "\n",
    "plt.plot(predictions[\"Date\"], predictions[\"target\"], color=\"r\")\n",
    "plt.plot(last_vals[\"Date\"], last_vals[\"target\"], color=\"g\")\n",
    "plt.title(\"Gr√°fica de la lista aplanada\")\n",
    "plt.xlabel(\"√çndice\")\n",
    "plt.ylabel(\"Valor\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88078c66",
   "metadata": {},
   "source": [
    "# INTERPRETABILITY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2461fd42",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mThe kernel died. Error: ... View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "interpretation = tft.interpret_output(preds.output, reduction=\"sum\") #\n",
    "tft.plot_interpretation(interpretation)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2735f9d0",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mThe kernel died. Error: ... View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
