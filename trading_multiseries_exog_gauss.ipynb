{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "18f03e0a",
   "metadata": {},
   "source": [
    "<!-- # IMPORTS -->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5f98c2c",
   "metadata": {},
   "source": [
    "<!-- Por incompatibilidades entre librerias nos vemos obligados a hacer este workaround para que solucionar los problemas de dependencias. -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e43a3d70",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nicov\\anaconda3\\envs\\tft\\lib\\site-packages\\pytorch_forecasting\\models\\base_model.py:30: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    }
   ],
   "source": [
    "import  scipy.signal.signaltools\n",
    "import numpy as np\n",
    "\n",
    "def _centered(arr, newsize):\n",
    "    # Return the center newsize portion of the array.\n",
    "    newsize = np.asarray(newsize)\n",
    "    currsize = np.array(arr.shape)\n",
    "    startind = (currsize - newsize) // 2\n",
    "    endind = startind + newsize\n",
    "    myslice = [slice(startind[k], endind[k]) for k in range(len(endind))]\n",
    "    return arr[tuple(myslice)]\n",
    "\n",
    "scipy.signal.signaltools._centered = _centered\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "# import os\n",
    "# import pickle\n",
    "import pytorch_forecasting\n",
    "from pytorch_forecasting.data import GroupNormalizer\n",
    "from pytorch_forecasting.models.temporal_fusion_transformer.tuning import optimize_hyperparameters\n",
    "from pytorch_forecasting import TemporalFusionTransformer, TimeSeriesDataSet\n",
    "from lightning.pytorch.callbacks import EarlyStopping, LearningRateMonitor\n",
    "import lightning.pytorch as pl\n",
    "from lightning.pytorch.loggers import TensorBoardLogger\n",
    "import torch\n",
    "from pytorch_forecasting.metrics import MAE, SMAPE, PoissonLoss, QuantileLoss, MAPE, MASE\n",
    "from lightning.pytorch.tuner import Tuner\n",
    "from scipy.ndimage import gaussian_filter1d\n",
    "from  scipy.signal.signaltools import _centered\n",
    "from tft_helper import *\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "torch.backends.cudnn.benchmark = True # Enables cuDNN auto-tuner for faster runtime when input sizes are consistent\n",
    "\n",
    "basepath = os.path.abspath(\"\")  # script directory\n",
    "\n",
    "sys.path.insert(1, os.path.join(basepath, \"..\\\\\"))\n",
    "from datetime import datetime, timedelta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82736cf5",
   "metadata": {},
   "source": [
    "<!-- # PARAMS -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5b0f9f96",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_file = 'BTC'\n",
    "exog_files = ['Nasdaq', 'IBEX35', 'EUStoxx50', 'DowJones', 'S&P500', 'USD_EUR', 'GBP_USD', 'USTech100', 'S&P500Futures']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "62f8001a",
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "seq_len = 5 #sequence lenght: how many timesteps does a sequence have. For example a week could be considered a single sequence, therefore seq_len would be 5 as as the stock market opens 5 days a week.\n",
    "pred_len = 25 # prediction lenght: How many timesteps does a prediction sequence have. For example if each prediction is a full week pred_len should be 5 as the stock market opens 5 days a week.\n",
    "n_prev_len = 50 # Number of previous timesteps to take for inference. \n",
    "n_preds = 4 # number of predictions with test data\n",
    "test_len = pred_len * n_preds  # Number of timesteps to use for test data.\n",
    "group = \"group\" # If a same model should predict different stores, indices etc specify how to group them. If theres only one time series the set group col to one full of the same value.\n",
    "loss = MAE() #QuantileLoss() # Loss function. \n",
    "epochs = 100 # Epochs to train the model.\n",
    "\n",
    "# Set ts date range\n",
    "date_start = '2010-01-04' #None #\"2023-06-01\"\n",
    "date_end = \"2024-7-29\"\n",
    "shift = 1 # How many times to shift values. Useful for using last indicator values (RSI, MACD...) for inference\n",
    "ts_indicator_params = {\n",
    "    \"moving_average_windows\": [5, 10, 20, 50, 100, 200], # Moving averages periods\n",
    "    # \"sigma_gaussian_filter\": [1,2],\n",
    "    \"n_lags\": 10,\n",
    "                     \n",
    "                     }\n",
    "shift_cols = False\n",
    "# cols_to_shift = [2:]\n",
    "\n",
    "# Set training config.\n",
    "lr_finder = False\n",
    "grid_search = \"random\"\n",
    "early_stop_callback = EarlyStopping(monitor=\"val_loss\", min_delta=1e-4, patience=10, verbose=False, mode=\"min\")\n",
    "lr_logger = LearningRateMonitor()  # log the learning rate\n",
    "# logger = TensorBoardLogger(\"lightning_logs\")  # logging results to a tensorboard\n",
    "\n",
    "# TFT training params.\n",
    "tft_params =  {\"gradient_clip_val\": 0.03, \"hidden_size\": 24, \"dropout\": 0.25, \"hidden_continuous_size\": 24, \"attention_head_size\": 4, \"learning_rate\": 0.01, \"loss\": loss, \"early_stop_callback\": early_stop_callback}\n",
    "\n",
    "\n",
    "PIB_relevant_countries = ['USA',\n",
    " 'CHN',\n",
    "#  'EMU',\n",
    " 'DEU',\n",
    "#  'FRA',\n",
    "#  'GBR',\n",
    " 'JPN',\n",
    " 'IND',\n",
    " 'BRA',\n",
    " 'CAN',\n",
    "#  'AUS',\n",
    "#  'ITA',\n",
    "#  'KOR',\n",
    "#  'MEX',\n",
    "#  'IDN',\n",
    "#  'SAU',\n",
    "#  'ZAF',\n",
    "#  'TUR',\n",
    "#  'ESP'\n",
    " ]\n",
    "\n",
    "# param_grid = {\n",
    "#     \"gradient_clip_val\": [0.01, 0.03, 0.05],\n",
    "#     \"hidden_size\": [8, 16, 32],\n",
    "#     \"dropout\": [0.1, 0.25, 0.4],\n",
    "#     \"hidden_continuous_size\": [8, 16, 32],\n",
    "#     \"attention_head_size\": [2, 4, 8],\n",
    "#     \"learning_rate\": [0.005, 0.01, 0.03],\n",
    "#     \"loss\": [loss],\n",
    "#     \"test_len\": [test_len],\n",
    "#     \"pred_len\": [pred_len],\n",
    "#     \"n_prev_len\": [n_prev_len],\n",
    "# }\n",
    "\n",
    "param_grid = {\n",
    "    \"gradient_clip_val\": [0.01, 0.03, 0.05],\n",
    "    \"hidden_size\": [8, 16, 32],\n",
    "    \"dropout\": [0.1, 0.2, 0.3],\n",
    "    \"hidden_continuous_size\": [16, 64, 128],\n",
    "    \"attention_head_size\": [4,8,16],\n",
    "    \"learning_rate\": [0.005, 0.01, 0.03],\n",
    "    \"loss\": [loss],\n",
    "    \"test_len\": [test_len],\n",
    "    \"pred_len\": [pred_len],\n",
    "    \"n_prev_len\": [n_prev_len],\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8032f7e1",
   "metadata": {
    "id": "8032f7e1"
   },
   "source": [
    "<!-- # LOAD DATA -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8621112e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset does not contain volume data.\n",
      "Dataset does not contain volume data.\n",
      "Dataset does not contain volume data.\n",
      "Dataset does not contain volume data.\n",
      "Dataset does not contain volume data.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>target</th>\n",
       "      <th>open</th>\n",
       "      <th>max</th>\n",
       "      <th>min</th>\n",
       "      <th>var</th>\n",
       "      <th>exog_Nasdaq</th>\n",
       "      <th>exog_IBEX35</th>\n",
       "      <th>exog_EUStoxx50</th>\n",
       "      <th>exog_DowJones</th>\n",
       "      <th>exog_S&amp;P500</th>\n",
       "      <th>exog_USD_EUR</th>\n",
       "      <th>exog_GBP_USD</th>\n",
       "      <th>exog_USTech100</th>\n",
       "      <th>exog_S&amp;P500Futures</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>434.0</td>\n",
       "      <td>430.0</td>\n",
       "      <td>438.0</td>\n",
       "      <td>425.9</td>\n",
       "      <td>0.94</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.9208</td>\n",
       "      <td>1.4748</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016-01-02</td>\n",
       "      <td>433.7</td>\n",
       "      <td>434.0</td>\n",
       "      <td>437.4</td>\n",
       "      <td>430.7</td>\n",
       "      <td>-0.06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016-01-03</td>\n",
       "      <td>430.7</td>\n",
       "      <td>433.7</td>\n",
       "      <td>434.1</td>\n",
       "      <td>423.1</td>\n",
       "      <td>-0.70</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016-01-04</td>\n",
       "      <td>433.3</td>\n",
       "      <td>430.7</td>\n",
       "      <td>435.3</td>\n",
       "      <td>428.6</td>\n",
       "      <td>0.61</td>\n",
       "      <td>4497.86</td>\n",
       "      <td>9313.2</td>\n",
       "      <td>3164.76</td>\n",
       "      <td>17148.94</td>\n",
       "      <td>2012.7</td>\n",
       "      <td>0.9232</td>\n",
       "      <td>1.4718</td>\n",
       "      <td>4497.9</td>\n",
       "      <td>2009.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016-01-05</td>\n",
       "      <td>431.2</td>\n",
       "      <td>433.3</td>\n",
       "      <td>435.3</td>\n",
       "      <td>428.9</td>\n",
       "      <td>-0.49</td>\n",
       "      <td>4484.18</td>\n",
       "      <td>9335.2</td>\n",
       "      <td>3178.01</td>\n",
       "      <td>17158.66</td>\n",
       "      <td>2016.7</td>\n",
       "      <td>0.9304</td>\n",
       "      <td>1.4672</td>\n",
       "      <td>4484.2</td>\n",
       "      <td>2011.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3246</th>\n",
       "      <td>2024-11-20</td>\n",
       "      <td>94303.9</td>\n",
       "      <td>92252.6</td>\n",
       "      <td>94836.1</td>\n",
       "      <td>91517.4</td>\n",
       "      <td>2.24</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>43225.79</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.9483</td>\n",
       "      <td>1.2650</td>\n",
       "      <td>20664.8</td>\n",
       "      <td>5937.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3247</th>\n",
       "      <td>2024-11-21</td>\n",
       "      <td>98374.5</td>\n",
       "      <td>94308.7</td>\n",
       "      <td>98937.2</td>\n",
       "      <td>94063.8</td>\n",
       "      <td>4.32</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.9546</td>\n",
       "      <td>1.2586</td>\n",
       "      <td>20695.6</td>\n",
       "      <td>5970.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3248</th>\n",
       "      <td>2024-11-22</td>\n",
       "      <td>98929.7</td>\n",
       "      <td>98381.2</td>\n",
       "      <td>99617.4</td>\n",
       "      <td>97182.2</td>\n",
       "      <td>0.56</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.9595</td>\n",
       "      <td>1.2531</td>\n",
       "      <td>20800.4</td>\n",
       "      <td>5987.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3249</th>\n",
       "      <td>2024-11-23</td>\n",
       "      <td>97699.0</td>\n",
       "      <td>98927.2</td>\n",
       "      <td>98927.2</td>\n",
       "      <td>97180.9</td>\n",
       "      <td>-1.24</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3250</th>\n",
       "      <td>2024-11-24</td>\n",
       "      <td>96052.7</td>\n",
       "      <td>97696.4</td>\n",
       "      <td>98552.6</td>\n",
       "      <td>95791.4</td>\n",
       "      <td>-1.69</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20857.4</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3251 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Date   target     open      max      min   var  exog_Nasdaq  \\\n",
       "0    2016-01-01    434.0    430.0    438.0    425.9  0.94          NaN   \n",
       "1    2016-01-02    433.7    434.0    437.4    430.7 -0.06          NaN   \n",
       "2    2016-01-03    430.7    433.7    434.1    423.1 -0.70          NaN   \n",
       "3    2016-01-04    433.3    430.7    435.3    428.6  0.61      4497.86   \n",
       "4    2016-01-05    431.2    433.3    435.3    428.9 -0.49      4484.18   \n",
       "...         ...      ...      ...      ...      ...   ...          ...   \n",
       "3246 2024-11-20  94303.9  92252.6  94836.1  91517.4  2.24          NaN   \n",
       "3247 2024-11-21  98374.5  94308.7  98937.2  94063.8  4.32          NaN   \n",
       "3248 2024-11-22  98929.7  98381.2  99617.4  97182.2  0.56          NaN   \n",
       "3249 2024-11-23  97699.0  98927.2  98927.2  97180.9 -1.24          NaN   \n",
       "3250 2024-11-24  96052.7  97696.4  98552.6  95791.4 -1.69          NaN   \n",
       "\n",
       "      exog_IBEX35  exog_EUStoxx50  exog_DowJones  exog_S&P500  exog_USD_EUR  \\\n",
       "0             NaN             NaN            NaN          NaN        0.9208   \n",
       "1             NaN             NaN            NaN          NaN           NaN   \n",
       "2             NaN             NaN            NaN          NaN           NaN   \n",
       "3          9313.2         3164.76       17148.94       2012.7        0.9232   \n",
       "4          9335.2         3178.01       17158.66       2016.7        0.9304   \n",
       "...           ...             ...            ...          ...           ...   \n",
       "3246          NaN             NaN       43225.79          NaN        0.9483   \n",
       "3247          NaN             NaN            NaN          NaN        0.9546   \n",
       "3248          NaN             NaN            NaN          NaN        0.9595   \n",
       "3249          NaN             NaN            NaN          NaN           NaN   \n",
       "3250          NaN             NaN            NaN          NaN           NaN   \n",
       "\n",
       "      exog_GBP_USD  exog_USTech100  exog_S&P500Futures  \n",
       "0           1.4748             NaN                 NaN  \n",
       "1              NaN             NaN                 NaN  \n",
       "2              NaN             NaN                 NaN  \n",
       "3           1.4718          4497.9             2009.00  \n",
       "4           1.4672          4484.2             2011.75  \n",
       "...            ...             ...                 ...  \n",
       "3246        1.2650         20664.8             5937.75  \n",
       "3247        1.2586         20695.6             5970.50  \n",
       "3248        1.2531         20800.4             5987.00  \n",
       "3249           NaN             NaN                 NaN  \n",
       "3250           NaN         20857.4                 NaN  \n",
       "\n",
       "[3251 rows x 15 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = create_combined_ts_df(target_file, exog_files)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56b5f849",
   "metadata": {},
   "source": [
    "<!-- ## ADD INDICATORS -->\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1fec0805",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = add_global_indicators(df, PIB_relevant_countries, date_start, date_end)\n",
    "df = add_indicators(df, ts_indicator_params, categorical_tendency_vars=True)\n",
    "# df = df.rename(columns={\"target\": \"exog_target\"})\n",
    "# df = df.rename(columns={\"target_smoothed_2\": \"target\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8103608c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>target</th>\n",
       "      <th>open</th>\n",
       "      <th>max</th>\n",
       "      <th>min</th>\n",
       "      <th>var</th>\n",
       "      <th>exog_Nasdaq</th>\n",
       "      <th>exog_IBEX35</th>\n",
       "      <th>exog_EUStoxx50</th>\n",
       "      <th>exog_DowJones</th>\n",
       "      <th>...</th>\n",
       "      <th>bullish_rsi</th>\n",
       "      <th>bearish_rsi</th>\n",
       "      <th>bullish_bollinger</th>\n",
       "      <th>bearish_bollinger</th>\n",
       "      <th>bullish_macd</th>\n",
       "      <th>bearish_macd</th>\n",
       "      <th>bullish_atr</th>\n",
       "      <th>bearish_atr</th>\n",
       "      <th>bullish_trend</th>\n",
       "      <th>bearish_trend</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>434.0</td>\n",
       "      <td>430.0</td>\n",
       "      <td>438.0</td>\n",
       "      <td>425.9</td>\n",
       "      <td>0.94</td>\n",
       "      <td>4497.86</td>\n",
       "      <td>9313.2</td>\n",
       "      <td>3164.76</td>\n",
       "      <td>17148.94</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016-01-02</td>\n",
       "      <td>433.7</td>\n",
       "      <td>434.0</td>\n",
       "      <td>437.4</td>\n",
       "      <td>430.7</td>\n",
       "      <td>-0.06</td>\n",
       "      <td>4497.86</td>\n",
       "      <td>9313.2</td>\n",
       "      <td>3164.76</td>\n",
       "      <td>17148.94</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016-01-03</td>\n",
       "      <td>430.7</td>\n",
       "      <td>433.7</td>\n",
       "      <td>434.1</td>\n",
       "      <td>423.1</td>\n",
       "      <td>-0.70</td>\n",
       "      <td>4497.86</td>\n",
       "      <td>9313.2</td>\n",
       "      <td>3164.76</td>\n",
       "      <td>17148.94</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016-01-04</td>\n",
       "      <td>433.3</td>\n",
       "      <td>430.7</td>\n",
       "      <td>435.3</td>\n",
       "      <td>428.6</td>\n",
       "      <td>0.61</td>\n",
       "      <td>4497.86</td>\n",
       "      <td>9313.2</td>\n",
       "      <td>3164.76</td>\n",
       "      <td>17148.94</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016-01-05</td>\n",
       "      <td>431.2</td>\n",
       "      <td>433.3</td>\n",
       "      <td>435.3</td>\n",
       "      <td>428.9</td>\n",
       "      <td>-0.49</td>\n",
       "      <td>4484.18</td>\n",
       "      <td>9335.2</td>\n",
       "      <td>3178.01</td>\n",
       "      <td>17158.66</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3128</th>\n",
       "      <td>2024-07-25</td>\n",
       "      <td>65799.3</td>\n",
       "      <td>65363.9</td>\n",
       "      <td>66088.6</td>\n",
       "      <td>63500.9</td>\n",
       "      <td>0.66</td>\n",
       "      <td>18830.59</td>\n",
       "      <td>11145.6</td>\n",
       "      <td>4811.28</td>\n",
       "      <td>39935.07</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3129</th>\n",
       "      <td>2024-07-26</td>\n",
       "      <td>67908.6</td>\n",
       "      <td>65799.7</td>\n",
       "      <td>68205.0</td>\n",
       "      <td>65764.3</td>\n",
       "      <td>3.21</td>\n",
       "      <td>19023.66</td>\n",
       "      <td>11165.9</td>\n",
       "      <td>4862.50</td>\n",
       "      <td>40589.34</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3130</th>\n",
       "      <td>2024-07-27</td>\n",
       "      <td>67843.1</td>\n",
       "      <td>67910.8</td>\n",
       "      <td>69387.6</td>\n",
       "      <td>66776.8</td>\n",
       "      <td>-0.10</td>\n",
       "      <td>19023.66</td>\n",
       "      <td>11165.9</td>\n",
       "      <td>4862.50</td>\n",
       "      <td>40589.34</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3131</th>\n",
       "      <td>2024-07-28</td>\n",
       "      <td>68256.3</td>\n",
       "      <td>67888.9</td>\n",
       "      <td>68291.9</td>\n",
       "      <td>67067.8</td>\n",
       "      <td>0.61</td>\n",
       "      <td>19023.66</td>\n",
       "      <td>11165.9</td>\n",
       "      <td>4862.50</td>\n",
       "      <td>40589.34</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3132</th>\n",
       "      <td>2024-07-29</td>\n",
       "      <td>66798.7</td>\n",
       "      <td>68256.3</td>\n",
       "      <td>70000.2</td>\n",
       "      <td>66544.5</td>\n",
       "      <td>-2.14</td>\n",
       "      <td>19059.49</td>\n",
       "      <td>11117.8</td>\n",
       "      <td>4815.39</td>\n",
       "      <td>40539.93</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3133 rows × 76 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Date   target     open      max      min   var  exog_Nasdaq  \\\n",
       "0    2016-01-01    434.0    430.0    438.0    425.9  0.94      4497.86   \n",
       "1    2016-01-02    433.7    434.0    437.4    430.7 -0.06      4497.86   \n",
       "2    2016-01-03    430.7    433.7    434.1    423.1 -0.70      4497.86   \n",
       "3    2016-01-04    433.3    430.7    435.3    428.6  0.61      4497.86   \n",
       "4    2016-01-05    431.2    433.3    435.3    428.9 -0.49      4484.18   \n",
       "...         ...      ...      ...      ...      ...   ...          ...   \n",
       "3128 2024-07-25  65799.3  65363.9  66088.6  63500.9  0.66     18830.59   \n",
       "3129 2024-07-26  67908.6  65799.7  68205.0  65764.3  3.21     19023.66   \n",
       "3130 2024-07-27  67843.1  67910.8  69387.6  66776.8 -0.10     19023.66   \n",
       "3131 2024-07-28  68256.3  67888.9  68291.9  67067.8  0.61     19023.66   \n",
       "3132 2024-07-29  66798.7  68256.3  70000.2  66544.5 -2.14     19059.49   \n",
       "\n",
       "      exog_IBEX35  exog_EUStoxx50  exog_DowJones  ...  bullish_rsi  \\\n",
       "0          9313.2         3164.76       17148.94  ...            0   \n",
       "1          9313.2         3164.76       17148.94  ...            0   \n",
       "2          9313.2         3164.76       17148.94  ...            0   \n",
       "3          9313.2         3164.76       17148.94  ...            0   \n",
       "4          9335.2         3178.01       17158.66  ...            0   \n",
       "...           ...             ...            ...  ...          ...   \n",
       "3128      11145.6         4811.28       39935.07  ...            0   \n",
       "3129      11165.9         4862.50       40589.34  ...            0   \n",
       "3130      11165.9         4862.50       40589.34  ...            0   \n",
       "3131      11165.9         4862.50       40589.34  ...            0   \n",
       "3132      11117.8         4815.39       40539.93  ...            0   \n",
       "\n",
       "      bearish_rsi  bullish_bollinger  bearish_bollinger  bullish_macd  \\\n",
       "0               0                  0                  0             0   \n",
       "1               0                  0                  0             0   \n",
       "2               0                  0                  0             0   \n",
       "3               0                  0                  0             0   \n",
       "4               0                  0                  0             0   \n",
       "...           ...                ...                ...           ...   \n",
       "3128            1                  0                  0             1   \n",
       "3129            1                  0                  0             1   \n",
       "3130            1                  0                  0             1   \n",
       "3131            1                  0                  0             1   \n",
       "3132            0                  0                  0             1   \n",
       "\n",
       "      bearish_macd  bullish_atr  bearish_atr  bullish_trend bearish_trend  \n",
       "0                0            0            0              0             0  \n",
       "1                1            0            0              0             0  \n",
       "2                1            0            0              0             0  \n",
       "3                1            0            0              0             0  \n",
       "4                1            0            0              0             0  \n",
       "...            ...          ...          ...            ...           ...  \n",
       "3128             0            0            1              0             0  \n",
       "3129             0            1            0              1             0  \n",
       "3130             0            0            1              0             0  \n",
       "3131             0            0            1              0             0  \n",
       "3132             0            0            1              0             0  \n",
       "\n",
       "[3133 rows x 76 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2bef641",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # SHift indicator values\n",
    "# if shift_cols:\n",
    "#     cols_to_shift = [col for col in df.columns[3:] if not (col.startswith('AAII') or col.startswith('PIB'))]\n",
    "#     df[cols_to_shift] = df[cols_to_shift].shift(shift)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "98789fc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df.copy().dropna()\n",
    "data.rename(columns={'target': 'close'}, inplace=True)\n",
    "data.to_csv('BTC.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e0225526",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'evvcw' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mevvcw\u001b[49m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'evvcw' is not defined"
     ]
    }
   ],
   "source": [
    "evvcw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "179a60de",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df.copy()\n",
    "data[\"group\"] = 1\n",
    "\n",
    "# Supongamos que tu DataFrame se llama 'data' y que la columna 'Date' tiene las fechas\n",
    "# Crear una lista de días festivos (ejemplo, agrega tus días festivos)\n",
    "dias_festivos = pd.to_datetime([\"2024-01-01\", \"2024-12-25\", ])  # Añade más días festivos\n",
    "\n",
    "# Meses del año (convertir a nombres de meses)\n",
    "data[\"month\"] = data[\"Date\"].dt.strftime('%B')  # Ejemplo: \"January\", \"February\", etc.\n",
    "\n",
    "# Días del año (de 1 a 365 o 366 en años bisiestos), convertir en cadena\n",
    "data[\"day_of_year\"] = data[\"Date\"].dt.dayofyear.astype(str)  # Convertir el número de día a cadena\n",
    "\n",
    "# Días de la semana (de lunes a viernes: 0 = lunes, 4 = viernes), convertir a nombre de día\n",
    "data[\"weekday\"] = data[\"Date\"].dt.strftime('%A')  # Ejemplo: \"Monday\", \"Tuesday\", etc.\n",
    "\n",
    "# Filtrar para eliminar sábados y domingos\n",
    "data = data[data[\"weekday\"].isin([\"Monday\", \"Tuesday\", \"Wednesday\", \"Thursday\", \"Friday\"])]\n",
    "\n",
    "# Identificar si el día es festivo (usar \"Yes\" o \"No\" en lugar de 1 o 0)\n",
    "data[\"is_holiday\"] = data[\"Date\"].isin(dias_festivos).map({True: \"Yes\", False: \"No\"})\n",
    "\n",
    "data[\"time_idx\"] = data.index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "738538a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>close</th>\n",
       "      <th>open</th>\n",
       "      <th>max</th>\n",
       "      <th>min</th>\n",
       "      <th>var</th>\n",
       "      <th>exog_Nasdaq</th>\n",
       "      <th>exog_IBEX35</th>\n",
       "      <th>exog_EUStoxx50</th>\n",
       "      <th>exog_DowJones</th>\n",
       "      <th>...</th>\n",
       "      <th>bullish_atr</th>\n",
       "      <th>bearish_atr</th>\n",
       "      <th>bullish_trend</th>\n",
       "      <th>bearish_trend</th>\n",
       "      <th>group</th>\n",
       "      <th>month</th>\n",
       "      <th>day_of_year</th>\n",
       "      <th>weekday</th>\n",
       "      <th>is_holiday</th>\n",
       "      <th>time_idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>434.0</td>\n",
       "      <td>430.0</td>\n",
       "      <td>438.0</td>\n",
       "      <td>425.9</td>\n",
       "      <td>0.94</td>\n",
       "      <td>4497.86</td>\n",
       "      <td>9313.2</td>\n",
       "      <td>3164.76</td>\n",
       "      <td>17148.94</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>January</td>\n",
       "      <td>1</td>\n",
       "      <td>Friday</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016-01-04</td>\n",
       "      <td>433.3</td>\n",
       "      <td>430.7</td>\n",
       "      <td>435.3</td>\n",
       "      <td>428.6</td>\n",
       "      <td>0.61</td>\n",
       "      <td>4497.86</td>\n",
       "      <td>9313.2</td>\n",
       "      <td>3164.76</td>\n",
       "      <td>17148.94</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>January</td>\n",
       "      <td>4</td>\n",
       "      <td>Monday</td>\n",
       "      <td>No</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016-01-05</td>\n",
       "      <td>431.2</td>\n",
       "      <td>433.3</td>\n",
       "      <td>435.3</td>\n",
       "      <td>428.9</td>\n",
       "      <td>-0.49</td>\n",
       "      <td>4484.18</td>\n",
       "      <td>9335.2</td>\n",
       "      <td>3178.01</td>\n",
       "      <td>17158.66</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>January</td>\n",
       "      <td>5</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>No</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2016-01-06</td>\n",
       "      <td>430.8</td>\n",
       "      <td>431.2</td>\n",
       "      <td>432.1</td>\n",
       "      <td>425.0</td>\n",
       "      <td>-0.09</td>\n",
       "      <td>4443.98</td>\n",
       "      <td>9197.4</td>\n",
       "      <td>3139.32</td>\n",
       "      <td>16906.51</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>January</td>\n",
       "      <td>6</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>No</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2016-01-07</td>\n",
       "      <td>457.0</td>\n",
       "      <td>430.8</td>\n",
       "      <td>457.5</td>\n",
       "      <td>428.5</td>\n",
       "      <td>6.09</td>\n",
       "      <td>4305.72</td>\n",
       "      <td>9059.3</td>\n",
       "      <td>3084.68</td>\n",
       "      <td>16514.10</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>January</td>\n",
       "      <td>7</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>No</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3126</th>\n",
       "      <td>2024-07-23</td>\n",
       "      <td>65937.8</td>\n",
       "      <td>67550.4</td>\n",
       "      <td>67750.2</td>\n",
       "      <td>65512.9</td>\n",
       "      <td>-2.39</td>\n",
       "      <td>19754.34</td>\n",
       "      <td>11212.7</td>\n",
       "      <td>4916.80</td>\n",
       "      <td>40358.09</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>July</td>\n",
       "      <td>205</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>No</td>\n",
       "      <td>3126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3127</th>\n",
       "      <td>2024-07-24</td>\n",
       "      <td>65370.5</td>\n",
       "      <td>65936.8</td>\n",
       "      <td>67072.1</td>\n",
       "      <td>65155.2</td>\n",
       "      <td>-0.86</td>\n",
       "      <td>19032.39</td>\n",
       "      <td>11210.1</td>\n",
       "      <td>4861.87</td>\n",
       "      <td>39853.87</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>July</td>\n",
       "      <td>206</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>No</td>\n",
       "      <td>3127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3128</th>\n",
       "      <td>2024-07-25</td>\n",
       "      <td>65799.3</td>\n",
       "      <td>65363.9</td>\n",
       "      <td>66088.6</td>\n",
       "      <td>63500.9</td>\n",
       "      <td>0.66</td>\n",
       "      <td>18830.59</td>\n",
       "      <td>11145.6</td>\n",
       "      <td>4811.28</td>\n",
       "      <td>39935.07</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>July</td>\n",
       "      <td>207</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>No</td>\n",
       "      <td>3128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3129</th>\n",
       "      <td>2024-07-26</td>\n",
       "      <td>67908.6</td>\n",
       "      <td>65799.7</td>\n",
       "      <td>68205.0</td>\n",
       "      <td>65764.3</td>\n",
       "      <td>3.21</td>\n",
       "      <td>19023.66</td>\n",
       "      <td>11165.9</td>\n",
       "      <td>4862.50</td>\n",
       "      <td>40589.34</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>July</td>\n",
       "      <td>208</td>\n",
       "      <td>Friday</td>\n",
       "      <td>No</td>\n",
       "      <td>3129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3132</th>\n",
       "      <td>2024-07-29</td>\n",
       "      <td>66798.7</td>\n",
       "      <td>68256.3</td>\n",
       "      <td>70000.2</td>\n",
       "      <td>66544.5</td>\n",
       "      <td>-2.14</td>\n",
       "      <td>19059.49</td>\n",
       "      <td>11117.8</td>\n",
       "      <td>4815.39</td>\n",
       "      <td>40539.93</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>July</td>\n",
       "      <td>211</td>\n",
       "      <td>Monday</td>\n",
       "      <td>No</td>\n",
       "      <td>3132</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2237 rows × 82 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Date    close     open      max      min   var  exog_Nasdaq  \\\n",
       "0    2016-01-01    434.0    430.0    438.0    425.9  0.94      4497.86   \n",
       "3    2016-01-04    433.3    430.7    435.3    428.6  0.61      4497.86   \n",
       "4    2016-01-05    431.2    433.3    435.3    428.9 -0.49      4484.18   \n",
       "5    2016-01-06    430.8    431.2    432.1    425.0 -0.09      4443.98   \n",
       "6    2016-01-07    457.0    430.8    457.5    428.5  6.09      4305.72   \n",
       "...         ...      ...      ...      ...      ...   ...          ...   \n",
       "3126 2024-07-23  65937.8  67550.4  67750.2  65512.9 -2.39     19754.34   \n",
       "3127 2024-07-24  65370.5  65936.8  67072.1  65155.2 -0.86     19032.39   \n",
       "3128 2024-07-25  65799.3  65363.9  66088.6  63500.9  0.66     18830.59   \n",
       "3129 2024-07-26  67908.6  65799.7  68205.0  65764.3  3.21     19023.66   \n",
       "3132 2024-07-29  66798.7  68256.3  70000.2  66544.5 -2.14     19059.49   \n",
       "\n",
       "      exog_IBEX35  exog_EUStoxx50  exog_DowJones  ...  bullish_atr  \\\n",
       "0          9313.2         3164.76       17148.94  ...            0   \n",
       "3          9313.2         3164.76       17148.94  ...            0   \n",
       "4          9335.2         3178.01       17158.66  ...            0   \n",
       "5          9197.4         3139.32       16906.51  ...            0   \n",
       "6          9059.3         3084.68       16514.10  ...            0   \n",
       "...           ...             ...            ...  ...          ...   \n",
       "3126      11212.7         4916.80       40358.09  ...            0   \n",
       "3127      11210.1         4861.87       39853.87  ...            0   \n",
       "3128      11145.6         4811.28       39935.07  ...            0   \n",
       "3129      11165.9         4862.50       40589.34  ...            1   \n",
       "3132      11117.8         4815.39       40539.93  ...            0   \n",
       "\n",
       "      bearish_atr  bullish_trend  bearish_trend  group    month  day_of_year  \\\n",
       "0               0              0              0      1  January            1   \n",
       "3               0              0              0      1  January            4   \n",
       "4               0              0              0      1  January            5   \n",
       "5               0              0              0      1  January            6   \n",
       "6               0              0              0      1  January            7   \n",
       "...           ...            ...            ...    ...      ...          ...   \n",
       "3126            1              0              0      1     July          205   \n",
       "3127            1              0              0      1     July          206   \n",
       "3128            1              0              0      1     July          207   \n",
       "3129            0              1              0      1     July          208   \n",
       "3132            1              0              0      1     July          211   \n",
       "\n",
       "        weekday  is_holiday time_idx  \n",
       "0        Friday          No        0  \n",
       "3        Monday          No        3  \n",
       "4       Tuesday          No        4  \n",
       "5     Wednesday          No        5  \n",
       "6      Thursday          No        6  \n",
       "...         ...         ...      ...  \n",
       "3126    Tuesday          No     3126  \n",
       "3127  Wednesday          No     3127  \n",
       "3128   Thursday          No     3128  \n",
       "3129     Friday          No     3129  \n",
       "3132     Monday          No     3132  \n",
       "\n",
       "[2237 rows x 82 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17b140da",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'frg' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[24], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mfrg\u001b[49m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'frg' is not defined"
     ]
    }
   ],
   "source": [
    "# frg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0651f8e",
   "metadata": {},
   "source": [
    " <!-- VARIABLES GROUPING -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa586286",
   "metadata": {},
   "outputs": [],
   "source": [
    "rest=['Date', 'target',\n",
    "'FEDFUNDS', 'open', 'max', 'min', 'var',\n",
    "'MACD', 'Signal_Line',\n",
    "'group', 'month', 'day_of_year', 'weekday','is_holiday', 'time_idx']\n",
    "PIB_cols = [col for col in df.columns if col.startswith('PIB')]\n",
    "AAII_cols = [col for col in df.columns if col.startswith('AAII')]\n",
    "VIX_cols = [col for col in df.columns if col.endswith('VIX')]\n",
    "SMA_cols = [col for col in df.columns if col.startswith('SMA')]\n",
    "EMA_cols = [col for col in df.columns if col.startswith('EMA')]\n",
    "lag_cols = [col for col in df.columns if col.startswith('target_lag')]\n",
    "target_smoothed_cols = [col for col in df.columns if col.startswith('target_smoothed')]\n",
    "RSI_cols = [col for col in df.columns if col.startswith('RSI')]\n",
    "Bollinger_cols = [col for col in df.columns if col.startswith('Bollinger')]\n",
    "ATR_cols = [col for col in df.columns if col.startswith('ATR')]\n",
    "CCI_cols = [col for col in df.columns if col.startswith('CCI')]\n",
    "ROC_cols = [col for col in df.columns if col.startswith('ROC')]\n",
    "Williams_cols = [col for col in df.columns if col.startswith('Williams')]\n",
    "Stochastic_cols = [col for col in df.columns if col.startswith('Stochastic')]\n",
    "bullish_cols = [col for col in df.columns if col.startswith('bullish')]\n",
    "bearish_cols = [col for col in df.columns if col.startswith('bearish')]\n",
    "exog_ts = [col for col in df.columns if col.startswith('exog')]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fa86e03",
   "metadata": {},
   "source": [
    "<!-- ## TRAIN - TEST SPLIT -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c2fd2fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "full = data.copy()\n",
    "cols_to_convert = [\"target\", \"open\", \"max\", \"min\", \"var\", \"MACD\", \"Signal_Line\"] + SMA_cols + EMA_cols + Bollinger_cols + ATR_cols + CCI_cols + ROC_cols + Williams_cols + Stochastic_cols + exog_ts + VIX_cols + lag_cols + target_smoothed_cols + RSI_cols\n",
    "full[cols_to_convert] = full[cols_to_convert].apply(pd.to_numeric, errors='coerce')\n",
    "full = full.ffill().bfill()\n",
    "\n",
    "data = full[:-test_len]\n",
    "test = full[-test_len:]\n",
    "data = data.reset_index(drop=True)\n",
    "data = data.dropna()\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(data[\"Date\"][-200:], data[\"target\"][-200:], color=\"blue\", label=\"Train\")\n",
    "plt.plot(test[\"Date\"][-200:], test[\"target\"][-200:], color=\"green\", label=\"Test\")\n",
    "\n",
    "plt.xlabel(\"Fecha y Hora\")\n",
    "plt.ylabel(\"Precio Spot\")\n",
    "plt.title(\"Precio Spot en función de Fecha y Hora\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "740262e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>exog_target</th>\n",
       "      <th>open</th>\n",
       "      <th>max</th>\n",
       "      <th>min</th>\n",
       "      <th>var</th>\n",
       "      <th>exog_Nasdaq</th>\n",
       "      <th>exog_IBEX35</th>\n",
       "      <th>exog_EUStoxx50</th>\n",
       "      <th>exog_DowJones</th>\n",
       "      <th>...</th>\n",
       "      <th>bullish_atr</th>\n",
       "      <th>bearish_atr</th>\n",
       "      <th>bullish_trend</th>\n",
       "      <th>bearish_trend</th>\n",
       "      <th>group</th>\n",
       "      <th>month</th>\n",
       "      <th>day_of_year</th>\n",
       "      <th>weekday</th>\n",
       "      <th>is_holiday</th>\n",
       "      <th>time_idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>434.0</td>\n",
       "      <td>430.0</td>\n",
       "      <td>434.1</td>\n",
       "      <td>423.1</td>\n",
       "      <td>-0.70</td>\n",
       "      <td>4497.86</td>\n",
       "      <td>9313.2</td>\n",
       "      <td>3164.76</td>\n",
       "      <td>17148.94</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>January</td>\n",
       "      <td>1</td>\n",
       "      <td>Friday</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016-01-04</td>\n",
       "      <td>433.3</td>\n",
       "      <td>430.7</td>\n",
       "      <td>434.1</td>\n",
       "      <td>423.1</td>\n",
       "      <td>-0.70</td>\n",
       "      <td>4497.86</td>\n",
       "      <td>9313.2</td>\n",
       "      <td>3164.76</td>\n",
       "      <td>17148.94</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>January</td>\n",
       "      <td>4</td>\n",
       "      <td>Monday</td>\n",
       "      <td>No</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016-01-05</td>\n",
       "      <td>431.2</td>\n",
       "      <td>433.3</td>\n",
       "      <td>435.3</td>\n",
       "      <td>428.6</td>\n",
       "      <td>0.61</td>\n",
       "      <td>4497.86</td>\n",
       "      <td>9313.2</td>\n",
       "      <td>3164.76</td>\n",
       "      <td>17148.94</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>January</td>\n",
       "      <td>5</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>No</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016-01-06</td>\n",
       "      <td>430.8</td>\n",
       "      <td>431.2</td>\n",
       "      <td>435.3</td>\n",
       "      <td>428.9</td>\n",
       "      <td>-0.49</td>\n",
       "      <td>4484.18</td>\n",
       "      <td>9335.2</td>\n",
       "      <td>3178.01</td>\n",
       "      <td>17158.66</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>January</td>\n",
       "      <td>6</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>No</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016-01-07</td>\n",
       "      <td>457.0</td>\n",
       "      <td>430.8</td>\n",
       "      <td>432.1</td>\n",
       "      <td>425.0</td>\n",
       "      <td>-0.09</td>\n",
       "      <td>4443.98</td>\n",
       "      <td>9197.4</td>\n",
       "      <td>3139.32</td>\n",
       "      <td>16906.51</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>January</td>\n",
       "      <td>7</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>No</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2132</th>\n",
       "      <td>2024-03-05</td>\n",
       "      <td>63792.6</td>\n",
       "      <td>68273.1</td>\n",
       "      <td>68495.1</td>\n",
       "      <td>62746.8</td>\n",
       "      <td>8.13</td>\n",
       "      <td>18226.48</td>\n",
       "      <td>10069.8</td>\n",
       "      <td>4912.92</td>\n",
       "      <td>38989.83</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>March</td>\n",
       "      <td>65</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>No</td>\n",
       "      <td>2986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2133</th>\n",
       "      <td>2024-03-06</td>\n",
       "      <td>66080.4</td>\n",
       "      <td>63794.7</td>\n",
       "      <td>69063.1</td>\n",
       "      <td>60138.2</td>\n",
       "      <td>-6.56</td>\n",
       "      <td>17897.87</td>\n",
       "      <td>10117.1</td>\n",
       "      <td>4893.07</td>\n",
       "      <td>38585.19</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>March</td>\n",
       "      <td>66</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>No</td>\n",
       "      <td>2987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2134</th>\n",
       "      <td>2024-03-07</td>\n",
       "      <td>66855.3</td>\n",
       "      <td>66074.6</td>\n",
       "      <td>67604.9</td>\n",
       "      <td>62848.7</td>\n",
       "      <td>3.59</td>\n",
       "      <td>18017.57</td>\n",
       "      <td>10197.2</td>\n",
       "      <td>4915.49</td>\n",
       "      <td>38661.05</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>March</td>\n",
       "      <td>67</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>No</td>\n",
       "      <td>2988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2135</th>\n",
       "      <td>2024-03-08</td>\n",
       "      <td>68172.0</td>\n",
       "      <td>66854.4</td>\n",
       "      <td>67985.5</td>\n",
       "      <td>65602.6</td>\n",
       "      <td>1.17</td>\n",
       "      <td>18297.99</td>\n",
       "      <td>10319.6</td>\n",
       "      <td>4974.22</td>\n",
       "      <td>38791.35</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>March</td>\n",
       "      <td>68</td>\n",
       "      <td>Friday</td>\n",
       "      <td>No</td>\n",
       "      <td>2989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2136</th>\n",
       "      <td>2024-03-11</td>\n",
       "      <td>72099.1</td>\n",
       "      <td>68964.7</td>\n",
       "      <td>69905.3</td>\n",
       "      <td>68165.0</td>\n",
       "      <td>0.88</td>\n",
       "      <td>18018.45</td>\n",
       "      <td>10305.7</td>\n",
       "      <td>4961.11</td>\n",
       "      <td>38722.69</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>March</td>\n",
       "      <td>71</td>\n",
       "      <td>Monday</td>\n",
       "      <td>No</td>\n",
       "      <td>2992</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2137 rows × 84 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Date  exog_target     open      max      min   var  exog_Nasdaq  \\\n",
       "0    2016-01-01        434.0    430.0    434.1    423.1 -0.70      4497.86   \n",
       "1    2016-01-04        433.3    430.7    434.1    423.1 -0.70      4497.86   \n",
       "2    2016-01-05        431.2    433.3    435.3    428.6  0.61      4497.86   \n",
       "3    2016-01-06        430.8    431.2    435.3    428.9 -0.49      4484.18   \n",
       "4    2016-01-07        457.0    430.8    432.1    425.0 -0.09      4443.98   \n",
       "...         ...          ...      ...      ...      ...   ...          ...   \n",
       "2132 2024-03-05      63792.6  68273.1  68495.1  62746.8  8.13     18226.48   \n",
       "2133 2024-03-06      66080.4  63794.7  69063.1  60138.2 -6.56     17897.87   \n",
       "2134 2024-03-07      66855.3  66074.6  67604.9  62848.7  3.59     18017.57   \n",
       "2135 2024-03-08      68172.0  66854.4  67985.5  65602.6  1.17     18297.99   \n",
       "2136 2024-03-11      72099.1  68964.7  69905.3  68165.0  0.88     18018.45   \n",
       "\n",
       "      exog_IBEX35  exog_EUStoxx50  exog_DowJones  ...  bullish_atr  \\\n",
       "0          9313.2         3164.76       17148.94  ...            0   \n",
       "1          9313.2         3164.76       17148.94  ...            0   \n",
       "2          9313.2         3164.76       17148.94  ...            0   \n",
       "3          9335.2         3178.01       17158.66  ...            0   \n",
       "4          9197.4         3139.32       16906.51  ...            0   \n",
       "...           ...             ...            ...  ...          ...   \n",
       "2132      10069.8         4912.92       38989.83  ...            1   \n",
       "2133      10117.1         4893.07       38585.19  ...            1   \n",
       "2134      10197.2         4915.49       38661.05  ...            1   \n",
       "2135      10319.6         4974.22       38791.35  ...            1   \n",
       "2136      10305.7         4961.11       38722.69  ...            1   \n",
       "\n",
       "      bearish_atr  bullish_trend  bearish_trend  group    month  day_of_year  \\\n",
       "0               0              0              0      1  January            1   \n",
       "1               0              0              0      1  January            4   \n",
       "2               0              0              0      1  January            5   \n",
       "3               0              0              0      1  January            6   \n",
       "4               0              0              0      1  January            7   \n",
       "...           ...            ...            ...    ...      ...          ...   \n",
       "2132            0              1              0      1    March           65   \n",
       "2133            0              1              0      1    March           66   \n",
       "2134            0              1              0      1    March           67   \n",
       "2135            0              1              0      1    March           68   \n",
       "2136            0              1              0      1    March           71   \n",
       "\n",
       "        weekday  is_holiday  time_idx  \n",
       "0        Friday          No         0  \n",
       "1        Monday          No         3  \n",
       "2       Tuesday          No         4  \n",
       "3     Wednesday          No         5  \n",
       "4      Thursday          No         6  \n",
       "...         ...         ...       ...  \n",
       "2132    Tuesday          No      2986  \n",
       "2133  Wednesday          No      2987  \n",
       "2134   Thursday          No      2988  \n",
       "2135     Friday          No      2989  \n",
       "2136     Monday          No      2992  \n",
       "\n",
       "[2137 rows x 84 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45a04371",
   "metadata": {},
   "source": [
    "## DF FINL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da4fc650",
   "metadata": {},
   "source": [
    "<!-- ## TimeSeriesDataset -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afdbea69",
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "max_prediction_length = pred_len\n",
    "max_encoder_length = n_prev_len \n",
    "# Ajusta training_cutoff para reservar un rango más amplio para la validación\n",
    "# validation_size = 50  # ajusta según el tamaño deseado para el conjunto de validación\n",
    "training_cutoff = data[\"time_idx\"].max() - max_prediction_length #- validation_size\n",
    "\n",
    "train = TimeSeriesDataSet(\n",
    "    data[lambda x: x.time_idx <= training_cutoff],\n",
    "    time_idx=\"time_idx\",\n",
    "    target=\"target\",\n",
    "    group_ids=[group],\n",
    "    min_encoder_length=max_encoder_length,  # keep encoder length long (as it is in the validation set)\n",
    "    max_encoder_length=max_encoder_length,\n",
    "    # min_prediction_length=24,\n",
    "    max_prediction_length=max_prediction_length,\n",
    "    static_categoricals=[],\n",
    "    static_reals=[],\n",
    "    time_varying_known_categoricals=[\"month\", \"weekday\", \"day_of_year\", \"is_holiday\"],  # group of categorical variables can be treated as one variable\n",
    "    time_varying_known_reals=[\"Date\", \"time_idx\", 'FEDFUNDS'] + AAII_cols + PIB_cols,\n",
    "                                        \n",
    "    time_varying_unknown_categoricals=  bullish_cols +  bearish_cols,\n",
    "    time_varying_unknown_reals=[\n",
    "        \"target\",\n",
    "        \"open\",\n",
    "        \"max\",\n",
    "        \"min\",\n",
    "        # \"vol\",\n",
    "        \"var\",\n",
    "        \"MACD\",\n",
    "        \"Signal_Line\",\n",
    "    ]     + \n",
    "    lag_cols + \n",
    "    SMA_cols +\n",
    "    EMA_cols +\n",
    "    RSI_cols +\n",
    "    Bollinger_cols +\n",
    "    ATR_cols +\n",
    "    CCI_cols +\n",
    "    ROC_cols +\n",
    "    Stochastic_cols +\n",
    "    Williams_cols +\n",
    "    VIX_cols +\n",
    "    exog_ts +\n",
    "    target_smoothed_cols\n",
    "    ,\n",
    "    # lags={\"target\": list(range(1, 5))},\n",
    "    # target_normalizer=GroupNormalizer(\"standard\", groups=[group], transformation=\"softplus\"),\n",
    "    # use softplus and normalize by group\n",
    "    add_relative_time_idx=True,\n",
    "    add_target_scales=True,\n",
    "    allow_missing_timesteps=True,\n",
    "    # add_encoder_length=True,\n",
    "    categorical_encoders={\n",
    "        \"month\": pytorch_forecasting.data.encoders.NaNLabelEncoder(add_nan=True),\n",
    "        \"weekday\": pytorch_forecasting.data.encoders.NaNLabelEncoder(add_nan=True),\n",
    "        \"day_of_year\": pytorch_forecasting.data.encoders.NaNLabelEncoder(add_nan=True),\n",
    "    },\n",
    ")\n",
    "\n",
    "validation = TimeSeriesDataSet.from_dataset(train,  data, predict=True, stop_randomization=True)\n",
    "# test = TimeSeriesDataSet.from_dataset(training, test_data, predict=True, stop_randomization=True)\n",
    "\n",
    "# create dataloaders for model\n",
    "batch_size = 32  # set this between 32 to 128\n",
    "train_dataloader = train.to_dataloader(\n",
    "    train=True, batch_size=batch_size, num_workers=7, persistent_workers=True\n",
    ")\n",
    "val_dataloader = validation.to_dataloader(\n",
    "    train=False, batch_size=batch_size, num_workers=7, persistent_workers=True\n",
    ")\n",
    "# test_dataloader = test.to_dataloader(train=False, batch_size=batch_size, num_workers=11, persistent_workers=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1db5ef6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TimeSeriesDataSet[length=1](\n",
       "\ttime_idx='time_idx',\n",
       "\ttarget='target',\n",
       "\tgroup_ids=['group'],\n",
       "\tweight=None,\n",
       "\tmax_encoder_length=50,\n",
       "\tmin_encoder_length=50,\n",
       "\tmin_prediction_idx=0,\n",
       "\tmin_prediction_length=25,\n",
       "\tmax_prediction_length=25,\n",
       "\tstatic_categoricals=[],\n",
       "\tstatic_reals=['target_center', 'target_scale'],\n",
       "\ttime_varying_known_categoricals=['month', 'weekday', 'day_of_year', 'is_holiday'],\n",
       "\ttime_varying_known_reals=['Date', 'time_idx', 'FEDFUNDS', 'AAII_Bullish', 'AAII_Neutral', 'AAII_Bearish', 'PIB_USA', 'PIB_CHN', 'PIB_DEU', 'PIB_JPN', 'PIB_IND', 'PIB_BRA', 'PIB_CAN', 'relative_time_idx'],\n",
       "\ttime_varying_unknown_categoricals=['bullish_sma_50_200', 'bullish_rsi', 'bullish_bollinger', 'bullish_macd', 'bullish_atr', 'bullish_trend', 'bearish_sma_50_200', 'bearish_rsi', 'bearish_bollinger', 'bearish_macd', 'bearish_atr', 'bearish_trend'],\n",
       "\ttime_varying_unknown_reals=['target', 'open', 'max', 'min', 'var', 'MACD', 'Signal_Line', 'target_lag1', 'target_lag2', 'target_lag3', 'target_lag4', 'target_lag5', 'target_lag6', 'target_lag7', 'target_lag8', 'target_lag9', 'target_lag10', 'SMA_5', 'SMA_10', 'SMA_20', 'SMA_50', 'SMA_100', 'SMA_200', 'EMA_5', 'EMA_10', 'EMA_20', 'EMA_50', 'EMA_100', 'EMA_200', 'RSI_14', 'Bollinger_Upper_20', 'Bollinger_Lower_20', 'ATR_14', 'CCI_10', 'CCI_20', 'ROC_10', 'ROC_14', 'ROC_20', 'Stochastic_14_K', 'Stochastic_14_D', 'Williams_%R_14', 'VIX', 'EUVIX', 'exog_target', 'exog_Nasdaq', 'exog_IBEX35', 'exog_EUStoxx50', 'exog_DowJones', 'exog_S&P500', 'exog_USD_EUR', 'exog_GBP_USD', 'exog_USTech100', 'exog_S&P500Futures', 'target_smoothed_1'],\n",
       "\tvariable_groups={},\n",
       "\tconstant_fill_strategy={},\n",
       "\tallow_missing_timesteps=True,\n",
       "\tlags={},\n",
       "\tadd_relative_time_idx=True,\n",
       "\tadd_target_scales=True,\n",
       "\tadd_encoder_length=False,\n",
       "\ttarget_normalizer=EncoderNormalizer(\n",
       "\tmethod='standard',\n",
       "\tcenter=True,\n",
       "\tmax_length=None,\n",
       "\ttransformation='relu',\n",
       "\tmethod_kwargs={}\n",
       "),\n",
       "\tcategorical_encoders={'month': NaNLabelEncoder(add_nan=True, warn=True), 'weekday': NaNLabelEncoder(add_nan=True, warn=True), 'day_of_year': NaNLabelEncoder(add_nan=True, warn=True), '__group_id__group': NaNLabelEncoder(add_nan=False, warn=True), 'is_holiday': NaNLabelEncoder(add_nan=False, warn=True), 'bullish_sma_50_200': NaNLabelEncoder(add_nan=False, warn=True), 'bullish_rsi': NaNLabelEncoder(add_nan=False, warn=True), 'bullish_bollinger': NaNLabelEncoder(add_nan=False, warn=True), 'bullish_macd': NaNLabelEncoder(add_nan=False, warn=True), 'bullish_atr': NaNLabelEncoder(add_nan=False, warn=True), 'bullish_trend': NaNLabelEncoder(add_nan=False, warn=True), 'bearish_sma_50_200': NaNLabelEncoder(add_nan=False, warn=True), 'bearish_rsi': NaNLabelEncoder(add_nan=False, warn=True), 'bearish_bollinger': NaNLabelEncoder(add_nan=False, warn=True), 'bearish_macd': NaNLabelEncoder(add_nan=False, warn=True), 'bearish_atr': NaNLabelEncoder(add_nan=False, warn=True), 'bearish_trend': NaNLabelEncoder(add_nan=False, warn=True)},\n",
       "\tscalers={'target_center': StandardScaler(), 'target_scale': StandardScaler(), 'Date': StandardScaler(), 'time_idx': StandardScaler(), 'FEDFUNDS': StandardScaler(), 'AAII_Bullish': StandardScaler(), 'AAII_Neutral': StandardScaler(), 'AAII_Bearish': StandardScaler(), 'PIB_USA': StandardScaler(), 'PIB_CHN': StandardScaler(), 'PIB_DEU': StandardScaler(), 'PIB_JPN': StandardScaler(), 'PIB_IND': StandardScaler(), 'PIB_BRA': StandardScaler(), 'PIB_CAN': StandardScaler(), 'relative_time_idx': StandardScaler(), 'open': StandardScaler(), 'max': StandardScaler(), 'min': StandardScaler(), 'var': StandardScaler(), 'MACD': StandardScaler(), 'Signal_Line': StandardScaler(), 'target_lag1': StandardScaler(), 'target_lag2': StandardScaler(), 'target_lag3': StandardScaler(), 'target_lag4': StandardScaler(), 'target_lag5': StandardScaler(), 'target_lag6': StandardScaler(), 'target_lag7': StandardScaler(), 'target_lag8': StandardScaler(), 'target_lag9': StandardScaler(), 'target_lag10': StandardScaler(), 'SMA_5': StandardScaler(), 'SMA_10': StandardScaler(), 'SMA_20': StandardScaler(), 'SMA_50': StandardScaler(), 'SMA_100': StandardScaler(), 'SMA_200': StandardScaler(), 'EMA_5': StandardScaler(), 'EMA_10': StandardScaler(), 'EMA_20': StandardScaler(), 'EMA_50': StandardScaler(), 'EMA_100': StandardScaler(), 'EMA_200': StandardScaler(), 'RSI_14': StandardScaler(), 'Bollinger_Upper_20': StandardScaler(), 'Bollinger_Lower_20': StandardScaler(), 'ATR_14': StandardScaler(), 'CCI_10': StandardScaler(), 'CCI_20': StandardScaler(), 'ROC_10': StandardScaler(), 'ROC_14': StandardScaler(), 'ROC_20': StandardScaler(), 'Stochastic_14_K': StandardScaler(), 'Stochastic_14_D': StandardScaler(), 'Williams_%R_14': StandardScaler(), 'VIX': StandardScaler(), 'EUVIX': StandardScaler(), 'exog_target': StandardScaler(), 'exog_Nasdaq': StandardScaler(), 'exog_IBEX35': StandardScaler(), 'exog_EUStoxx50': StandardScaler(), 'exog_DowJones': StandardScaler(), 'exog_S&P500': StandardScaler(), 'exog_USD_EUR': StandardScaler(), 'exog_GBP_USD': StandardScaler(), 'exog_USTech100': StandardScaler(), 'exog_S&P500Futures': StandardScaler(), 'target_smoothed_1': StandardScaler()},\n",
       "\trandomize_length=None,\n",
       "\tpredict_mode=True\n",
       ")"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c2a24e8",
   "metadata": {},
   "source": [
    "<!-- \n",
    "# LEARNIG RATE FINDER -->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44fa807d",
   "metadata": {},
   "source": [
    "<!-- En primer lugar realizamos un estudio para hallar de forma aproximada el valor optimo de tasa de aprendizaje.  No es recomendable al 100% usar el valor sugerido directamente pues a veces no encuentra el mejor, sin embargo si que da un muy buen punto de partida por donde empezar a probar. Para ello usamos un modelo TFT cualquiera basico. -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54055c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if lr_finder:\n",
    "    res = get_best_lr(train, train_dataloader, val_dataloader, **tft_params)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "008a1fdd",
   "metadata": {},
   "source": [
    "<!-- # MODELLING -->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "927621bc",
   "metadata": {},
   "source": [
    "<!-- ## TRAIN MODEL -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "152ce290",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not grid_search:\n",
    "    # tft_params[\"learning_rate\"] = 0.01\n",
    "    tft, val_loss = tft_trainer(train, train_dataloader, val_dataloader, max_epochs=epochs, **tft_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f0f0114",
   "metadata": {},
   "source": [
    "<!-- ### EVAL MODEL -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba6ae28f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not grid_search:\n",
    "    preds = tft_predict(tft, val_dataloader)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54f4ad1d",
   "metadata": {},
   "source": [
    "<!-- ## GRID SEARCH -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45763d2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " -------------------------------------------------------- \n",
      " Probando combinación aleatoria 1/50: {'gradient_clip_val': 0.03, 'hidden_size': 32, 'dropout': 0.3, 'hidden_continuous_size': 64, 'attention_head_size': 8, 'learning_rate': 0.03, 'loss': MAE(), 'test_len': 100, 'pred_len': 25, 'n_prev_len': 50}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99: 100%|██████████| 32/32 [00:34<00:00,  0.94it/s, v_num=6, train_loss_step=578.0, val_loss=1.53e+4, train_loss_epoch=504.0]    "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99: 100%|██████████| 32/32 [00:34<00:00,  0.92it/s, v_num=6, train_loss_step=578.0, val_loss=1.53e+4, train_loss_epoch=504.0]\n",
      "Number of parameters in network: 697.7k\n",
      "Training time: 48m 54s\n",
      "Nueva mejor combinación encontrada: {'gradient_clip_val': 0.03, 'hidden_size': 32, 'dropout': 0.3, 'hidden_continuous_size': 64, 'attention_head_size': 8, 'learning_rate': 0.03, 'loss': MAE(), 'test_len': 100, 'pred_len': 25, 'n_prev_len': 50} con pérdida 15326.7666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " -------------------------------------------------------- \n",
      " Probando combinación aleatoria 2/50: {'gradient_clip_val': 0.05, 'hidden_size': 32, 'dropout': 0.1, 'hidden_continuous_size': 64, 'attention_head_size': 4, 'learning_rate': 0.01, 'loss': MAE(), 'test_len': 100, 'pred_len': 25, 'n_prev_len': 50}\n",
      "Epoch 99: 100%|██████████| 32/32 [00:44<00:00,  0.72it/s, v_num=11, train_loss_step=620.0, val_loss=1.41e+4, train_loss_epoch=617.0]    "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99: 100%|██████████| 32/32 [00:44<00:00,  0.71it/s, v_num=11, train_loss_step=620.0, val_loss=1.41e+4, train_loss_epoch=617.0]\n",
      "Number of parameters in network: 697.9k\n",
      "Training time: 66m 19s\n",
      "Nueva mejor combinación encontrada: {'gradient_clip_val': 0.05, 'hidden_size': 32, 'dropout': 0.1, 'hidden_continuous_size': 64, 'attention_head_size': 4, 'learning_rate': 0.01, 'loss': MAE(), 'test_len': 100, 'pred_len': 25, 'n_prev_len': 50} con pérdida 14126.9277\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " -------------------------------------------------------- \n",
      " Probando combinación aleatoria 3/50: {'gradient_clip_val': 0.05, 'hidden_size': 16, 'dropout': 0.1, 'hidden_continuous_size': 128, 'attention_head_size': 4, 'learning_rate': 0.01, 'loss': MAE(), 'test_len': 100, 'pred_len': 25, 'n_prev_len': 50}\n",
      "Epoch 99: 100%|██████████| 32/32 [00:49<00:00,  0.64it/s, v_num=16, train_loss_step=734.0, val_loss=1.5e+4, train_loss_epoch=691.0]     "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99: 100%|██████████| 32/32 [00:50<00:00,  0.64it/s, v_num=16, train_loss_step=734.0, val_loss=1.5e+4, train_loss_epoch=691.0]\n",
      "Number of parameters in network: 461.9k\n",
      "Training time: 77m 22s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " -------------------------------------------------------- \n",
      " Probando combinación aleatoria 4/50: {'gradient_clip_val': 0.05, 'hidden_size': 8, 'dropout': 0.3, 'hidden_continuous_size': 64, 'attention_head_size': 16, 'learning_rate': 0.005, 'loss': MAE(), 'test_len': 100, 'pred_len': 25, 'n_prev_len': 50}\n",
      "Epoch 99: 100%|██████████| 32/32 [00:49<00:00,  0.65it/s, v_num=21, train_loss_step=1.64e+3, val_loss=1.1e+4, train_loss_epoch=1.19e+3] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99: 100%|██████████| 32/32 [00:49<00:00,  0.64it/s, v_num=21, train_loss_step=1.64e+3, val_loss=1.1e+4, train_loss_epoch=1.19e+3]\n",
      "Number of parameters in network: 126.5k\n",
      "Training time: 78m 26s\n",
      "Nueva mejor combinación encontrada: {'gradient_clip_val': 0.05, 'hidden_size': 8, 'dropout': 0.3, 'hidden_continuous_size': 64, 'attention_head_size': 16, 'learning_rate': 0.005, 'loss': MAE(), 'test_len': 100, 'pred_len': 25, 'n_prev_len': 50} con pérdida 10985.5596\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " -------------------------------------------------------- \n",
      " Probando combinación aleatoria 5/50: {'gradient_clip_val': 0.03, 'hidden_size': 32, 'dropout': 0.2, 'hidden_continuous_size': 16, 'attention_head_size': 16, 'learning_rate': 0.03, 'loss': MAE(), 'test_len': 100, 'pred_len': 25, 'n_prev_len': 50}\n",
      "Epoch 99: 100%|██████████| 32/32 [01:05<00:00,  0.49it/s, v_num=26, train_loss_step=457.0, val_loss=1.48e+4, train_loss_epoch=499.0]    "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99: 100%|██████████| 32/32 [01:05<00:00,  0.49it/s, v_num=26, train_loss_step=457.0, val_loss=1.48e+4, train_loss_epoch=499.0]\n",
      "Number of parameters in network: 270.3k\n",
      "Training time: 101m 56s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " -------------------------------------------------------- \n",
      " Probando combinación aleatoria 6/50: {'gradient_clip_val': 0.05, 'hidden_size': 8, 'dropout': 0.3, 'hidden_continuous_size': 128, 'attention_head_size': 16, 'learning_rate': 0.03, 'loss': MAE(), 'test_len': 100, 'pred_len': 25, 'n_prev_len': 50}\n",
      "Epoch 12:  44%|████▍     | 14/32 [00:24<00:31,  0.57it/s, v_num=31, train_loss_step=1.93e+3, val_loss=9.2e+3, train_loss_epoch=1.42e+3] Number of parameters in network: 220.8k\n",
      "Training time: 12m 52s\n",
      "Nueva mejor combinación encontrada: {'gradient_clip_val': 0.05, 'hidden_size': 8, 'dropout': 0.3, 'hidden_continuous_size': 128, 'attention_head_size': 16, 'learning_rate': 0.03, 'loss': MAE(), 'test_len': 100, 'pred_len': 25, 'n_prev_len': 50} con pérdida 9199.2031\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " -------------------------------------------------------- \n",
      " Probando combinación aleatoria 7/50: {'gradient_clip_val': 0.03, 'hidden_size': 16, 'dropout': 0.1, 'hidden_continuous_size': 16, 'attention_head_size': 4, 'learning_rate': 0.01, 'loss': MAE(), 'test_len': 100, 'pred_len': 25, 'n_prev_len': 50}\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Only Tensors created explicitly by the user (graph leaves) support the deepcopy protocol at the moment",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[37], line 6\u001b[0m\n\u001b[0;32m      3\u001b[0m warnings\u001b[38;5;241m.\u001b[39mfilterwarnings(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Llamada a la función de búsqueda aleatoria\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m best_model, best_params, best_val_loss \u001b[38;5;241m=\u001b[39m \u001b[43mrandom_hyperparameter_search\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mval_dataloader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparam_grid\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_iterations\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[43msave_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m./plots/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mtarget_file\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m_gauss_multiexog_-\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mn_prev_len\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43md-\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mdate_start\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreplace\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m-\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m-\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mdate_end\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreplace\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m-\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     16\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcsv_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m./results/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mtarget_file\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m_gauss_multiexog-\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mn_prev_len\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43md-\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mdate_start\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m-\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mdate_end\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m.csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     17\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\nicov\\Documents\\Github\\QuantTrader-TFT\\tft_helper.py:333\u001b[0m, in \u001b[0;36mrandom_hyperparameter_search\u001b[1;34m(data, train, train_dataloader, val_dataloader, test, param_grid, n_iterations, max_epochs, save_dir, csv_file)\u001b[0m\n\u001b[0;32m    330\u001b[0m start_time \u001b[38;5;241m=\u001b[39m datetime\u001b[38;5;241m.\u001b[39mnow()\n\u001b[0;32m    332\u001b[0m \u001b[38;5;66;03m# Entrenar el modelo con la combinación actual de hiperparámetros\u001b[39;00m\n\u001b[1;32m--> 333\u001b[0m tft, val_loss \u001b[38;5;241m=\u001b[39m \u001b[43mtft_trainer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    334\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_epochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mparams\u001b[49m\n\u001b[0;32m    335\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    337\u001b[0m \u001b[38;5;66;03m# Medir el tiempo de finalización del entrenamiento\u001b[39;00m\n\u001b[0;32m    338\u001b[0m end_time \u001b[38;5;241m=\u001b[39m datetime\u001b[38;5;241m.\u001b[39mnow()\n",
      "File \u001b[1;32mc:\\Users\\nicov\\Documents\\Github\\QuantTrader-TFT\\tft_helper.py:110\u001b[0m, in \u001b[0;36mtft_trainer\u001b[1;34m(train, train_dataloader, val_dataloader, max_epochs, model_path, **kwargs)\u001b[0m\n\u001b[0;32m     92\u001b[0m \u001b[38;5;66;03m# Filtrar los callbacks que no son None\u001b[39;00m\n\u001b[0;32m     93\u001b[0m trainer \u001b[38;5;241m=\u001b[39m pl\u001b[38;5;241m.\u001b[39mTrainer(\n\u001b[0;32m     94\u001b[0m     max_epochs\u001b[38;5;241m=\u001b[39mmax_epochs,\n\u001b[0;32m     95\u001b[0m     accelerator\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgpu\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    107\u001b[0m     ],\n\u001b[0;32m    108\u001b[0m )\n\u001b[1;32m--> 110\u001b[0m tft \u001b[38;5;241m=\u001b[39m \u001b[43mTemporalFusionTransformer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_dataset\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    111\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    112\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlearning_rate\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.15\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    113\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhidden_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mhidden_size\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m16\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    114\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_head_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mattention_head_size\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    115\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdropout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdropout\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    116\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhidden_continuous_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mhidden_continuous_size\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m8\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    117\u001b[0m \u001b[43m    \u001b[49m\u001b[43mloss\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mloss\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mloss\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mQuantileLoss\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    118\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlog_interval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlog_interval\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m64\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    119\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43moptimizer\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mRanger\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    120\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreduce_on_plateau_patience\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mreduce_on_plateau_patience\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    121\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    123\u001b[0m trainer\u001b[38;5;241m.\u001b[39mfit(tft, train_dataloader, val_dataloader)\n\u001b[0;32m    125\u001b[0m \u001b[38;5;66;03m# Guardar el modelo entrenado\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\nicov\\anaconda3\\envs\\tft\\lib\\site-packages\\pytorch_forecasting\\models\\temporal_fusion_transformer\\__init__.py:356\u001b[0m, in \u001b[0;36mTemporalFusionTransformer.from_dataset\u001b[1;34m(cls, dataset, allowed_encoder_known_variable_names, **kwargs)\u001b[0m\n\u001b[0;32m    353\u001b[0m new_kwargs\u001b[38;5;241m.\u001b[39mupdate(\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mdeduce_default_output_parameters(dataset, kwargs, QuantileLoss()))\n\u001b[0;32m    355\u001b[0m \u001b[38;5;66;03m# create class and return\u001b[39;00m\n\u001b[1;32m--> 356\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_dataset\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    357\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallowed_encoder_known_variable_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallowed_encoder_known_variable_names\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mnew_kwargs\u001b[49m\n\u001b[0;32m    358\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\nicov\\anaconda3\\envs\\tft\\lib\\site-packages\\pytorch_forecasting\\models\\base_model.py:1672\u001b[0m, in \u001b[0;36mBaseModelWithCovariates.from_dataset\u001b[1;34m(cls, dataset, allowed_encoder_known_variable_names, **kwargs)\u001b[0m\n\u001b[0;32m   1652\u001b[0m new_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(\n\u001b[0;32m   1653\u001b[0m     static_categoricals\u001b[38;5;241m=\u001b[39mdataset\u001b[38;5;241m.\u001b[39mstatic_categoricals,\n\u001b[0;32m   1654\u001b[0m     time_varying_categoricals_encoder\u001b[38;5;241m=\u001b[39m[\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1669\u001b[0m     categorical_groups\u001b[38;5;241m=\u001b[39mdataset\u001b[38;5;241m.\u001b[39mvariable_groups,\n\u001b[0;32m   1670\u001b[0m )\n\u001b[0;32m   1671\u001b[0m new_kwargs\u001b[38;5;241m.\u001b[39mupdate(kwargs)\n\u001b[1;32m-> 1672\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mnew_kwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\nicov\\anaconda3\\envs\\tft\\lib\\site-packages\\pytorch_forecasting\\models\\base_model.py:1238\u001b[0m, in \u001b[0;36mBaseModel.from_dataset\u001b[1;34m(cls, dataset, **kwargs)\u001b[0m\n\u001b[0;32m   1236\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput_transformer\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m kwargs:\n\u001b[0;32m   1237\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput_transformer\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m dataset\u001b[38;5;241m.\u001b[39mtarget_normalizer\n\u001b[1;32m-> 1238\u001b[0m net \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1239\u001b[0m net\u001b[38;5;241m.\u001b[39mdataset_parameters \u001b[38;5;241m=\u001b[39m dataset\u001b[38;5;241m.\u001b[39mget_parameters()\n\u001b[0;32m   1240\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dataset\u001b[38;5;241m.\u001b[39mmulti_target:\n",
      "File \u001b[1;32mc:\\Users\\nicov\\anaconda3\\envs\\tft\\lib\\site-packages\\pytorch_forecasting\\models\\temporal_fusion_transformer\\__init__.py:140\u001b[0m, in \u001b[0;36mTemporalFusionTransformer.__init__\u001b[1;34m(self, hidden_size, lstm_layers, dropout, output_size, loss, attention_head_size, max_encoder_length, static_categoricals, static_reals, time_varying_categoricals_encoder, time_varying_categoricals_decoder, categorical_groups, time_varying_reals_encoder, time_varying_reals_decoder, x_reals, x_categoricals, hidden_continuous_size, hidden_continuous_sizes, embedding_sizes, embedding_paddings, embedding_labels, learning_rate, log_interval, log_val_interval, log_gradient_flow, reduce_on_plateau_patience, monotone_constaints, share_single_variable_networks, causal_attention, logging_metrics, **kwargs)\u001b[0m\n\u001b[0;32m    138\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m loss \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    139\u001b[0m     loss \u001b[38;5;241m=\u001b[39m QuantileLoss()\n\u001b[1;32m--> 140\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave_hyperparameters\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    141\u001b[0m \u001b[38;5;66;03m# store loss function separately as it is a module\u001b[39;00m\n\u001b[0;32m    142\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(loss, LightningMetric), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoss has to be a PyTorch Lightning `Metric`\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\nicov\\anaconda3\\envs\\tft\\lib\\site-packages\\lightning\\pytorch\\core\\mixins\\hparams_mixin.py:113\u001b[0m, in \u001b[0;36mHyperparametersMixin.save_hyperparameters\u001b[1;34m(self, ignore, frame, logger, *args)\u001b[0m\n\u001b[0;32m    111\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m current_frame:\n\u001b[0;32m    112\u001b[0m         frame \u001b[38;5;241m=\u001b[39m current_frame\u001b[38;5;241m.\u001b[39mf_back\n\u001b[1;32m--> 113\u001b[0m \u001b[43msave_hyperparameters\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframe\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mframe\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\nicov\\anaconda3\\envs\\tft\\lib\\site-packages\\lightning\\pytorch\\utilities\\parsing.py:205\u001b[0m, in \u001b[0;36msave_hyperparameters\u001b[1;34m(obj, ignore, frame, *args)\u001b[0m\n\u001b[0;32m    199\u001b[0m         rank_zero_warn(\n\u001b[0;32m    200\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAttribute \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m is an instance of `nn.Module` and is already saved during checkpointing.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    201\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m It is recommended to ignore them using `self.save_hyperparameters(ignore=[\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m])`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    202\u001b[0m         )\n\u001b[0;32m    204\u001b[0m \u001b[38;5;66;03m# make a deep copy so there are no other runtime changes reflected\u001b[39;00m\n\u001b[1;32m--> 205\u001b[0m obj\u001b[38;5;241m.\u001b[39m_hparams_initial \u001b[38;5;241m=\u001b[39m \u001b[43mcopy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdeepcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_hparams\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\nicov\\anaconda3\\envs\\tft\\lib\\copy.py:172\u001b[0m, in \u001b[0;36mdeepcopy\u001b[1;34m(x, memo, _nil)\u001b[0m\n\u001b[0;32m    170\u001b[0m                 y \u001b[38;5;241m=\u001b[39m x\n\u001b[0;32m    171\u001b[0m             \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 172\u001b[0m                 y \u001b[38;5;241m=\u001b[39m \u001b[43m_reconstruct\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mrv\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    174\u001b[0m \u001b[38;5;66;03m# If is its own copy, don't memoize.\u001b[39;00m\n\u001b[0;32m    175\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m x:\n",
      "File \u001b[1;32mc:\\Users\\nicov\\anaconda3\\envs\\tft\\lib\\copy.py:296\u001b[0m, in \u001b[0;36m_reconstruct\u001b[1;34m(x, memo, func, args, state, listiter, dictiter, deepcopy)\u001b[0m\n\u001b[0;32m    294\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m dictiter:\n\u001b[0;32m    295\u001b[0m         key \u001b[38;5;241m=\u001b[39m deepcopy(key, memo)\n\u001b[1;32m--> 296\u001b[0m         value \u001b[38;5;241m=\u001b[39m \u001b[43mdeepcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    297\u001b[0m         y[key] \u001b[38;5;241m=\u001b[39m value\n\u001b[0;32m    298\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\nicov\\anaconda3\\envs\\tft\\lib\\copy.py:172\u001b[0m, in \u001b[0;36mdeepcopy\u001b[1;34m(x, memo, _nil)\u001b[0m\n\u001b[0;32m    170\u001b[0m                 y \u001b[38;5;241m=\u001b[39m x\n\u001b[0;32m    171\u001b[0m             \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 172\u001b[0m                 y \u001b[38;5;241m=\u001b[39m \u001b[43m_reconstruct\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mrv\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    174\u001b[0m \u001b[38;5;66;03m# If is its own copy, don't memoize.\u001b[39;00m\n\u001b[0;32m    175\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m x:\n",
      "File \u001b[1;32mc:\\Users\\nicov\\anaconda3\\envs\\tft\\lib\\copy.py:270\u001b[0m, in \u001b[0;36m_reconstruct\u001b[1;34m(x, memo, func, args, state, listiter, dictiter, deepcopy)\u001b[0m\n\u001b[0;32m    268\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m state \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    269\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m deep:\n\u001b[1;32m--> 270\u001b[0m         state \u001b[38;5;241m=\u001b[39m \u001b[43mdeepcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    271\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(y, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__setstate__\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m    272\u001b[0m         y\u001b[38;5;241m.\u001b[39m__setstate__(state)\n",
      "File \u001b[1;32mc:\\Users\\nicov\\anaconda3\\envs\\tft\\lib\\copy.py:146\u001b[0m, in \u001b[0;36mdeepcopy\u001b[1;34m(x, memo, _nil)\u001b[0m\n\u001b[0;32m    144\u001b[0m copier \u001b[38;5;241m=\u001b[39m _deepcopy_dispatch\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;28mcls\u001b[39m)\n\u001b[0;32m    145\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m copier \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 146\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[43mcopier\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    147\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    148\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(\u001b[38;5;28mcls\u001b[39m, \u001b[38;5;28mtype\u001b[39m):\n",
      "File \u001b[1;32mc:\\Users\\nicov\\anaconda3\\envs\\tft\\lib\\copy.py:230\u001b[0m, in \u001b[0;36m_deepcopy_dict\u001b[1;34m(x, memo, deepcopy)\u001b[0m\n\u001b[0;32m    228\u001b[0m memo[\u001b[38;5;28mid\u001b[39m(x)] \u001b[38;5;241m=\u001b[39m y\n\u001b[0;32m    229\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m x\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m--> 230\u001b[0m     y[deepcopy(key, memo)] \u001b[38;5;241m=\u001b[39m \u001b[43mdeepcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    231\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m y\n",
      "File \u001b[1;32mc:\\Users\\nicov\\anaconda3\\envs\\tft\\lib\\copy.py:153\u001b[0m, in \u001b[0;36mdeepcopy\u001b[1;34m(x, memo, _nil)\u001b[0m\n\u001b[0;32m    151\u001b[0m copier \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(x, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__deepcopy__\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    152\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m copier \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 153\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[43mcopier\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmemo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    154\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    155\u001b[0m     reductor \u001b[38;5;241m=\u001b[39m dispatch_table\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;28mcls\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\nicov\\anaconda3\\envs\\tft\\lib\\site-packages\\torch\\_tensor.py:86\u001b[0m, in \u001b[0;36mTensor.__deepcopy__\u001b[1;34m(self, memo)\u001b[0m\n\u001b[0;32m     84\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(Tensor\u001b[38;5;241m.\u001b[39m__deepcopy__, (\u001b[38;5;28mself\u001b[39m,), \u001b[38;5;28mself\u001b[39m, memo)\n\u001b[0;32m     85\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_leaf:\n\u001b[1;32m---> 86\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m     87\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOnly Tensors created explicitly by the user \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     88\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(graph leaves) support the deepcopy protocol at the moment\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     89\u001b[0m     )\n\u001b[0;32m     90\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mid\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;129;01min\u001b[39;00m memo:\n\u001b[0;32m     91\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m memo[\u001b[38;5;28mid\u001b[39m(\u001b[38;5;28mself\u001b[39m)]\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Only Tensors created explicitly by the user (graph leaves) support the deepcopy protocol at the moment"
     ]
    }
   ],
   "source": [
    "if grid_search == \"random\":\n",
    "    # Suprime todos los warnings\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "    # Llamada a la función de búsqueda aleatoria\n",
    "    best_model, best_params, best_val_loss = random_hyperparameter_search(\n",
    "        data,\n",
    "        train,\n",
    "        train_dataloader,\n",
    "        val_dataloader,\n",
    "        test,\n",
    "        param_grid,\n",
    "        n_iterations=50,\n",
    "        max_epochs=epochs,\n",
    "        save_dir=f'./plots/{target_file}_gauss_multiexog_-{n_prev_len}d-{date_start.replace(\"-\",\"\")}-{date_end.replace(\"-\",\"\")}',\n",
    "        csv_file=f\"./results/{target_file}_gauss_multiexog-{n_prev_len}d-{date_start}-{date_end}.csv\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40e9473e",
   "metadata": {},
   "outputs": [],
   "source": [
    "if grid_search == \"exhaustive\":\n",
    "    \n",
    "    # Suprime todos los warnings \n",
    "\n",
    "    \n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "    \n",
    "    # Llamada a la función de búsqueda de hiperparámetros\n",
    "    best_model, best_params, best_val_loss = exhaustive_hyperparameter_search(\n",
    "        data, train, train_dataloader, val_dataloader, test, param_grid, max_epochs=1\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "tft",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
