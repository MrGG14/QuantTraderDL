{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "18f03e0a",
   "metadata": {},
   "source": [
    "# IMPORTS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5f98c2c",
   "metadata": {},
   "source": [
    "Por incompatibilidades entre librerias nos vemos obligados a hacer este workaround para que solucionar los problemas de dependencias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e43a3d70",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nicov\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pytorch_forecasting\\models\\base_model.py:30: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    }
   ],
   "source": [
    "import  scipy.signal.signaltools\n",
    "import numpy as np\n",
    "\n",
    "def _centered(arr, newsize):\n",
    "    # Return the center newsize portion of the array.\n",
    "    newsize = np.asarray(newsize)\n",
    "    currsize = np.array(arr.shape)\n",
    "    startind = (currsize - newsize) // 2\n",
    "    endind = startind + newsize\n",
    "    myslice = [slice(startind[k], endind[k]) for k in range(len(endind))]\n",
    "    return arr[tuple(myslice)]\n",
    "\n",
    "scipy.signal.signaltools._centered = _centered\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "# import os\n",
    "# import pickle\n",
    "import pytorch_forecasting\n",
    "from pytorch_forecasting.data import GroupNormalizer\n",
    "from pytorch_forecasting.models.temporal_fusion_transformer.tuning import optimize_hyperparameters\n",
    "from pytorch_forecasting import TemporalFusionTransformer, TimeSeriesDataSet\n",
    "from lightning.pytorch.callbacks import EarlyStopping, LearningRateMonitor\n",
    "import lightning.pytorch as pl\n",
    "from lightning.pytorch.loggers import TensorBoardLogger\n",
    "import torch\n",
    "from pytorch_forecasting.metrics import MAE, SMAPE, PoissonLoss, QuantileLoss, MAPE, MASE\n",
    "from lightning.pytorch.tuner import Tuner\n",
    "from  scipy.signal.signaltools import _centered\n",
    "from tft_helper import *\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "torch.backends.cudnn.benchmark = True # Enables cuDNN auto-tuner for faster runtime when input sizes are consistent\n",
    "\n",
    "basepath = os.path.abspath(\"\")  # script directory\n",
    "\n",
    "sys.path.insert(1, os.path.join(basepath, \"..\\\\\"))\n",
    "from datetime import datetime, timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "018de99c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install optuna==3.4.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdf5d2e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "82736cf5",
   "metadata": {},
   "source": [
    "# PARAMS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "62f8001a",
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "seq_len = 5 #sequence lenght: how many timesteps does a sequence have. For example a week could be considered a single sequence, therefore seq_len would be 5 as as the stock market opens 5 days a week.\n",
    "pred_len = seq_len * 5 # prediction lenght: How many timesteps does a prediction sequence have. For example if each prediction is a full week pred_len should be 5 as the stock market opens 5 days a week.\n",
    "n_prev_len = 100 # Number of previous timesteps to take for inference. \n",
    "n_preds = 5 # number of predictions with test data\n",
    "test_len = pred_len * n_preds  # Number of timesteps to use for test data.\n",
    "group = \"group\" # If a same model should predict different stores, indices etc specify how to group them. If theres only one time series the set group col to one full of the same value.\n",
    "n_lags = seq_len * 20  # Number of lags to use.\n",
    "loss = MAPE() # Loss function. \n",
    "epochs = 75 # Epochs to train the model.\n",
    "\n",
    "# Set ts date range\n",
    "date_start = '2010-01-04' #None #\"2023-06-01\"\n",
    "date_end = \"2024-7-29\"\n",
    "shift = 1 # How many times to shift values. Useful for using last indicator values (RSI, MACD...) for inference\n",
    "ma_periods = [ 5, 10, 20, 50, 100, 200] # Moving averages periods\n",
    "# cols_to_shift = [2:]\n",
    "\n",
    "# Set training config.\n",
    "lr_finder = False\n",
    "grid_search = \"random\"\n",
    "early_stop_callback = EarlyStopping(monitor=\"val_loss\", min_delta=1e-4, patience=10, verbose=False, mode=\"min\")\n",
    "lr_logger = LearningRateMonitor()  # log the learning rate\n",
    "# logger = TensorBoardLogger(\"lightning_logs\")  # logging results to a tensorboard\n",
    "\n",
    "# TFT training params.\n",
    "tft_params =  {\"gradient_clip_val\": 0.03, \"hidden_size\": 24, \"dropout\": 0.25, \"hidden_continuous_size\": 24, \"attention_head_size\": 4, \"learning_rate\": 0.01, \"loss\": loss, \"early_stop_callback\": early_stop_callback}\n",
    "\n",
    "\n",
    "PIB_relevant_countries = ['USA',\n",
    " 'CHN',\n",
    " 'EMU',\n",
    " 'DEU',\n",
    " 'FRA',\n",
    " 'GBR',\n",
    " 'JPN',\n",
    " 'IND',\n",
    " 'BRA',\n",
    " 'CAN',\n",
    " 'AUS',\n",
    " 'ITA',\n",
    " 'KOR',\n",
    " 'MEX',\n",
    " 'IDN',\n",
    " 'SAU',\n",
    " 'ZAF',\n",
    " 'TUR',\n",
    " 'ESP']\n",
    "\n",
    "# If grid search, set param grid.\n",
    "# param_grid = {\n",
    "#     \"gradient_clip_val\": [0.01, 0.03, 0.05],\n",
    "#     \"hidden_size\": [8, 16, 32],\n",
    "#     \"dropout\": [0.1, 0.25, 0.4],\n",
    "#     \"hidden_continuous_size\": [8, 16, 32],\n",
    "#     \"attention_head_size\": [2, 4, 8],\n",
    "#     \"learning_rate\": [0.005, 0.01, 0.03],\n",
    "#     \"loss\": [loss],\n",
    "#     \"test_len\": [test_len],\n",
    "#     \"pred_len\": [pred_len],\n",
    "#     \"n_prev_len\": [n_prev_len],\n",
    "# }\n",
    "\n",
    "param_grid = {\n",
    "    \"gradient_clip_val\": [0.01, 0.03, 0.05],\n",
    "    \"hidden_size\": [8, 16, 32],\n",
    "    \"dropout\": [0.1, 0.2, 0.3],\n",
    "    \"hidden_continuous_size\": [16, 64, 128],\n",
    "    \"attention_head_size\": [4,8,16],\n",
    "    \"learning_rate\": [0.005, 0.01, 0.03],\n",
    "    \"loss\": [loss],\n",
    "    \"test_len\": [test_len],\n",
    "    \"pred_len\": [pred_len],\n",
    "    \"n_prev_len\": [n_prev_len],\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8032f7e1",
   "metadata": {
    "id": "8032f7e1"
   },
   "source": [
    "# LOAD DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "888ad372",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset does not contain volume data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nicov\\AppData\\Local\\Temp\\ipykernel_19224\\2957053358.py:100: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df = df.ffill()\n"
     ]
    }
   ],
   "source": [
    "# Load time series data.\n",
    "df_nasdaq = load_file(file_name=\"Nasdaq\", path=\"./data/\", ftype=\"csv\")\n",
    "df_nasdaq = investing_preprocessing(df_nasdaq)\n",
    "df_nasdaq = df_nasdaq.rename(columns={\"target\": \"target_nasdaq\"})\n",
    "\n",
    "df_ibex35 = load_file(file_name=\"Datos históricos del IBEX 35\", path=\"./data/\", ftype=\"csv\")\n",
    "df_ibex35 = investing_preprocessing(df_ibex35)\n",
    "df_ibex35 = df_ibex35.rename(columns={\"target\": \"target_ibex35\"})\n",
    "\n",
    "df_syp500 = load_file(file_name=\"S&P500\", path=\"./data/\", ftype=\"csv\")\n",
    "df_syp500 = investing_preprocessing(df_syp500)\n",
    "\n",
    "df_eustoxx = load_file(file_name=\"EUStoxx50\", path=\"./data/\", ftype=\"csv\")\n",
    "df_eustoxx = investing_preprocessing(df_eustoxx)\n",
    "df_eustoxx = df_eustoxx.rename(columns={\"target\": \"target_eustoxx\"})\n",
    "\n",
    "# Usamos las series de Ibex35, EUSTOXX y Nasdaq como variables exogenas.\n",
    "df = df_ibex35.merge(df_nasdaq[['Date','target_nasdaq']], on='Date', how='left')\n",
    "df = df.merge(df_eustoxx[['Date','target_eustoxx']], on='Date', how='left')\n",
    "df = df.merge(df_syp500[['Date','target']], on='Date',how='left')\n",
    "\n",
    "# Cargamos los datos de la tasa de interes (Federal Funds Effective Rate) de estados unidos. https://fred.stlouisfed.org/series/FEDFUNDS\n",
    "FedFundsRate_df = load_file(file_name=\"FedFundsEffRate\", path=\"./data/\", ftype=\"csv\")\n",
    "FedFundsRate_df = FedFundsRate_df.rename(columns={\"DATE\": \"Date\"})\n",
    "FedFundsRate_df[\"Date\"] = pd.to_datetime(FedFundsRate_df[\"Date\"], format=\"%Y-%m-%d\")\n",
    "\n",
    "\n",
    "\n",
    "# Cargamos los datos del indice VIX. https://fred.stlouisfed.org/series/VIXCLS\n",
    "VIX_df = load_file(file_name=\"VIX_FRED\", path=\"./data/\", ftype=\"csv\")\n",
    "VIX_df = VIX_df.rename(columns={\"DATE\": \"Date\", \"VIXCLS\": \"VIX\"})\n",
    "VIX_df[\"Date\"] = pd.to_datetime(VIX_df[\"Date\"], format=\"%Y-%m-%d\")\n",
    "\n",
    "\n",
    "EUVIX_df = load_file(file_name=\"VSTOXX\", path=\"./data/\", ftype=\"csv\")\n",
    "EUVIX_df = EUVIX_df.rename(columns={\"target\": \"EUVIX\"})\n",
    "EUVIX_df = EUVIX_df[['Date', 'Price']]\n",
    "EUVIX_df[\"Date\"] = pd.to_datetime(EUVIX_df[\"Date\"], format=\"%m/%d/%Y\")\n",
    "EUVIX_df = EUVIX_df.rename(columns={\"Price\": \"EUVIX\"})\n",
    "\n",
    "\n",
    "# Cargamos los datos del PIB de los paises seleccionados\n",
    "worldPIB = load_file(file_name=\"worldPIBdata\", path=\"./data/\", ftype=\"xls\", skiprows=3)\n",
    "worldPIB = worldPIB.iloc[:, [0, 1] + list(range(50, len(worldPIB.columns)))]\n",
    "# df = df.iloc[1:, :]\n",
    "\n",
    "worldPIB=worldPIB.set_index('Country Code').loc[PIB_relevant_countries].T\n",
    "worldPIB = worldPIB.drop(index='Country Name')\n",
    "worldPIB.index.name = 'Date'\n",
    "worldPIB.reset_index(inplace=True)\n",
    "worldPIB[\"Date\"] = pd.to_datetime(worldPIB[\"Date\"], format=\"%Y\")\n",
    "worldPIB.columns.name = ''\n",
    "worldPIB = worldPIB.rename(columns={col: f\"PIB_{col}\" for col in worldPIB.columns[1:]})\n",
    "\n",
    "\n",
    "# Cargamos los datos de AAII (American Association of Individual Investors)\n",
    "AAII_df=load_file(file_name=\"IIAA_sentiment\", path=\"./data/\", ftype=\"xls\", usecols=range(0,4), **{\"skiprows\":3, \"skipfooter\":203})\n",
    "AAII_df[\"Date\"] = pd.to_datetime(AAII_df[\"Date\"], format=\"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "# Loas AAII stock sentiment historic data.\n",
    "AAII_df = AAII_df.rename(\n",
    "    columns={\n",
    "        \"Bullish\": \"AAII_Bullish\",\n",
    "        \"Neutral\": \"AAII_Neutral\",\n",
    "        \"Bearish\": \"AAII_Bearish\",})\n",
    "\n",
    "# Get selected time range for training\n",
    "if date_end:\n",
    "    df = df[df[\"Date\"] <= date_end]\n",
    "    AAII_df = AAII_df[AAII_df[\"Date\"] < date_end]\n",
    "\n",
    "\n",
    "if date_start:\n",
    "    df = df[df[\"Date\"] >= date_start]\n",
    "    AAII_df = AAII_df[AAII_df[\"Date\"] >= date_start]\n",
    "\n",
    "# Creo que es mas eficiente asi que eliminar con el merge\n",
    "\n",
    "AAII_df = AAII_df.reset_index(drop=True)\n",
    "\n",
    "# Merge dataframes to create training df.\n",
    "df = df.merge(AAII_df, on=\"Date\", how=\"left\")\n",
    "df = df.merge(FedFundsRate_df, on=\"Date\", how=\"left\")\n",
    "df = df.merge(VIX_df, on=\"Date\", how=\"left\")\n",
    "df = df.merge(EUVIX_df, on=\"Date\", how=\"left\")\n",
    "\n",
    "df['year'] = pd.to_datetime(df['Date']).dt.year\n",
    "\n",
    "# Crear una columna temporal 'year' en df2 convirtiendo 'date' a enteros\n",
    "# Extraer el año directamente de la columna 'Date' en worldPIB\n",
    "worldPIB['year'] = pd.to_datetime(worldPIB['Date']).dt.year\n",
    "\n",
    "# Realizar el merge usando la columna temporal 'year'\n",
    "df = pd.merge(df, worldPIB, on='year', how='left')\n",
    "df = df.rename(columns={'Date_x': 'Date'})\n",
    "\n",
    "# Eliminar la columna temporal 'year' después del merge\n",
    "df = df.drop(columns=['year'])\n",
    "\n",
    "df = df.ffill()\n",
    "df = df.bfill()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6cab5ddf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>EUVIX</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024-11-01</td>\n",
       "      <td>21.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024-10-31</td>\n",
       "      <td>21.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2024-10-30</td>\n",
       "      <td>19.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2024-10-29</td>\n",
       "      <td>18.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2024-10-28</td>\n",
       "      <td>18.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3018</th>\n",
       "      <td>2013-01-07</td>\n",
       "      <td>16.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3019</th>\n",
       "      <td>2013-01-04</td>\n",
       "      <td>16.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3020</th>\n",
       "      <td>2013-01-03</td>\n",
       "      <td>17.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3021</th>\n",
       "      <td>2013-01-02</td>\n",
       "      <td>18.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3022</th>\n",
       "      <td>2012-12-28</td>\n",
       "      <td>21.35</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3023 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Date  EUVIX\n",
       "0    2024-11-01  21.09\n",
       "1    2024-10-31  21.73\n",
       "2    2024-10-30  19.93\n",
       "3    2024-10-29  18.99\n",
       "4    2024-10-28  18.66\n",
       "...         ...    ...\n",
       "3018 2013-01-07  16.82\n",
       "3019 2013-01-04  16.07\n",
       "3020 2013-01-03  17.54\n",
       "3021 2013-01-02  18.36\n",
       "3022 2012-12-28  21.35\n",
       "\n",
       "[3023 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EUVIX_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7ba96331",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>target_ibex35</th>\n",
       "      <th>open</th>\n",
       "      <th>max</th>\n",
       "      <th>min</th>\n",
       "      <th>vol</th>\n",
       "      <th>var</th>\n",
       "      <th>target_nasdaq</th>\n",
       "      <th>target_eustoxx</th>\n",
       "      <th>target</th>\n",
       "      <th>...</th>\n",
       "      <th>PIB_CAN</th>\n",
       "      <th>PIB_AUS</th>\n",
       "      <th>PIB_ITA</th>\n",
       "      <th>PIB_KOR</th>\n",
       "      <th>PIB_MEX</th>\n",
       "      <th>PIB_IDN</th>\n",
       "      <th>PIB_SAU</th>\n",
       "      <th>PIB_ZAF</th>\n",
       "      <th>PIB_TUR</th>\n",
       "      <th>PIB_ESP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2010-01-04</td>\n",
       "      <td>12145.1</td>\n",
       "      <td>11986.5</td>\n",
       "      <td>12145.1</td>\n",
       "      <td>11986.1</td>\n",
       "      <td>184130000.0</td>\n",
       "      <td>1.72</td>\n",
       "      <td>1886.70</td>\n",
       "      <td>2324.48</td>\n",
       "      <td>1133.00</td>\n",
       "      <td>...</td>\n",
       "      <td>3.090806</td>\n",
       "      <td>2.226538</td>\n",
       "      <td>1.713296</td>\n",
       "      <td>6.804825</td>\n",
       "      <td>4.971335</td>\n",
       "      <td>6.223854</td>\n",
       "      <td>5.039508</td>\n",
       "      <td>3.039733</td>\n",
       "      <td>8.427104</td>\n",
       "      <td>0.162920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2010-01-05</td>\n",
       "      <td>12204.4</td>\n",
       "      <td>12141.8</td>\n",
       "      <td>12240.5</td>\n",
       "      <td>12139.8</td>\n",
       "      <td>238430000.0</td>\n",
       "      <td>0.49</td>\n",
       "      <td>1888.43</td>\n",
       "      <td>2324.48</td>\n",
       "      <td>1136.50</td>\n",
       "      <td>...</td>\n",
       "      <td>3.090806</td>\n",
       "      <td>2.226538</td>\n",
       "      <td>1.713296</td>\n",
       "      <td>6.804825</td>\n",
       "      <td>4.971335</td>\n",
       "      <td>6.223854</td>\n",
       "      <td>5.039508</td>\n",
       "      <td>3.039733</td>\n",
       "      <td>8.427104</td>\n",
       "      <td>0.162920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2010-01-06</td>\n",
       "      <td>12222.5</td>\n",
       "      <td>12216.4</td>\n",
       "      <td>12230.7</td>\n",
       "      <td>12147.6</td>\n",
       "      <td>123740000.0</td>\n",
       "      <td>0.15</td>\n",
       "      <td>1878.42</td>\n",
       "      <td>2324.48</td>\n",
       "      <td>1137.10</td>\n",
       "      <td>...</td>\n",
       "      <td>3.090806</td>\n",
       "      <td>2.226538</td>\n",
       "      <td>1.713296</td>\n",
       "      <td>6.804825</td>\n",
       "      <td>4.971335</td>\n",
       "      <td>6.223854</td>\n",
       "      <td>5.039508</td>\n",
       "      <td>3.039733</td>\n",
       "      <td>8.427104</td>\n",
       "      <td>0.162920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2010-01-07</td>\n",
       "      <td>12166.3</td>\n",
       "      <td>12163.0</td>\n",
       "      <td>12199.7</td>\n",
       "      <td>12079.1</td>\n",
       "      <td>192310000.0</td>\n",
       "      <td>-0.46</td>\n",
       "      <td>1876.72</td>\n",
       "      <td>2324.48</td>\n",
       "      <td>1141.70</td>\n",
       "      <td>...</td>\n",
       "      <td>3.090806</td>\n",
       "      <td>2.226538</td>\n",
       "      <td>1.713296</td>\n",
       "      <td>6.804825</td>\n",
       "      <td>4.971335</td>\n",
       "      <td>6.223854</td>\n",
       "      <td>5.039508</td>\n",
       "      <td>3.039733</td>\n",
       "      <td>8.427104</td>\n",
       "      <td>0.162920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2010-01-08</td>\n",
       "      <td>12163.0</td>\n",
       "      <td>12218.0</td>\n",
       "      <td>12232.2</td>\n",
       "      <td>12079.9</td>\n",
       "      <td>213110000.0</td>\n",
       "      <td>-0.03</td>\n",
       "      <td>1892.59</td>\n",
       "      <td>2324.48</td>\n",
       "      <td>1145.00</td>\n",
       "      <td>...</td>\n",
       "      <td>3.090806</td>\n",
       "      <td>2.226538</td>\n",
       "      <td>1.713296</td>\n",
       "      <td>6.804825</td>\n",
       "      <td>4.971335</td>\n",
       "      <td>6.223854</td>\n",
       "      <td>5.039508</td>\n",
       "      <td>3.039733</td>\n",
       "      <td>8.427104</td>\n",
       "      <td>0.162920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3728</th>\n",
       "      <td>2024-07-23</td>\n",
       "      <td>11212.7</td>\n",
       "      <td>11154.3</td>\n",
       "      <td>11221.8</td>\n",
       "      <td>11097.5</td>\n",
       "      <td>101470000.0</td>\n",
       "      <td>0.62</td>\n",
       "      <td>19754.34</td>\n",
       "      <td>4916.80</td>\n",
       "      <td>5555.74</td>\n",
       "      <td>...</td>\n",
       "      <td>1.065994</td>\n",
       "      <td>3.016988</td>\n",
       "      <td>0.920692</td>\n",
       "      <td>1.356733</td>\n",
       "      <td>3.228737</td>\n",
       "      <td>5.048106</td>\n",
       "      <td>-0.754915</td>\n",
       "      <td>0.601662</td>\n",
       "      <td>4.516867</td>\n",
       "      <td>2.503294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3729</th>\n",
       "      <td>2024-07-24</td>\n",
       "      <td>11210.1</td>\n",
       "      <td>11170.8</td>\n",
       "      <td>11245.5</td>\n",
       "      <td>11154.4</td>\n",
       "      <td>128810000.0</td>\n",
       "      <td>-0.02</td>\n",
       "      <td>19032.39</td>\n",
       "      <td>4861.87</td>\n",
       "      <td>5427.13</td>\n",
       "      <td>...</td>\n",
       "      <td>1.065994</td>\n",
       "      <td>3.016988</td>\n",
       "      <td>0.920692</td>\n",
       "      <td>1.356733</td>\n",
       "      <td>3.228737</td>\n",
       "      <td>5.048106</td>\n",
       "      <td>-0.754915</td>\n",
       "      <td>0.601662</td>\n",
       "      <td>4.516867</td>\n",
       "      <td>2.503294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3730</th>\n",
       "      <td>2024-07-25</td>\n",
       "      <td>11145.6</td>\n",
       "      <td>11132.7</td>\n",
       "      <td>11158.1</td>\n",
       "      <td>11012.0</td>\n",
       "      <td>120030000.0</td>\n",
       "      <td>-0.58</td>\n",
       "      <td>18830.59</td>\n",
       "      <td>4811.28</td>\n",
       "      <td>5399.22</td>\n",
       "      <td>...</td>\n",
       "      <td>1.065994</td>\n",
       "      <td>3.016988</td>\n",
       "      <td>0.920692</td>\n",
       "      <td>1.356733</td>\n",
       "      <td>3.228737</td>\n",
       "      <td>5.048106</td>\n",
       "      <td>-0.754915</td>\n",
       "      <td>0.601662</td>\n",
       "      <td>4.516867</td>\n",
       "      <td>2.503294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3731</th>\n",
       "      <td>2024-07-26</td>\n",
       "      <td>11165.9</td>\n",
       "      <td>11102.5</td>\n",
       "      <td>11177.6</td>\n",
       "      <td>11068.7</td>\n",
       "      <td>86560000.0</td>\n",
       "      <td>0.18</td>\n",
       "      <td>19023.66</td>\n",
       "      <td>4862.50</td>\n",
       "      <td>5459.10</td>\n",
       "      <td>...</td>\n",
       "      <td>1.065994</td>\n",
       "      <td>3.016988</td>\n",
       "      <td>0.920692</td>\n",
       "      <td>1.356733</td>\n",
       "      <td>3.228737</td>\n",
       "      <td>5.048106</td>\n",
       "      <td>-0.754915</td>\n",
       "      <td>0.601662</td>\n",
       "      <td>4.516867</td>\n",
       "      <td>2.503294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3732</th>\n",
       "      <td>2024-07-29</td>\n",
       "      <td>11117.8</td>\n",
       "      <td>11224.4</td>\n",
       "      <td>11254.2</td>\n",
       "      <td>11089.7</td>\n",
       "      <td>76500000.0</td>\n",
       "      <td>-0.43</td>\n",
       "      <td>19059.49</td>\n",
       "      <td>4815.39</td>\n",
       "      <td>5463.54</td>\n",
       "      <td>...</td>\n",
       "      <td>1.065994</td>\n",
       "      <td>3.016988</td>\n",
       "      <td>0.920692</td>\n",
       "      <td>1.356733</td>\n",
       "      <td>3.228737</td>\n",
       "      <td>5.048106</td>\n",
       "      <td>-0.754915</td>\n",
       "      <td>0.601662</td>\n",
       "      <td>4.516867</td>\n",
       "      <td>2.503294</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3733 rows × 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Date  target_ibex35     open      max      min          vol   var  \\\n",
       "0    2010-01-04        12145.1  11986.5  12145.1  11986.1  184130000.0  1.72   \n",
       "1    2010-01-05        12204.4  12141.8  12240.5  12139.8  238430000.0  0.49   \n",
       "2    2010-01-06        12222.5  12216.4  12230.7  12147.6  123740000.0  0.15   \n",
       "3    2010-01-07        12166.3  12163.0  12199.7  12079.1  192310000.0 -0.46   \n",
       "4    2010-01-08        12163.0  12218.0  12232.2  12079.9  213110000.0 -0.03   \n",
       "...         ...            ...      ...      ...      ...          ...   ...   \n",
       "3728 2024-07-23        11212.7  11154.3  11221.8  11097.5  101470000.0  0.62   \n",
       "3729 2024-07-24        11210.1  11170.8  11245.5  11154.4  128810000.0 -0.02   \n",
       "3730 2024-07-25        11145.6  11132.7  11158.1  11012.0  120030000.0 -0.58   \n",
       "3731 2024-07-26        11165.9  11102.5  11177.6  11068.7   86560000.0  0.18   \n",
       "3732 2024-07-29        11117.8  11224.4  11254.2  11089.7   76500000.0 -0.43   \n",
       "\n",
       "      target_nasdaq  target_eustoxx   target  ...   PIB_CAN   PIB_AUS  \\\n",
       "0           1886.70         2324.48  1133.00  ...  3.090806  2.226538   \n",
       "1           1888.43         2324.48  1136.50  ...  3.090806  2.226538   \n",
       "2           1878.42         2324.48  1137.10  ...  3.090806  2.226538   \n",
       "3           1876.72         2324.48  1141.70  ...  3.090806  2.226538   \n",
       "4           1892.59         2324.48  1145.00  ...  3.090806  2.226538   \n",
       "...             ...             ...      ...  ...       ...       ...   \n",
       "3728       19754.34         4916.80  5555.74  ...  1.065994  3.016988   \n",
       "3729       19032.39         4861.87  5427.13  ...  1.065994  3.016988   \n",
       "3730       18830.59         4811.28  5399.22  ...  1.065994  3.016988   \n",
       "3731       19023.66         4862.50  5459.10  ...  1.065994  3.016988   \n",
       "3732       19059.49         4815.39  5463.54  ...  1.065994  3.016988   \n",
       "\n",
       "       PIB_ITA   PIB_KOR   PIB_MEX   PIB_IDN   PIB_SAU   PIB_ZAF   PIB_TUR  \\\n",
       "0     1.713296  6.804825  4.971335  6.223854  5.039508  3.039733  8.427104   \n",
       "1     1.713296  6.804825  4.971335  6.223854  5.039508  3.039733  8.427104   \n",
       "2     1.713296  6.804825  4.971335  6.223854  5.039508  3.039733  8.427104   \n",
       "3     1.713296  6.804825  4.971335  6.223854  5.039508  3.039733  8.427104   \n",
       "4     1.713296  6.804825  4.971335  6.223854  5.039508  3.039733  8.427104   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "3728  0.920692  1.356733  3.228737  5.048106 -0.754915  0.601662  4.516867   \n",
       "3729  0.920692  1.356733  3.228737  5.048106 -0.754915  0.601662  4.516867   \n",
       "3730  0.920692  1.356733  3.228737  5.048106 -0.754915  0.601662  4.516867   \n",
       "3731  0.920692  1.356733  3.228737  5.048106 -0.754915  0.601662  4.516867   \n",
       "3732  0.920692  1.356733  3.228737  5.048106 -0.754915  0.601662  4.516867   \n",
       "\n",
       "       PIB_ESP  \n",
       "0     0.162920  \n",
       "1     0.162920  \n",
       "2     0.162920  \n",
       "3     0.162920  \n",
       "4     0.162920  \n",
       "...        ...  \n",
       "3728  2.503294  \n",
       "3729  2.503294  \n",
       "3730  2.503294  \n",
       "3731  2.503294  \n",
       "3732  2.503294  \n",
       "\n",
       "[3733 rows x 36 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56b5f849",
   "metadata": {},
   "source": [
    "## ADD INDICATORS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ed78615b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# añadimos lags\n",
    "lags = buildLaggedFeatures(df, n_lags, [\"target\"])\n",
    "df = pd.concat([df, lags], axis=1)\n",
    "\n",
    "for i in ma_periods:\n",
    "    df = add_sma(df, period=i)\n",
    "    df = add_ema(df, period=i)\n",
    "\n",
    "df = add_rsi(df)\n",
    "df = add_bollinger_bands(df)\n",
    "df = add_macd(df)\n",
    "df = add_atr(df)\n",
    "\n",
    "# Agregar CCI con diferentes períodos\n",
    "for i in [10,20]:\n",
    "    df = add_cci(df, period=i)\n",
    "\n",
    "# Agregar ROC con diferentes períodos\n",
    "for i in [10, 14, 20]:\n",
    "    df = add_roc(df, period=i)\n",
    "\n",
    "# Agregar Stochastic Oscillator con diferentes períodos\n",
    "df = add_stochastic(df)\n",
    "\n",
    "# Agregar Williams %R con diferentes períodos\n",
    "df = add_williams_r(df)\n",
    "\n",
    "# Suponiendo que ya has agregado los indicadores a df\n",
    "\n",
    "# Crear variables binarias para identificar tendencias\n",
    "# 1. Tendencia alcista/bajista usando medias móviles\n",
    "df['bullish_sma_50_200'] = (df['SMA_50'] > df['SMA_200']).astype(int)  # 1 si la SMA de 50 > SMA de 200\n",
    "df['bearish_sma_50_200'] = (df['SMA_50'] < df['SMA_200']).astype(int)  # 1 si la SMA de 50 < SMA de 200\n",
    "\n",
    "# 2. Tendencia alcista/bajista usando RSI\n",
    "df['bullish_rsi'] = (df['RSI_14'] < 30).astype(int)  # 1 si RSI es menor que 30 (sobreventa)\n",
    "df['bearish_rsi'] = (df['RSI_14'] > 70).astype(int)  # 1 si RSI es mayor que 70 (sobrecompra)\n",
    "\n",
    "# 3. Tendencia alcista/bajista usando Bandas de Bollinger\n",
    "df['bullish_bollinger'] = (df['target'] < df['Bollinger_Lower_20']).astype(int)  # 1 si el precio está por debajo de la banda inferior\n",
    "df['bearish_bollinger'] = (df['target'] > df['Bollinger_Upper_20']).astype(int)  # 1 si el precio está por encima de la banda superior\n",
    "\n",
    "# 4. Tendencia alcista/bajista usando MACD\n",
    "df['bullish_macd'] = (df['MACD'] > df['Signal_Line']).astype(int)  # 1 si MACD es mayor que la señal\n",
    "df['bearish_macd'] = (df['MACD'] < df['Signal_Line']).astype(int)  # 1 si MACD es menor que la señal\n",
    "\n",
    "# 5. Tendencia alcista/bajista usando ATR\n",
    "df['bullish_atr'] = (df['ATR_14'] > df['ATR_14'].rolling(window=14).mean()).astype(int)  # 1 si ATR actual es mayor que la media\n",
    "df['bearish_atr'] = (df['ATR_14'] < df['ATR_14'].rolling(window=14).mean()).astype(int)  # 1 si ATR actual es menor que la media\n",
    "\n",
    "# Ejemplo de combinación de señales para una tendencia general\n",
    "df['bullish_trend'] = ((df['bullish_sma_50_200'] + df['bullish_rsi'] + \n",
    "                        df['bullish_bollinger'] + df['bullish_macd'] + \n",
    "                        df['bullish_atr']) > 2).astype(int)\n",
    "\n",
    "df['bearish_trend'] = ((df['bearish_sma_50_200'] + df['bearish_rsi'] + \n",
    "                        df['bearish_bollinger'] + df['bearish_macd'] + \n",
    "                        df['bearish_atr']) >= 3).astype(int)\n",
    "\n",
    "binary_columns = [\n",
    "    'bullish_sma_50_200', 'bearish_sma_50_200', \n",
    "    'bullish_rsi', 'bearish_rsi', \n",
    "    'bullish_bollinger', 'bearish_bollinger', \n",
    "    'bullish_macd', 'bearish_macd', \n",
    "    'bullish_atr', 'bearish_atr', \n",
    "    'bullish_trend', 'bearish_trend'\n",
    "]\n",
    "\n",
    "# Convertir cada columna binaria a string\n",
    "for col in binary_columns:\n",
    "    df[col] = df[col].astype(str)\n",
    "\n",
    "# Agregar Parabolic SAR (sin período, pero podrías ajustar los factores de aceleración)\n",
    "# data = add_parabolic_sar(data)\n",
    "\n",
    "# Agregar Ichimoku Cloud (no requiere período)\n",
    "# df = add_ichimoku(df)\n",
    "\n",
    "# Calculate ATR (Average True Range)\n",
    "\n",
    "# df[\"ATR\"] = ta.ATR(df[\"max\"], df[\"min\"], df[\"close\"], timeperiod=14)\n",
    "\n",
    "# Calculate ADX (Average Directional Index)\n",
    "# df[\"ADX\"] = ta.ADX(df[\"max\"], df[\"min\"], df[\"close\"], timeperiod=14)\n",
    "\n",
    "\n",
    "# # Calculate CCI (Commodity Channel Index)\n",
    "# df[\"CCI\"] = ta.CCI(df[\"max\"], df[\"min\"], df[\"close\"], timeperiod=14)\n",
    "\n",
    "# # Calculate OBV (On-Balance Volume)\n",
    "# df[\"OBV\"] = ta.OBV(df[\"close\"], df[\"vol\"])\n",
    "\n",
    "# # Calculate Stochastic Oscillator (SlowK, SlowD)\n",
    "# df[\"SlowK\"], df[\"SlowD\"] = ta.STOCH(df[\"max\"], df[\"min\"], df[\"close\"], fastk_period=14, slowk_period=3, slowk_matype=0, slowd_period=3, slowd_matype=0)\n",
    "\n",
    "# df[\"WilliamsR\"] = ta.WILLR(df[\"max\"], df[\"min\"], df[\"close\"], timeperiod=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8103608c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>target_ibex35</th>\n",
       "      <th>open</th>\n",
       "      <th>max</th>\n",
       "      <th>min</th>\n",
       "      <th>vol</th>\n",
       "      <th>var</th>\n",
       "      <th>target_nasdaq</th>\n",
       "      <th>target_eustoxx</th>\n",
       "      <th>target</th>\n",
       "      <th>...</th>\n",
       "      <th>bullish_rsi</th>\n",
       "      <th>bearish_rsi</th>\n",
       "      <th>bullish_bollinger</th>\n",
       "      <th>bearish_bollinger</th>\n",
       "      <th>bullish_macd</th>\n",
       "      <th>bearish_macd</th>\n",
       "      <th>bullish_atr</th>\n",
       "      <th>bearish_atr</th>\n",
       "      <th>bullish_trend</th>\n",
       "      <th>bearish_trend</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2010-01-04</td>\n",
       "      <td>12145.1</td>\n",
       "      <td>11986.5</td>\n",
       "      <td>12145.1</td>\n",
       "      <td>11986.1</td>\n",
       "      <td>184130000.0</td>\n",
       "      <td>1.72</td>\n",
       "      <td>1886.70</td>\n",
       "      <td>2324.48</td>\n",
       "      <td>1133.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2010-01-05</td>\n",
       "      <td>12204.4</td>\n",
       "      <td>12141.8</td>\n",
       "      <td>12240.5</td>\n",
       "      <td>12139.8</td>\n",
       "      <td>238430000.0</td>\n",
       "      <td>0.49</td>\n",
       "      <td>1888.43</td>\n",
       "      <td>2324.48</td>\n",
       "      <td>1136.50</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2010-01-06</td>\n",
       "      <td>12222.5</td>\n",
       "      <td>12216.4</td>\n",
       "      <td>12230.7</td>\n",
       "      <td>12147.6</td>\n",
       "      <td>123740000.0</td>\n",
       "      <td>0.15</td>\n",
       "      <td>1878.42</td>\n",
       "      <td>2324.48</td>\n",
       "      <td>1137.10</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2010-01-07</td>\n",
       "      <td>12166.3</td>\n",
       "      <td>12163.0</td>\n",
       "      <td>12199.7</td>\n",
       "      <td>12079.1</td>\n",
       "      <td>192310000.0</td>\n",
       "      <td>-0.46</td>\n",
       "      <td>1876.72</td>\n",
       "      <td>2324.48</td>\n",
       "      <td>1141.70</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2010-01-08</td>\n",
       "      <td>12163.0</td>\n",
       "      <td>12218.0</td>\n",
       "      <td>12232.2</td>\n",
       "      <td>12079.9</td>\n",
       "      <td>213110000.0</td>\n",
       "      <td>-0.03</td>\n",
       "      <td>1892.59</td>\n",
       "      <td>2324.48</td>\n",
       "      <td>1145.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3728</th>\n",
       "      <td>2024-07-23</td>\n",
       "      <td>11212.7</td>\n",
       "      <td>11154.3</td>\n",
       "      <td>11221.8</td>\n",
       "      <td>11097.5</td>\n",
       "      <td>101470000.0</td>\n",
       "      <td>0.62</td>\n",
       "      <td>19754.34</td>\n",
       "      <td>4916.80</td>\n",
       "      <td>5555.74</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3729</th>\n",
       "      <td>2024-07-24</td>\n",
       "      <td>11210.1</td>\n",
       "      <td>11170.8</td>\n",
       "      <td>11245.5</td>\n",
       "      <td>11154.4</td>\n",
       "      <td>128810000.0</td>\n",
       "      <td>-0.02</td>\n",
       "      <td>19032.39</td>\n",
       "      <td>4861.87</td>\n",
       "      <td>5427.13</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3730</th>\n",
       "      <td>2024-07-25</td>\n",
       "      <td>11145.6</td>\n",
       "      <td>11132.7</td>\n",
       "      <td>11158.1</td>\n",
       "      <td>11012.0</td>\n",
       "      <td>120030000.0</td>\n",
       "      <td>-0.58</td>\n",
       "      <td>18830.59</td>\n",
       "      <td>4811.28</td>\n",
       "      <td>5399.22</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3731</th>\n",
       "      <td>2024-07-26</td>\n",
       "      <td>11165.9</td>\n",
       "      <td>11102.5</td>\n",
       "      <td>11177.6</td>\n",
       "      <td>11068.7</td>\n",
       "      <td>86560000.0</td>\n",
       "      <td>0.18</td>\n",
       "      <td>19023.66</td>\n",
       "      <td>4862.50</td>\n",
       "      <td>5459.10</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3732</th>\n",
       "      <td>2024-07-29</td>\n",
       "      <td>11117.8</td>\n",
       "      <td>11224.4</td>\n",
       "      <td>11254.2</td>\n",
       "      <td>11089.7</td>\n",
       "      <td>76500000.0</td>\n",
       "      <td>-0.43</td>\n",
       "      <td>19059.49</td>\n",
       "      <td>4815.39</td>\n",
       "      <td>5463.54</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3733 rows × 174 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Date  target_ibex35     open      max      min          vol   var  \\\n",
       "0    2010-01-04        12145.1  11986.5  12145.1  11986.1  184130000.0  1.72   \n",
       "1    2010-01-05        12204.4  12141.8  12240.5  12139.8  238430000.0  0.49   \n",
       "2    2010-01-06        12222.5  12216.4  12230.7  12147.6  123740000.0  0.15   \n",
       "3    2010-01-07        12166.3  12163.0  12199.7  12079.1  192310000.0 -0.46   \n",
       "4    2010-01-08        12163.0  12218.0  12232.2  12079.9  213110000.0 -0.03   \n",
       "...         ...            ...      ...      ...      ...          ...   ...   \n",
       "3728 2024-07-23        11212.7  11154.3  11221.8  11097.5  101470000.0  0.62   \n",
       "3729 2024-07-24        11210.1  11170.8  11245.5  11154.4  128810000.0 -0.02   \n",
       "3730 2024-07-25        11145.6  11132.7  11158.1  11012.0  120030000.0 -0.58   \n",
       "3731 2024-07-26        11165.9  11102.5  11177.6  11068.7   86560000.0  0.18   \n",
       "3732 2024-07-29        11117.8  11224.4  11254.2  11089.7   76500000.0 -0.43   \n",
       "\n",
       "      target_nasdaq  target_eustoxx   target  ...  bullish_rsi  bearish_rsi  \\\n",
       "0           1886.70         2324.48  1133.00  ...            0            0   \n",
       "1           1888.43         2324.48  1136.50  ...            0            0   \n",
       "2           1878.42         2324.48  1137.10  ...            0            0   \n",
       "3           1876.72         2324.48  1141.70  ...            0            0   \n",
       "4           1892.59         2324.48  1145.00  ...            0            0   \n",
       "...             ...             ...      ...  ...          ...          ...   \n",
       "3728       19754.34         4916.80  5555.74  ...            0            0   \n",
       "3729       19032.39         4861.87  5427.13  ...            0            0   \n",
       "3730       18830.59         4811.28  5399.22  ...            0            0   \n",
       "3731       19023.66         4862.50  5459.10  ...            0            0   \n",
       "3732       19059.49         4815.39  5463.54  ...            0            0   \n",
       "\n",
       "      bullish_bollinger  bearish_bollinger bullish_macd  bearish_macd  \\\n",
       "0                     0                  0            0             0   \n",
       "1                     0                  0            1             0   \n",
       "2                     0                  0            1             0   \n",
       "3                     0                  0            1             0   \n",
       "4                     0                  0            1             0   \n",
       "...                 ...                ...          ...           ...   \n",
       "3728                  0                  0            0             1   \n",
       "3729                  1                  0            0             1   \n",
       "3730                  1                  0            0             1   \n",
       "3731                  0                  0            0             1   \n",
       "3732                  0                  0            0             1   \n",
       "\n",
       "     bullish_atr  bearish_atr  bullish_trend  bearish_trend  \n",
       "0              0            0              0              0  \n",
       "1              0            0              0              0  \n",
       "2              0            0              0              0  \n",
       "3              0            0              0              0  \n",
       "4              0            0              0              0  \n",
       "...          ...          ...            ...            ...  \n",
       "3728           1            0              0              0  \n",
       "3729           1            0              1              0  \n",
       "3730           1            0              1              0  \n",
       "3731           1            0              0              0  \n",
       "3732           1            0              0              0  \n",
       "\n",
       "[3733 rows x 174 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f2bef641",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SHift indicator values\n",
    "cols_to_shift = [col for col in df.columns[3:] if not (col.startswith('AAII') or col.startswith('PIB'))]\n",
    "df[cols_to_shift] = df[cols_to_shift].shift(shift)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "faa75de8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = df.copy()\n",
    "# data[\"group\"] = 1\n",
    "\n",
    "# # Supongamos que tu DataFrame se llama 'data' y que la columna 'Date' tiene las fechas\n",
    "# # Crear una lista de días festivos (ejemplo, agrega tus días festivos)\n",
    "# dias_festivos = pd.to_datetime([\"2024-01-01\", \"2024-12-25\", ])  # Añade más días festivos\n",
    "\n",
    "# # Meses del año (de 1 a 12, de manera categórica)\n",
    "# data[\"month\"] = data[\"Date\"].dt.month.astype(\"category\")\n",
    "\n",
    "# # Días del año (de 1 a 365 o 366 en años bisiestos)\n",
    "# data[\"day_of_year\"] = data[\"Date\"].dt.dayofyear.astype(\"category\")\n",
    "\n",
    "# # Días de la semana (de lunes a viernes: 0 = lunes, 4 = viernes)\n",
    "# data[\"weekday\"] = data[\"Date\"].dt.weekday\n",
    "# data = data[data[\"weekday\"] < 5]  # Eliminar sábados (5) y domingos (6)\n",
    "\n",
    "# # Identificar si el día es festivo (1 si es festivo, 0 si no lo es)\n",
    "# data[\"is_holiday\"] = data[\"Date\"].isin(dias_festivos).astype(int)\n",
    "\n",
    "# # data[\"time_idx\"] = data.groupby(group).cumcount()\n",
    "\n",
    "# data[\"time_idx\"] = data.index\n",
    "\n",
    "# # data[\"Low\"].fillna(method=\"ffill\", inplace=True)\n",
    "# # data[\"High\"].fillna(method=\"ffill\", inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "179a60de",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df.copy()\n",
    "data[\"group\"] = 1\n",
    "\n",
    "# Supongamos que tu DataFrame se llama 'data' y que la columna 'Date' tiene las fechas\n",
    "# Crear una lista de días festivos (ejemplo, agrega tus días festivos)\n",
    "dias_festivos = pd.to_datetime([\"2024-01-01\", \"2024-12-25\", ])  # Añade más días festivos\n",
    "\n",
    "# Meses del año (convertir a nombres de meses)\n",
    "data[\"month\"] = data[\"Date\"].dt.strftime('%B')  # Ejemplo: \"January\", \"February\", etc.\n",
    "\n",
    "# Días del año (de 1 a 365 o 366 en años bisiestos), convertir en cadena\n",
    "data[\"day_of_year\"] = data[\"Date\"].dt.dayofyear.astype(str)  # Convertir el número de día a cadena\n",
    "\n",
    "# Días de la semana (de lunes a viernes: 0 = lunes, 4 = viernes), convertir a nombre de día\n",
    "data[\"weekday\"] = data[\"Date\"].dt.strftime('%A')  # Ejemplo: \"Monday\", \"Tuesday\", etc.\n",
    "\n",
    "# Filtrar para eliminar sábados y domingos\n",
    "data = data[data[\"weekday\"].isin([\"Monday\", \"Tuesday\", \"Wednesday\", \"Thursday\", \"Friday\"])]\n",
    "\n",
    "# Identificar si el día es festivo (usar \"Yes\" o \"No\" en lugar de 1 o 0)\n",
    "data[\"is_holiday\"] = data[\"Date\"].isin(dias_festivos).map({True: \"Yes\", False: \"No\"})\n",
    "\n",
    "data[\"time_idx\"] = data.index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a4f482f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_convert = [\n",
    "    \"target\",\n",
    "    \"open\",\n",
    "    \"max\",\n",
    "    \"min\",\n",
    "    \"var\",\n",
    "    \"SMA_5\",\n",
    "    \"EMA_5\",\n",
    "    \"SMA_10\",\n",
    "    \"EMA_10\",\n",
    "    \"SMA_20\",\n",
    "    \"EMA_20\",\n",
    "    \"Bollinger_Upper_20\",\n",
    "    \"Bollinger_Lower_20\",\n",
    "    \"MACD\",\n",
    "    \"Signal_Line\",\n",
    "    \"CCI_10\",\n",
    "    \"CCI_20\",\n",
    "    \"ROC_10\",\n",
    "    \"ROC_14\",\n",
    "    \"ROC_20\",\n",
    "    \"Stochastic_14_K\",\n",
    "    \"Stochastic_14_D\",\n",
    "    \"Williams_%R_14\",\n",
    "    \"VIX\",\n",
    "]\n",
    "\n",
    "data[cols_to_convert] = data[cols_to_convert].apply(pd.to_numeric, errors=\"coerce\")\n",
    "data = data.ffill().bfill()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fa86e03",
   "metadata": {},
   "source": [
    "## TRAIN - TEST SPLIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1c2fd2fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "full = data.copy()\n",
    "cols_to_convert = [\"target\", \"open\", \"max\", \"min\", \"var\", \"SMA_5\", \"EMA_5\", \"SMA_10\", \"EMA_10\", \"SMA_20\", \"EMA_20\",\n",
    "                   \"Bollinger_Upper_20\", \"Bollinger_Lower_20\", \"MACD\", \"Signal_Line\", \"CCI_10\", \"CCI_20\", \"ROC_10\",\n",
    "                   \"ROC_14\", \"ROC_20\", \"Stochastic_14_K\", \"Stochastic_14_D\", \"Williams_%R_14\", \"VIX\"]\n",
    "\n",
    "data[cols_to_convert] = data[cols_to_convert].apply(pd.to_numeric, errors='coerce')\n",
    "data = data.ffill().bfill()\n",
    "data = full[:-test_len]\n",
    "test = full[-test_len:]\n",
    "# test[\"target\"] = 0\n",
    "data = data.reset_index(drop=True)\n",
    "data = data.dropna()\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(data[\"Date\"], data[\"target\"], color=\"blue\", label=\"Train\")\n",
    "plt.plot(test[\"Date\"], test[\"target\"], color=\"green\", label=\"Test\")\n",
    "\n",
    "plt.xlabel(\"Fecha y Hora\")\n",
    "plt.ylabel(\"Precio Spot\")\n",
    "plt.title(\"Precio Spot en función de Fecha y Hora\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45a04371",
   "metadata": {},
   "source": [
    "<!-- ## DF FINL -->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da4fc650",
   "metadata": {},
   "source": [
    "## TimeSeriesDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "39224a5e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "afdbea69",
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nicov\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pytorch_forecasting\\data\\encoders.py:318: UserWarning: Found 1 unknown classes which were set to NaN\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "max_prediction_length = pred_len\n",
    "max_encoder_length = n_prev_len \n",
    "# Ajusta training_cutoff para reservar un rango más amplio para la validación\n",
    "validation_size = 50  # ajusta según el tamaño deseado para el conjunto de validación\n",
    "training_cutoff = data[\"time_idx\"].max() - max_prediction_length - validation_size\n",
    "\n",
    "train = TimeSeriesDataSet(\n",
    "    data[lambda x: x.time_idx <= training_cutoff],\n",
    "    time_idx=\"time_idx\",\n",
    "    target=\"target\",\n",
    "    group_ids=[group],\n",
    "    min_encoder_length=max_encoder_length,  # keep encoder length long (as it is in the validation set)\n",
    "    max_encoder_length=max_encoder_length,\n",
    "    # min_prediction_length=24,\n",
    "    max_prediction_length=max_prediction_length,\n",
    "    static_categoricals=[],\n",
    "    static_reals=[],\n",
    "    time_varying_known_categoricals=[\"month\", \"weekday\", \"day_of_year\", \"is_holiday\"],  # group of categorical variables can be treated as one variable\n",
    "    time_varying_known_reals=[\"Date\", \"time_idx\", 'AAII_Bullish',\t'AAII_Neutral',\t'AAII_Bearish', 'FEDFUNDS'] +\n",
    "                                        [col for col in df.columns if col.startswith('PIB')],\n",
    "    time_varying_unknown_categoricals=[\n",
    "        'bullish_sma_50_200',\n",
    "        'bearish_sma_50_200',\n",
    "        'bullish_rsi',\n",
    "        'bearish_rsi',\n",
    "        'bullish_bollinger',\n",
    "        'bearish_bollinger',\n",
    "        'bullish_macd',\n",
    "        'bearish_macd',\n",
    "        'bullish_atr',\n",
    "        'bearish_atr',\n",
    "        'bullish_trend',\n",
    "        'bearish_trend'],\n",
    "    time_varying_unknown_reals=[\n",
    "        \"target\",\n",
    "        \"open\",\n",
    "        \"max\",\n",
    "        \"min\",\n",
    "        # \"vol\",\n",
    "        \"var\",\n",
    "        \"target_lag1\",\n",
    "        \"target_lag2\",\n",
    "        \"target_lag3\",\n",
    "        \"target_lag4\",\n",
    "        \"target_lag5\",\n",
    "        \"SMA_5\",\n",
    "        \"EMA_5\",\n",
    "        \"SMA_10\",\n",
    "        \"EMA_10\",\n",
    "        # \"SMA_15\",\n",
    "        # \"EMA_15\",\n",
    "        \"SMA_20\",\n",
    "        \"EMA_20\",\n",
    "        # \"RSI_20\",\n",
    "        \"Bollinger_Upper_20\",\n",
    "        \"Bollinger_Lower_20\",\n",
    "        \"MACD\",\n",
    "        \"Signal_Line\",\n",
    "        # \"ATR_20\",\n",
    "        \"CCI_10\",\n",
    "        \"CCI_20\",\n",
    "        \"ROC_10\",\n",
    "        \"ROC_14\",\n",
    "        \"ROC_20\",\n",
    "        \"Stochastic_14_K\",\n",
    "        \"Stochastic_14_D\",\n",
    "        \"Williams_%R_14\",\n",
    "        \"VIX\",\n",
    "        \"EUVIX\",\n",
    "        \"target_eustoxx\",\n",
    "        \"target_ibex35\",\n",
    "        \"target_nasdaq\",\n",
    "    ],\n",
    "    # lags={\"target\": list(range(1, 5))},\n",
    "    # target_normalizer=GroupNormalizer(\"standard\", groups=[group], transformation=\"softplus\"),\n",
    "    # use softplus and normalize by group\n",
    "    add_relative_time_idx=True,\n",
    "    add_target_scales=True,\n",
    "    allow_missing_timesteps=True,\n",
    "    # add_encoder_length=True,\n",
    "    categorical_encoders={\n",
    "        \"month\": pytorch_forecasting.data.encoders.NaNLabelEncoder(add_nan=True),\n",
    "        \"weekday\": pytorch_forecasting.data.encoders.NaNLabelEncoder(add_nan=True),\n",
    "        \"day_of_year\": pytorch_forecasting.data.encoders.NaNLabelEncoder(add_nan=True),\n",
    "    },\n",
    ")\n",
    "\n",
    "validation = TimeSeriesDataSet.from_dataset(train,  data, predict=True, stop_randomization=True)\n",
    "# test = TimeSeriesDataSet.from_dataset(training, test_data, predict=True, stop_randomization=True)\n",
    "\n",
    "# create dataloaders for model\n",
    "batch_size = 32  # set this between 32 to 128\n",
    "train_dataloader = train.to_dataloader(\n",
    "    train=True, batch_size=batch_size, num_workers=7, persistent_workers=True\n",
    ")\n",
    "val_dataloader = validation.to_dataloader(\n",
    "    train=False, batch_size=batch_size, num_workers=7, persistent_workers=True\n",
    ")\n",
    "# test_dataloader = test.to_dataloader(train=False, batch_size=batch_size, num_workers=11, persistent_workers=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9b716d2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75\n"
     ]
    }
   ],
   "source": [
    "validation_data = data[lambda x: x.time_idx > training_cutoff]\n",
    "print(len(validation_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1db5ef6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TimeSeriesDataSet[length=1](\n",
       "\ttime_idx='time_idx',\n",
       "\ttarget='target',\n",
       "\tgroup_ids=['group'],\n",
       "\tweight=None,\n",
       "\tmax_encoder_length=100,\n",
       "\tmin_encoder_length=100,\n",
       "\tmin_prediction_idx=0,\n",
       "\tmin_prediction_length=25,\n",
       "\tmax_prediction_length=25,\n",
       "\tstatic_categoricals=[],\n",
       "\tstatic_reals=['target_center', 'target_scale'],\n",
       "\ttime_varying_known_categoricals=['month', 'weekday', 'day_of_year', 'is_holiday'],\n",
       "\ttime_varying_known_reals=['Date', 'time_idx', 'AAII_Bullish', 'AAII_Neutral', 'AAII_Bearish', 'FEDFUNDS', 'PIB_USA', 'PIB_CHN', 'PIB_EMU', 'PIB_DEU', 'PIB_FRA', 'PIB_GBR', 'PIB_JPN', 'PIB_IND', 'PIB_BRA', 'PIB_CAN', 'PIB_AUS', 'PIB_ITA', 'PIB_KOR', 'PIB_MEX', 'PIB_IDN', 'PIB_SAU', 'PIB_ZAF', 'PIB_TUR', 'PIB_ESP', 'relative_time_idx'],\n",
       "\ttime_varying_unknown_categoricals=['bullish_sma_50_200', 'bearish_sma_50_200', 'bullish_rsi', 'bearish_rsi', 'bullish_bollinger', 'bearish_bollinger', 'bullish_macd', 'bearish_macd', 'bullish_atr', 'bearish_atr', 'bullish_trend', 'bearish_trend'],\n",
       "\ttime_varying_unknown_reals=['target', 'open', 'max', 'min', 'var', 'target_lag1', 'target_lag2', 'target_lag3', 'target_lag4', 'target_lag5', 'SMA_5', 'EMA_5', 'SMA_10', 'EMA_10', 'SMA_20', 'EMA_20', 'Bollinger_Upper_20', 'Bollinger_Lower_20', 'MACD', 'Signal_Line', 'CCI_10', 'CCI_20', 'ROC_10', 'ROC_14', 'ROC_20', 'Stochastic_14_K', 'Stochastic_14_D', 'Williams_%R_14', 'VIX', 'EUVIX', 'target_eustoxx', 'target_ibex35', 'target_nasdaq'],\n",
       "\tvariable_groups={},\n",
       "\tconstant_fill_strategy={},\n",
       "\tallow_missing_timesteps=True,\n",
       "\tlags={},\n",
       "\tadd_relative_time_idx=True,\n",
       "\tadd_target_scales=True,\n",
       "\tadd_encoder_length=False,\n",
       "\ttarget_normalizer=EncoderNormalizer(\n",
       "\tmethod='standard',\n",
       "\tcenter=True,\n",
       "\tmax_length=None,\n",
       "\ttransformation='relu',\n",
       "\tmethod_kwargs={}\n",
       "),\n",
       "\tcategorical_encoders={'month': NaNLabelEncoder(add_nan=True, warn=True), 'weekday': NaNLabelEncoder(add_nan=True, warn=True), 'day_of_year': NaNLabelEncoder(add_nan=True, warn=True), '__group_id__group': NaNLabelEncoder(add_nan=False, warn=True), 'is_holiday': NaNLabelEncoder(add_nan=False, warn=True), 'bullish_sma_50_200': NaNLabelEncoder(add_nan=False, warn=True), 'bearish_sma_50_200': NaNLabelEncoder(add_nan=False, warn=True), 'bullish_rsi': NaNLabelEncoder(add_nan=False, warn=True), 'bearish_rsi': NaNLabelEncoder(add_nan=False, warn=True), 'bullish_bollinger': NaNLabelEncoder(add_nan=False, warn=True), 'bearish_bollinger': NaNLabelEncoder(add_nan=False, warn=True), 'bullish_macd': NaNLabelEncoder(add_nan=False, warn=True), 'bearish_macd': NaNLabelEncoder(add_nan=False, warn=True), 'bullish_atr': NaNLabelEncoder(add_nan=False, warn=True), 'bearish_atr': NaNLabelEncoder(add_nan=False, warn=True), 'bullish_trend': NaNLabelEncoder(add_nan=False, warn=True), 'bearish_trend': NaNLabelEncoder(add_nan=False, warn=True)},\n",
       "\tscalers={'target_center': StandardScaler(), 'target_scale': StandardScaler(), 'Date': StandardScaler(), 'time_idx': StandardScaler(), 'AAII_Bullish': StandardScaler(), 'AAII_Neutral': StandardScaler(), 'AAII_Bearish': StandardScaler(), 'FEDFUNDS': StandardScaler(), 'PIB_USA': StandardScaler(), 'PIB_CHN': StandardScaler(), 'PIB_EMU': StandardScaler(), 'PIB_DEU': StandardScaler(), 'PIB_FRA': StandardScaler(), 'PIB_GBR': StandardScaler(), 'PIB_JPN': StandardScaler(), 'PIB_IND': StandardScaler(), 'PIB_BRA': StandardScaler(), 'PIB_CAN': StandardScaler(), 'PIB_AUS': StandardScaler(), 'PIB_ITA': StandardScaler(), 'PIB_KOR': StandardScaler(), 'PIB_MEX': StandardScaler(), 'PIB_IDN': StandardScaler(), 'PIB_SAU': StandardScaler(), 'PIB_ZAF': StandardScaler(), 'PIB_TUR': StandardScaler(), 'PIB_ESP': StandardScaler(), 'relative_time_idx': StandardScaler(), 'open': StandardScaler(), 'max': StandardScaler(), 'min': StandardScaler(), 'var': StandardScaler(), 'target_lag1': StandardScaler(), 'target_lag2': StandardScaler(), 'target_lag3': StandardScaler(), 'target_lag4': StandardScaler(), 'target_lag5': StandardScaler(), 'SMA_5': StandardScaler(), 'EMA_5': StandardScaler(), 'SMA_10': StandardScaler(), 'EMA_10': StandardScaler(), 'SMA_20': StandardScaler(), 'EMA_20': StandardScaler(), 'Bollinger_Upper_20': StandardScaler(), 'Bollinger_Lower_20': StandardScaler(), 'MACD': StandardScaler(), 'Signal_Line': StandardScaler(), 'CCI_10': StandardScaler(), 'CCI_20': StandardScaler(), 'ROC_10': StandardScaler(), 'ROC_14': StandardScaler(), 'ROC_20': StandardScaler(), 'Stochastic_14_K': StandardScaler(), 'Stochastic_14_D': StandardScaler(), 'Williams_%R_14': StandardScaler(), 'VIX': StandardScaler(), 'EUVIX': StandardScaler(), 'target_eustoxx': StandardScaler(), 'target_ibex35': StandardScaler(), 'target_nasdaq': StandardScaler()},\n",
       "\trandomize_length=None,\n",
       "\tpredict_mode=True\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c2a24e8",
   "metadata": {},
   "source": [
    "\n",
    "# LEARNIG RATE FINDER"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44fa807d",
   "metadata": {},
   "source": [
    "En primer lugar realizamos un estudio para hallar de forma aproximada el valor optimo de tasa de aprendizaje.  No es recomendable al 100% usar el valor sugerido directamente pues a veces no encuentra el mejor, sin embargo si que da un muy buen punto de partida por donde empezar a probar. Para ello usamos un modelo TFT cualquiera basico."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "54055c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if lr_finder:\n",
    "    res = get_best_lr(train, train_dataloader, val_dataloader, **tft_params)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "008a1fdd",
   "metadata": {},
   "source": [
    "# MODELLING"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "927621bc",
   "metadata": {},
   "source": [
    "## TRAIN MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "152ce290",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not grid_search:\n",
    "    # tft_params[\"learning_rate\"] = 0.01\n",
    "    tft, val_loss = tft_trainer(train, train_dataloader, val_dataloader, max_epochs=epochs, **tft_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dff7ab74",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6f0f0114",
   "metadata": {},
   "source": [
    "### EVAL MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ba6ae28f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not grid_search:\n",
    "    preds = tft_predict(tft, val_dataloader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a670302f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54f4ad1d",
   "metadata": {},
   "source": [
    "## GRID SEARCH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "45763d2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " -------------------------------------------------------- \n",
      " Probando combinación aleatoria 1/100: {'gradient_clip_val': 0.03, 'hidden_size': 8, 'dropout': 0.3, 'hidden_continuous_size': 16, 'attention_head_size': 4, 'learning_rate': 0.005, 'loss': MAPE(), 'test_len': 125, 'pred_len': 25, 'n_prev_len': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49: 100%|██████████| 32/32 [00:21<00:00,  1.48it/s, v_num=0, train_loss_step=0.0146, val_loss=0.0253, train_loss_epoch=0.0163]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49: 100%|██████████| 32/32 [00:22<00:00,  1.44it/s, v_num=0, train_loss_step=0.0146, val_loss=0.0253, train_loss_epoch=0.0163]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters in network: 57.4k\n",
      "Training time: 18m 55s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nueva mejor combinación encontrada: {'gradient_clip_val': 0.03, 'hidden_size': 8, 'dropout': 0.3, 'hidden_continuous_size': 16, 'attention_head_size': 4, 'learning_rate': 0.005, 'loss': MAPE(), 'test_len': 125, 'pred_len': 25, 'n_prev_len': 100} con pérdida 0.0253\n",
      "\n",
      " -------------------------------------------------------- \n",
      " Probando combinación aleatoria 2/100: {'gradient_clip_val': 0.01, 'hidden_size': 16, 'dropout': 0.2, 'hidden_continuous_size': 16, 'attention_head_size': 4, 'learning_rate': 0.03, 'loss': MAPE(), 'test_len': 125, 'pred_len': 25, 'n_prev_len': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49: 100%|██████████| 32/32 [00:18<00:00,  1.73it/s, v_num=6, train_loss_step=0.0114, val_loss=0.039, train_loss_epoch=0.00945]  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49: 100%|██████████| 32/32 [00:19<00:00,  1.68it/s, v_num=6, train_loss_step=0.0114, val_loss=0.039, train_loss_epoch=0.00945]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters in network: 148.2k\n",
      "Training time: 15m 46s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " -------------------------------------------------------- \n",
      " Probando combinación aleatoria 3/100: {'gradient_clip_val': 0.03, 'hidden_size': 32, 'dropout': 0.1, 'hidden_continuous_size': 64, 'attention_head_size': 8, 'learning_rate': 0.03, 'loss': MAPE(), 'test_len': 125, 'pred_len': 25, 'n_prev_len': 100}\n",
      "Epoch 49: 100%|██████████| 32/32 [00:22<00:00,  1.45it/s, v_num=12, train_loss_step=0.00753, val_loss=0.0319, train_loss_epoch=0.00812]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49: 100%|██████████| 32/32 [00:22<00:00,  1.41it/s, v_num=12, train_loss_step=0.00753, val_loss=0.0319, train_loss_epoch=0.00812]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters in network: 730.1k\n",
      "Training time: 19m 38s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " -------------------------------------------------------- \n",
      " Probando combinación aleatoria 4/100: {'gradient_clip_val': 0.03, 'hidden_size': 8, 'dropout': 0.2, 'hidden_continuous_size': 128, 'attention_head_size': 4, 'learning_rate': 0.01, 'loss': MAPE(), 'test_len': 125, 'pred_len': 25, 'n_prev_len': 100}\n",
      "Epoch 49: 100%|██████████| 32/32 [00:20<00:00,  1.55it/s, v_num=18, train_loss_step=0.0112, val_loss=0.0247, train_loss_epoch=0.0136]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49: 100%|██████████| 32/32 [00:21<00:00,  1.51it/s, v_num=18, train_loss_step=0.0112, val_loss=0.0247, train_loss_epoch=0.0136]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters in network: 225.6k\n",
      "Training time: 18m 59s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nueva mejor combinación encontrada: {'gradient_clip_val': 0.03, 'hidden_size': 8, 'dropout': 0.2, 'hidden_continuous_size': 128, 'attention_head_size': 4, 'learning_rate': 0.01, 'loss': MAPE(), 'test_len': 125, 'pred_len': 25, 'n_prev_len': 100} con pérdida 0.0247\n",
      "\n",
      " -------------------------------------------------------- \n",
      " Probando combinación aleatoria 5/100: {'gradient_clip_val': 0.01, 'hidden_size': 32, 'dropout': 0.1, 'hidden_continuous_size': 64, 'attention_head_size': 8, 'learning_rate': 0.01, 'loss': MAPE(), 'test_len': 125, 'pred_len': 25, 'n_prev_len': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49: 100%|██████████| 32/32 [00:22<00:00,  1.40it/s, v_num=24, train_loss_step=0.0133, val_loss=0.0171, train_loss_epoch=0.0107] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49: 100%|██████████| 32/32 [00:23<00:00,  1.36it/s, v_num=24, train_loss_step=0.0133, val_loss=0.0171, train_loss_epoch=0.0107]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters in network: 730.1k\n",
      "Training time: 19m 43s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nueva mejor combinación encontrada: {'gradient_clip_val': 0.01, 'hidden_size': 32, 'dropout': 0.1, 'hidden_continuous_size': 64, 'attention_head_size': 8, 'learning_rate': 0.01, 'loss': MAPE(), 'test_len': 125, 'pred_len': 25, 'n_prev_len': 100} con pérdida 0.0171\n",
      "\n",
      " -------------------------------------------------------- \n",
      " Probando combinación aleatoria 6/100: {'gradient_clip_val': 0.05, 'hidden_size': 8, 'dropout': 0.2, 'hidden_continuous_size': 128, 'attention_head_size': 4, 'learning_rate': 0.01, 'loss': MAPE(), 'test_len': 125, 'pred_len': 25, 'n_prev_len': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49: 100%|██████████| 32/32 [00:20<00:00,  1.56it/s, v_num=30, train_loss_step=0.0188, val_loss=0.0229, train_loss_epoch=0.0144]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49: 100%|██████████| 32/32 [00:21<00:00,  1.51it/s, v_num=30, train_loss_step=0.0188, val_loss=0.0229, train_loss_epoch=0.0144]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters in network: 225.6k\n",
      "Training time: 18m 58s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " -------------------------------------------------------- \n",
      " Probando combinación aleatoria 7/100: {'gradient_clip_val': 0.03, 'hidden_size': 8, 'dropout': 0.2, 'hidden_continuous_size': 64, 'attention_head_size': 16, 'learning_rate': 0.03, 'loss': MAPE(), 'test_len': 125, 'pred_len': 25, 'n_prev_len': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49: 100%|██████████| 32/32 [00:19<00:00,  1.61it/s, v_num=36, train_loss_step=0.0145, val_loss=0.0385, train_loss_epoch=0.0124] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49: 100%|██████████| 32/32 [00:20<00:00,  1.56it/s, v_num=36, train_loss_step=0.0145, val_loss=0.0385, train_loss_epoch=0.0124]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters in network: 129.3k\n",
      "Training time: 19m 11s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " -------------------------------------------------------- \n",
      " Probando combinación aleatoria 8/100: {'gradient_clip_val': 0.03, 'hidden_size': 32, 'dropout': 0.3, 'hidden_continuous_size': 64, 'attention_head_size': 16, 'learning_rate': 0.03, 'loss': MAPE(), 'test_len': 125, 'pred_len': 25, 'n_prev_len': 100}\n",
      "Epoch 49: 100%|██████████| 32/32 [00:22<00:00,  1.41it/s, v_num=42, train_loss_step=0.00864, val_loss=0.0226, train_loss_epoch=0.00916]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49: 100%|██████████| 32/32 [00:23<00:00,  1.37it/s, v_num=42, train_loss_step=0.00864, val_loss=0.0226, train_loss_epoch=0.00916]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters in network: 730.0k\n",
      "Training time: 20m 2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " -------------------------------------------------------- \n",
      " Probando combinación aleatoria 9/100: {'gradient_clip_val': 0.01, 'hidden_size': 8, 'dropout': 0.2, 'hidden_continuous_size': 128, 'attention_head_size': 16, 'learning_rate': 0.01, 'loss': MAPE(), 'test_len': 125, 'pred_len': 25, 'n_prev_len': 100}\n",
      "Epoch 49: 100%|██████████| 32/32 [00:22<00:00,  1.42it/s, v_num=48, train_loss_step=0.0176, val_loss=0.0343, train_loss_epoch=0.0144]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49: 100%|██████████| 32/32 [00:23<00:00,  1.38it/s, v_num=48, train_loss_step=0.0176, val_loss=0.0343, train_loss_epoch=0.0144]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters in network: 225.4k\n",
      "Training time: 19m 21s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " -------------------------------------------------------- \n",
      " Probando combinación aleatoria 10/100: {'gradient_clip_val': 0.05, 'hidden_size': 8, 'dropout': 0.2, 'hidden_continuous_size': 16, 'attention_head_size': 8, 'learning_rate': 0.03, 'loss': MAPE(), 'test_len': 125, 'pred_len': 25, 'n_prev_len': 100}\n",
      "Epoch 49: 100%|██████████| 32/32 [00:22<00:00,  1.39it/s, v_num=54, train_loss_step=0.012, val_loss=0.0125, train_loss_epoch=0.0125]  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49: 100%|██████████| 32/32 [00:23<00:00,  1.35it/s, v_num=54, train_loss_step=0.012, val_loss=0.0125, train_loss_epoch=0.0125]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters in network: 57.4k\n",
      "Training time: 20m 19s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nueva mejor combinación encontrada: {'gradient_clip_val': 0.05, 'hidden_size': 8, 'dropout': 0.2, 'hidden_continuous_size': 16, 'attention_head_size': 8, 'learning_rate': 0.03, 'loss': MAPE(), 'test_len': 125, 'pred_len': 25, 'n_prev_len': 100} con pérdida 0.0125\n",
      "\n",
      " -------------------------------------------------------- \n",
      " Probando combinación aleatoria 11/100: {'gradient_clip_val': 0.05, 'hidden_size': 32, 'dropout': 0.3, 'hidden_continuous_size': 128, 'attention_head_size': 16, 'learning_rate': 0.01, 'loss': MAPE(), 'test_len': 125, 'pred_len': 25, 'n_prev_len': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49: 100%|██████████| 32/32 [00:26<00:00,  1.22it/s, v_num=60, train_loss_step=0.0118, val_loss=0.0371, train_loss_epoch=0.0125] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49: 100%|██████████| 32/32 [00:27<00:00,  1.18it/s, v_num=60, train_loss_step=0.0118, val_loss=0.0371, train_loss_epoch=0.0125]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters in network: 1087.0k\n",
      "Training time: 23m 1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " -------------------------------------------------------- \n",
      " Probando combinación aleatoria 12/100: {'gradient_clip_val': 0.03, 'hidden_size': 8, 'dropout': 0.1, 'hidden_continuous_size': 128, 'attention_head_size': 16, 'learning_rate': 0.005, 'loss': MAPE(), 'test_len': 125, 'pred_len': 25, 'n_prev_len': 100}\n",
      "Epoch 49: 100%|██████████| 32/32 [00:23<00:00,  1.34it/s, v_num=66, train_loss_step=0.0157, val_loss=0.0136, train_loss_epoch=0.014] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49: 100%|██████████| 32/32 [00:24<00:00,  1.30it/s, v_num=66, train_loss_step=0.0157, val_loss=0.0136, train_loss_epoch=0.014]\n",
      "Number of parameters in network: 225.4k\n",
      "Training time: 22m 2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " -------------------------------------------------------- \n",
      " Probando combinación aleatoria 13/100: {'gradient_clip_val': 0.01, 'hidden_size': 32, 'dropout': 0.2, 'hidden_continuous_size': 16, 'attention_head_size': 16, 'learning_rate': 0.01, 'loss': MAPE(), 'test_len': 125, 'pred_len': 25, 'n_prev_len': 100}\n",
      "Epoch 49: 100%|██████████| 32/32 [00:25<00:00,  1.24it/s, v_num=72, train_loss_step=0.0113, val_loss=0.0395, train_loss_epoch=0.0118] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49: 100%|██████████| 32/32 [00:26<00:00,  1.21it/s, v_num=72, train_loss_step=0.0113, val_loss=0.0395, train_loss_epoch=0.0118]\n",
      "Number of parameters in network: 281.3k\n",
      "Training time: 23m 9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " -------------------------------------------------------- \n",
      " Probando combinación aleatoria 14/100: {'gradient_clip_val': 0.05, 'hidden_size': 16, 'dropout': 0.3, 'hidden_continuous_size': 16, 'attention_head_size': 16, 'learning_rate': 0.01, 'loss': MAPE(), 'test_len': 125, 'pred_len': 25, 'n_prev_len': 100}\n",
      "Epoch 49: 100%|██████████| 32/32 [00:19<00:00,  1.65it/s, v_num=78, train_loss_step=0.0137, val_loss=0.0272, train_loss_epoch=0.0135]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49: 100%|██████████| 32/32 [00:19<00:00,  1.60it/s, v_num=78, train_loss_step=0.0137, val_loss=0.0272, train_loss_epoch=0.0135]\n",
      "Number of parameters in network: 148.1k\n",
      "Training time: 18m 13s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " -------------------------------------------------------- \n",
      " Probando combinación aleatoria 15/100: {'gradient_clip_val': 0.03, 'hidden_size': 32, 'dropout': 0.1, 'hidden_continuous_size': 16, 'attention_head_size': 16, 'learning_rate': 0.03, 'loss': MAPE(), 'test_len': 125, 'pred_len': 25, 'n_prev_len': 100}\n",
      "Epoch 49: 100%|██████████| 32/32 [00:23<00:00,  1.36it/s, v_num=84, train_loss_step=0.00708, val_loss=0.0398, train_loss_epoch=0.00709]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49: 100%|██████████| 32/32 [00:24<00:00,  1.31it/s, v_num=84, train_loss_step=0.00708, val_loss=0.0398, train_loss_epoch=0.00709]\n",
      "Number of parameters in network: 281.3k\n",
      "Training time: 23m 27s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " -------------------------------------------------------- \n",
      " Probando combinación aleatoria 16/100: {'gradient_clip_val': 0.01, 'hidden_size': 8, 'dropout': 0.2, 'hidden_continuous_size': 128, 'attention_head_size': 8, 'learning_rate': 0.005, 'loss': MAPE(), 'test_len': 125, 'pred_len': 25, 'n_prev_len': 100}\n",
      "Epoch 49: 100%|██████████| 32/32 [00:27<00:00,  1.15it/s, v_num=90, train_loss_step=0.0125, val_loss=0.016, train_loss_epoch=0.015]  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49: 100%|██████████| 32/32 [00:28<00:00,  1.12it/s, v_num=90, train_loss_step=0.0125, val_loss=0.016, train_loss_epoch=0.015]\n",
      "Number of parameters in network: 225.6k\n",
      "Training time: 24m 52s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " -------------------------------------------------------- \n",
      " Probando combinación aleatoria 17/100: {'gradient_clip_val': 0.05, 'hidden_size': 8, 'dropout': 0.1, 'hidden_continuous_size': 128, 'attention_head_size': 4, 'learning_rate': 0.03, 'loss': MAPE(), 'test_len': 125, 'pred_len': 25, 'n_prev_len': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49: 100%|██████████| 32/32 [00:25<00:00,  1.26it/s, v_num=96, train_loss_step=0.0134, val_loss=0.0159, train_loss_epoch=0.0123] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49: 100%|██████████| 32/32 [00:26<00:00,  1.22it/s, v_num=96, train_loss_step=0.0134, val_loss=0.0159, train_loss_epoch=0.0123]\n",
      "Number of parameters in network: 225.6k\n",
      "Training time: 23m 54s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " -------------------------------------------------------- \n",
      " Probando combinación aleatoria 18/100: {'gradient_clip_val': 0.01, 'hidden_size': 32, 'dropout': 0.2, 'hidden_continuous_size': 64, 'attention_head_size': 16, 'learning_rate': 0.03, 'loss': MAPE(), 'test_len': 125, 'pred_len': 25, 'n_prev_len': 100}\n",
      "Epoch 49: 100%|██████████| 32/32 [00:23<00:00,  1.38it/s, v_num=102, train_loss_step=0.00753, val_loss=0.061, train_loss_epoch=0.00808] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49: 100%|██████████| 32/32 [00:23<00:00,  1.33it/s, v_num=102, train_loss_step=0.00753, val_loss=0.061, train_loss_epoch=0.00808]\n",
      "Number of parameters in network: 730.0k\n",
      "Training time: 23m 7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " -------------------------------------------------------- \n",
      " Probando combinación aleatoria 19/100: {'gradient_clip_val': 0.01, 'hidden_size': 8, 'dropout': 0.2, 'hidden_continuous_size': 16, 'attention_head_size': 16, 'learning_rate': 0.01, 'loss': MAPE(), 'test_len': 125, 'pred_len': 25, 'n_prev_len': 100}\n",
      "Epoch 49: 100%|██████████| 32/32 [00:20<00:00,  1.55it/s, v_num=108, train_loss_step=0.0145, val_loss=0.021, train_loss_epoch=0.0143] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49: 100%|██████████| 32/32 [00:21<00:00,  1.50it/s, v_num=108, train_loss_step=0.0145, val_loss=0.021, train_loss_epoch=0.0143]\n",
      "Number of parameters in network: 57.2k\n",
      "Training time: 20m 5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " -------------------------------------------------------- \n",
      " Probando combinación aleatoria 20/100: {'gradient_clip_val': 0.05, 'hidden_size': 8, 'dropout': 0.1, 'hidden_continuous_size': 64, 'attention_head_size': 16, 'learning_rate': 0.03, 'loss': MAPE(), 'test_len': 125, 'pred_len': 25, 'n_prev_len': 100}\n",
      "Epoch 49: 100%|██████████| 32/32 [00:20<00:00,  1.53it/s, v_num=114, train_loss_step=0.0116, val_loss=0.0143, train_loss_epoch=0.0107]  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49: 100%|██████████| 32/32 [00:21<00:00,  1.47it/s, v_num=114, train_loss_step=0.0116, val_loss=0.0143, train_loss_epoch=0.0107]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters in network: 129.3k\n",
      "Training time: 19m 3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " -------------------------------------------------------- \n",
      " Probando combinación aleatoria 21/100: {'gradient_clip_val': 0.03, 'hidden_size': 16, 'dropout': 0.3, 'hidden_continuous_size': 16, 'attention_head_size': 8, 'learning_rate': 0.01, 'loss': MAPE(), 'test_len': 125, 'pred_len': 25, 'n_prev_len': 100}\n",
      "Epoch 49: 100%|██████████| 32/32 [00:16<00:00,  1.92it/s, v_num=120, train_loss_step=0.0136, val_loss=0.035, train_loss_epoch=0.0138]  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49: 100%|██████████| 32/32 [00:17<00:00,  1.86it/s, v_num=120, train_loss_step=0.0136, val_loss=0.035, train_loss_epoch=0.0138]\n",
      "Number of parameters in network: 148.1k\n",
      "Training time: 19m 5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " -------------------------------------------------------- \n",
      " Probando combinación aleatoria 22/100: {'gradient_clip_val': 0.01, 'hidden_size': 16, 'dropout': 0.2, 'hidden_continuous_size': 64, 'attention_head_size': 4, 'learning_rate': 0.01, 'loss': MAPE(), 'test_len': 125, 'pred_len': 25, 'n_prev_len': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49: 100%|██████████| 32/32 [00:22<00:00,  1.44it/s, v_num=126, train_loss_step=0.00993, val_loss=0.0149, train_loss_epoch=0.0124]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49: 100%|██████████| 32/32 [00:22<00:00,  1.40it/s, v_num=126, train_loss_step=0.00993, val_loss=0.0149, train_loss_epoch=0.0124]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters in network: 290.5k\n",
      "Training time: 19m 8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " -------------------------------------------------------- \n",
      " Probando combinación aleatoria 23/100: {'gradient_clip_val': 0.03, 'hidden_size': 8, 'dropout': 0.2, 'hidden_continuous_size': 128, 'attention_head_size': 8, 'learning_rate': 0.01, 'loss': MAPE(), 'test_len': 125, 'pred_len': 25, 'n_prev_len': 100}\n",
      "Epoch 49: 100%|██████████| 32/32 [00:22<00:00,  1.43it/s, v_num=132, train_loss_step=0.0157, val_loss=0.0217, train_loss_epoch=0.0141]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49: 100%|██████████| 32/32 [00:23<00:00,  1.39it/s, v_num=132, train_loss_step=0.0157, val_loss=0.0217, train_loss_epoch=0.0141]\n",
      "Number of parameters in network: 225.6k\n",
      "Training time: 23m 13s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " -------------------------------------------------------- \n",
      " Probando combinación aleatoria 24/100: {'gradient_clip_val': 0.01, 'hidden_size': 16, 'dropout': 0.1, 'hidden_continuous_size': 128, 'attention_head_size': 16, 'learning_rate': 0.03, 'loss': MAPE(), 'test_len': 125, 'pred_len': 25, 'n_prev_len': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49: 100%|██████████| 32/32 [00:23<00:00,  1.35it/s, v_num=138, train_loss_step=0.0104, val_loss=0.0341, train_loss_epoch=0.0101]  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49: 100%|██████████| 32/32 [00:24<00:00,  1.31it/s, v_num=138, train_loss_step=0.0104, val_loss=0.0341, train_loss_epoch=0.0101]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters in network: 474.6k\n",
      "Training time: 21m 35s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " -------------------------------------------------------- \n",
      " Probando combinación aleatoria 25/100: {'gradient_clip_val': 0.03, 'hidden_size': 32, 'dropout': 0.3, 'hidden_continuous_size': 16, 'attention_head_size': 4, 'learning_rate': 0.01, 'loss': MAPE(), 'test_len': 125, 'pred_len': 25, 'n_prev_len': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20: 100%|██████████| 32/32 [00:21<00:00,  1.48it/s, v_num=144, train_loss_step=0.0124, val_loss=0.028, train_loss_epoch=0.0146] "
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 8.62 MiB for an array with shape (1494, 504, 3) and data type float32",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Input \u001b[1;32mIn [21]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m warnings\u001b[38;5;241m.\u001b[39mfilterwarnings(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Llamada a la función de búsqueda aleatoria\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m best_model, best_params, best_val_loss \u001b[38;5;241m=\u001b[39m \u001b[43mrandom_hyperparameter_search\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mval_dataloader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparam_grid\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_iterations\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[43msave_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m./plots/multiexog_syp500_-\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mn_prev_len\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43md-\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mdate_start\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreplace\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m-\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m-\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mdate_end\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreplace\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m-\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m-lessFilters\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     16\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcsv_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m./results/multiexog_syp500_-\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mn_prev_len\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43md-\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mdate_start\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m-\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mdate_end\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m.csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     17\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\nicov\\Documents\\Github\\TFT-QuantTrader\\tft_helper.py:297\u001b[0m, in \u001b[0;36mrandom_hyperparameter_search\u001b[1;34m(data, train, train_dataloader, val_dataloader, test, param_grid, n_iterations, max_epochs, save_dir, csv_file)\u001b[0m\n\u001b[0;32m    294\u001b[0m start_time \u001b[38;5;241m=\u001b[39m datetime\u001b[38;5;241m.\u001b[39mnow()\n\u001b[0;32m    296\u001b[0m \u001b[38;5;66;03m# Entrenar el modelo con la combinación actual de hiperparámetros\u001b[39;00m\n\u001b[1;32m--> 297\u001b[0m tft, val_loss \u001b[38;5;241m=\u001b[39m tft_trainer(\n\u001b[0;32m    298\u001b[0m     train, train_dataloader, val_dataloader, max_epochs\u001b[38;5;241m=\u001b[39mmax_epochs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams\n\u001b[0;32m    299\u001b[0m )\n\u001b[0;32m    301\u001b[0m \u001b[38;5;66;03m# Medir el tiempo de finalización del entrenamiento\u001b[39;00m\n\u001b[0;32m    302\u001b[0m end_time \u001b[38;5;241m=\u001b[39m datetime\u001b[38;5;241m.\u001b[39mnow()\n",
      "File \u001b[1;32mc:\\Users\\nicov\\Documents\\Github\\TFT-QuantTrader\\tft_helper.py:123\u001b[0m, in \u001b[0;36mtft_trainer\u001b[1;34m(train, train_dataloader, val_dataloader, max_epochs, model_path, **kwargs)\u001b[0m\n\u001b[0;32m     93\u001b[0m trainer \u001b[38;5;241m=\u001b[39m pl\u001b[38;5;241m.\u001b[39mTrainer(\n\u001b[0;32m     94\u001b[0m     max_epochs\u001b[38;5;241m=\u001b[39mmax_epochs,\n\u001b[0;32m     95\u001b[0m     accelerator\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgpu\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    107\u001b[0m     ],\n\u001b[0;32m    108\u001b[0m )\n\u001b[0;32m    110\u001b[0m tft \u001b[38;5;241m=\u001b[39m TemporalFusionTransformer\u001b[38;5;241m.\u001b[39mfrom_dataset(\n\u001b[0;32m    111\u001b[0m     train,\n\u001b[0;32m    112\u001b[0m     learning_rate\u001b[38;5;241m=\u001b[39mkwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlearning_rate\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m0.15\u001b[39m),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    120\u001b[0m     reduce_on_plateau_patience\u001b[38;5;241m=\u001b[39mkwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreduce_on_plateau_patience\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m4\u001b[39m),\n\u001b[0;32m    121\u001b[0m )\n\u001b[1;32m--> 123\u001b[0m trainer\u001b[38;5;241m.\u001b[39mfit(tft, train_dataloader, val_dataloader)\n\u001b[0;32m    125\u001b[0m \u001b[38;5;66;03m# Guardar el modelo entrenado\u001b[39;00m\n\u001b[0;32m    126\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m model_path:\n",
      "File \u001b[1;32mc:\\Users\\nicov\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\lightning\\pytorch\\trainer\\trainer.py:538\u001b[0m, in \u001b[0;36mTrainer.fit\u001b[1;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[0;32m    536\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m=\u001b[39m TrainerStatus\u001b[38;5;241m.\u001b[39mRUNNING\n\u001b[0;32m    537\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m--> 538\u001b[0m \u001b[43mcall\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_and_handle_interrupt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    539\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit_impl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatamodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\n\u001b[0;32m    540\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\nicov\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\lightning\\pytorch\\trainer\\call.py:47\u001b[0m, in \u001b[0;36m_call_and_handle_interrupt\u001b[1;34m(trainer, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[0;32m     45\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39mlauncher \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     46\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39mlauncher\u001b[38;5;241m.\u001b[39mlaunch(trainer_fn, \u001b[38;5;241m*\u001b[39margs, trainer\u001b[38;5;241m=\u001b[39mtrainer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m---> 47\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m trainer_fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     49\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _TunerExitException:\n\u001b[0;32m     50\u001b[0m     _call_teardown_hook(trainer)\n",
      "File \u001b[1;32mc:\\Users\\nicov\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\lightning\\pytorch\\trainer\\trainer.py:574\u001b[0m, in \u001b[0;36mTrainer._fit_impl\u001b[1;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[0;32m    567\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mfn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    568\u001b[0m ckpt_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_checkpoint_connector\u001b[38;5;241m.\u001b[39m_select_ckpt_path(\n\u001b[0;32m    569\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mfn,\n\u001b[0;32m    570\u001b[0m     ckpt_path,\n\u001b[0;32m    571\u001b[0m     model_provided\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    572\u001b[0m     model_connected\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlightning_module \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    573\u001b[0m )\n\u001b[1;32m--> 574\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mckpt_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    576\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mstopped\n\u001b[0;32m    577\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\nicov\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\lightning\\pytorch\\trainer\\trainer.py:981\u001b[0m, in \u001b[0;36mTrainer._run\u001b[1;34m(self, model, ckpt_path)\u001b[0m\n\u001b[0;32m    976\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_signal_connector\u001b[38;5;241m.\u001b[39mregister_signal_handlers()\n\u001b[0;32m    978\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[0;32m    979\u001b[0m \u001b[38;5;66;03m# RUN THE TRAINER\u001b[39;00m\n\u001b[0;32m    980\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[1;32m--> 981\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_stage\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    983\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[0;32m    984\u001b[0m \u001b[38;5;66;03m# POST-Training CLEAN UP\u001b[39;00m\n\u001b[0;32m    985\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[0;32m    986\u001b[0m log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: trainer tearing down\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\nicov\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\lightning\\pytorch\\trainer\\trainer.py:1025\u001b[0m, in \u001b[0;36mTrainer._run_stage\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1023\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run_sanity_check()\n\u001b[0;32m   1024\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mset_detect_anomaly(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_detect_anomaly):\n\u001b[1;32m-> 1025\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_loop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1026\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1027\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnexpected state \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\nicov\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\lightning\\pytorch\\loops\\fit_loop.py:205\u001b[0m, in \u001b[0;36m_FitLoop.run\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    203\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    204\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_advance_start()\n\u001b[1;32m--> 205\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madvance\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    206\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_advance_end()\n\u001b[0;32m    207\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_restarting \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\nicov\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\lightning\\pytorch\\loops\\fit_loop.py:363\u001b[0m, in \u001b[0;36m_FitLoop.advance\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    361\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mprofile(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_training_epoch\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    362\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data_fetcher \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 363\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mepoch_loop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_data_fetcher\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\nicov\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\lightning\\pytorch\\loops\\training_epoch_loop.py:141\u001b[0m, in \u001b[0;36m_TrainingEpochLoop.run\u001b[1;34m(self, data_fetcher)\u001b[0m\n\u001b[0;32m    139\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    140\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madvance(data_fetcher)\n\u001b[1;32m--> 141\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mon_advance_end\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_fetcher\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    142\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_restarting \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    143\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\nicov\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\lightning\\pytorch\\loops\\training_epoch_loop.py:295\u001b[0m, in \u001b[0;36m_TrainingEpochLoop.on_advance_end\u001b[1;34m(self, data_fetcher)\u001b[0m\n\u001b[0;32m    291\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_should_accumulate():\n\u001b[0;32m    292\u001b[0m     \u001b[38;5;66;03m# clear gradients to not leave any unused memory during validation\u001b[39;00m\n\u001b[0;32m    293\u001b[0m     call\u001b[38;5;241m.\u001b[39m_call_lightning_module_hook(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mon_validation_model_zero_grad\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 295\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mval_loop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    296\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39mtraining \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    297\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39m_logger_connector\u001b[38;5;241m.\u001b[39m_first_loop_iter \u001b[38;5;241m=\u001b[39m first_loop_iter\n",
      "File \u001b[1;32mc:\\Users\\nicov\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\lightning\\pytorch\\loops\\utilities.py:178\u001b[0m, in \u001b[0;36m_no_grad_context.<locals>._decorator\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    176\u001b[0m     context_manager \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mno_grad\n\u001b[0;32m    177\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m context_manager():\n\u001b[1;32m--> 178\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m loop_run(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\nicov\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\lightning\\pytorch\\loops\\evaluation_loop.py:142\u001b[0m, in \u001b[0;36m_EvaluationLoop.run\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    140\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_restarting \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    141\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_store_dataloader_outputs()\n\u001b[1;32m--> 142\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mon_run_end\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\nicov\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\lightning\\pytorch\\loops\\evaluation_loop.py:254\u001b[0m, in \u001b[0;36m_EvaluationLoop.on_run_end\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    251\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39m_logger_connector\u001b[38;5;241m.\u001b[39m_evaluation_epoch_end()\n\u001b[0;32m    253\u001b[0m \u001b[38;5;66;03m# hook\u001b[39;00m\n\u001b[1;32m--> 254\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_on_evaluation_epoch_end\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    256\u001b[0m logged_outputs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_logged_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_logged_outputs, []  \u001b[38;5;66;03m# free memory\u001b[39;00m\n\u001b[0;32m    257\u001b[0m \u001b[38;5;66;03m# include any logged outputs on epoch_end\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\nicov\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\lightning\\pytorch\\loops\\evaluation_loop.py:334\u001b[0m, in \u001b[0;36m_EvaluationLoop._on_evaluation_epoch_end\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    332\u001b[0m hook_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mon_test_epoch_end\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mtesting \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mon_validation_epoch_end\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    333\u001b[0m call\u001b[38;5;241m.\u001b[39m_call_callback_hooks(trainer, hook_name)\n\u001b[1;32m--> 334\u001b[0m \u001b[43mcall\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_lightning_module_hook\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrainer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhook_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    336\u001b[0m trainer\u001b[38;5;241m.\u001b[39m_logger_connector\u001b[38;5;241m.\u001b[39mon_epoch_end()\n",
      "File \u001b[1;32mc:\\Users\\nicov\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\lightning\\pytorch\\trainer\\call.py:167\u001b[0m, in \u001b[0;36m_call_lightning_module_hook\u001b[1;34m(trainer, hook_name, pl_module, *args, **kwargs)\u001b[0m\n\u001b[0;32m    164\u001b[0m pl_module\u001b[38;5;241m.\u001b[39m_current_fx_name \u001b[38;5;241m=\u001b[39m hook_name\n\u001b[0;32m    166\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mprofile(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[LightningModule]\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpl_module\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhook_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m--> 167\u001b[0m     output \u001b[38;5;241m=\u001b[39m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    169\u001b[0m \u001b[38;5;66;03m# restore current_fx when nested context\u001b[39;00m\n\u001b[0;32m    170\u001b[0m pl_module\u001b[38;5;241m.\u001b[39m_current_fx_name \u001b[38;5;241m=\u001b[39m prev_fx_name\n",
      "File \u001b[1;32mc:\\Users\\nicov\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pytorch_forecasting\\models\\base_model.py:636\u001b[0m, in \u001b[0;36mBaseModel.on_validation_epoch_end\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    635\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mon_validation_epoch_end\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m--> 636\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mon_epoch_end\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalidation_step_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    637\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalidation_step_outputs\u001b[38;5;241m.\u001b[39mclear()\n",
      "File \u001b[1;32mc:\\Users\\nicov\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pytorch_forecasting\\models\\temporal_fusion_transformer\\__init__.py:539\u001b[0m, in \u001b[0;36mTemporalFusionTransformer.on_epoch_end\u001b[1;34m(self, outputs)\u001b[0m\n\u001b[0;32m    535\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    536\u001b[0m \u001b[38;5;124;03mrun at epoch end for training or validation\u001b[39;00m\n\u001b[0;32m    537\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlog_interval \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining:\n\u001b[1;32m--> 539\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlog_interpretation\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\nicov\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pytorch_forecasting\\models\\temporal_fusion_transformer\\__init__.py:820\u001b[0m, in \u001b[0;36mTemporalFusionTransformer.log_interpretation\u001b[1;34m(self, outputs)\u001b[0m\n\u001b[0;32m    818\u001b[0m \u001b[38;5;66;03m# log to tensorboard\u001b[39;00m\n\u001b[0;32m    819\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name, fig \u001b[38;5;129;01min\u001b[39;00m figs\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m--> 820\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlogger\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexperiment\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_figure\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    821\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mlabel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcapitalize\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m \u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mname\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m importance\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mglobal_step\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mglobal_step\u001b[49m\n\u001b[0;32m    822\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    824\u001b[0m \u001b[38;5;66;03m# log lengths of encoder/decoder\u001b[39;00m\n\u001b[0;32m    825\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m \u001b[38;5;28mtype\u001b[39m \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoder\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdecoder\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n",
      "File \u001b[1;32mc:\\Users\\nicov\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\utils\\tensorboard\\writer.py:753\u001b[0m, in \u001b[0;36mSummaryWriter.add_figure\u001b[1;34m(self, tag, figure, global_step, close, walltime)\u001b[0m\n\u001b[0;32m    745\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madd_image(\n\u001b[0;32m    746\u001b[0m         tag,\n\u001b[0;32m    747\u001b[0m         figure_to_image(figure, close),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    750\u001b[0m         dataformats\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNCHW\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    751\u001b[0m     )\n\u001b[0;32m    752\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 753\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_image\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    754\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtag\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    755\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfigure_to_image\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfigure\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclose\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    756\u001b[0m \u001b[43m        \u001b[49m\u001b[43mglobal_step\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    757\u001b[0m \u001b[43m        \u001b[49m\u001b[43mwalltime\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    758\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdataformats\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mCHW\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    759\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\nicov\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\utils\\tensorboard\\writer.py:625\u001b[0m, in \u001b[0;36mSummaryWriter.add_image\u001b[1;34m(self, tag, img_tensor, global_step, walltime, dataformats)\u001b[0m\n\u001b[0;32m    580\u001b[0m \u001b[38;5;124;03m\"\"\"Add image data to summary.\u001b[39;00m\n\u001b[0;32m    581\u001b[0m \n\u001b[0;32m    582\u001b[0m \u001b[38;5;124;03mNote that this requires the ``pillow`` package.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    621\u001b[0m \n\u001b[0;32m    622\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    623\u001b[0m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_log_api_usage_once(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtensorboard.logging.add_image\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    624\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_file_writer()\u001b[38;5;241m.\u001b[39madd_summary(\n\u001b[1;32m--> 625\u001b[0m     \u001b[43mimage\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtag\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimg_tensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataformats\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdataformats\u001b[49m\u001b[43m)\u001b[49m, global_step, walltime\n\u001b[0;32m    626\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\nicov\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\utils\\tensorboard\\summary.py:576\u001b[0m, in \u001b[0;36mimage\u001b[1;34m(tag, tensor, rescale, dataformats)\u001b[0m\n\u001b[0;32m    574\u001b[0m scale_factor \u001b[38;5;241m=\u001b[39m _calc_scale_factor(tensor)\n\u001b[0;32m    575\u001b[0m tensor \u001b[38;5;241m=\u001b[39m tensor\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39mfloat32)\n\u001b[1;32m--> 576\u001b[0m tensor \u001b[38;5;241m=\u001b[39m \u001b[43m(\u001b[49m\u001b[43mtensor\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mscale_factor\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclip\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m255\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39muint8)\n\u001b[0;32m    577\u001b[0m image \u001b[38;5;241m=\u001b[39m make_image(tensor, rescale\u001b[38;5;241m=\u001b[39mrescale)\n\u001b[0;32m    578\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m Summary(value\u001b[38;5;241m=\u001b[39m[Summary\u001b[38;5;241m.\u001b[39mValue(tag\u001b[38;5;241m=\u001b[39mtag, image\u001b[38;5;241m=\u001b[39mimage)])\n",
      "File \u001b[1;32mc:\\Users\\nicov\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\numpy\\core\\_methods.py:161\u001b[0m, in \u001b[0;36m_clip\u001b[1;34m(a, min, max, out, casting, **kwargs)\u001b[0m\n\u001b[0;32m    158\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _clip_dep_invoke_with_casting(\n\u001b[0;32m    159\u001b[0m         um\u001b[38;5;241m.\u001b[39mmaximum, a, \u001b[38;5;28mmin\u001b[39m, out\u001b[38;5;241m=\u001b[39mout, casting\u001b[38;5;241m=\u001b[39mcasting, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    160\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 161\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _clip_dep_invoke_with_casting(\n\u001b[0;32m    162\u001b[0m         um\u001b[38;5;241m.\u001b[39mclip, a, \u001b[38;5;28mmin\u001b[39m, \u001b[38;5;28mmax\u001b[39m, out\u001b[38;5;241m=\u001b[39mout, casting\u001b[38;5;241m=\u001b[39mcasting, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\nicov\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\numpy\\core\\_methods.py:115\u001b[0m, in \u001b[0;36m_clip_dep_invoke_with_casting\u001b[1;34m(ufunc, out, casting, *args, **kwargs)\u001b[0m\n\u001b[0;32m    113\u001b[0m \u001b[38;5;66;03m# try to deal with broken casting rules\u001b[39;00m\n\u001b[0;32m    114\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 115\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ufunc(\u001b[38;5;241m*\u001b[39margs, out\u001b[38;5;241m=\u001b[39mout, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    116\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _exceptions\u001b[38;5;241m.\u001b[39m_UFuncOutputCastingError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    117\u001b[0m     \u001b[38;5;66;03m# Numpy 1.17.0, 2019-02-24\u001b[39;00m\n\u001b[0;32m    118\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    119\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConverting the output of clip from \u001b[39m\u001b[38;5;132;01m{!r}\u001b[39;00m\u001b[38;5;124m to \u001b[39m\u001b[38;5;132;01m{!r}\u001b[39;00m\u001b[38;5;124m is deprecated. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    120\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPass `casting=\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124munsafe\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124m` explicitly to silence this warning, or \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    123\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m\n\u001b[0;32m    124\u001b[0m     )\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 8.62 MiB for an array with shape (1494, 504, 3) and data type float32"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 504x684 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "if grid_search == \"random\":\n",
    "    # Suprime todos los warnings\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "    # Llamada a la función de búsqueda aleatoria\n",
    "    best_model, best_params, best_val_loss = random_hyperparameter_search(\n",
    "        data,\n",
    "        train,\n",
    "        train_dataloader,\n",
    "        val_dataloader,\n",
    "        test,\n",
    "        param_grid,\n",
    "        n_iterations=100,\n",
    "        max_epochs=50,\n",
    "        save_dir=f'./plots/multiexog_syp500_-{n_prev_len}d-{date_start.replace(\"-\",\"\")}-{date_end.replace(\"-\",\"\")}-lessFilters',\n",
    "        csv_file=f\"./results/multiexog_syp500_-{n_prev_len}d-{date_start}-{date_end}.csv\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "40e9473e",
   "metadata": {},
   "outputs": [],
   "source": [
    "if grid_search == \"exhaustive\":\n",
    "    \n",
    "    # Suprime todos los warnings \n",
    "\n",
    "    \n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "    \n",
    "    # Llamada a la función de búsqueda de hiperparámetros\n",
    "    best_model, best_params, best_val_loss = exhaustive_hyperparameter_search(\n",
    "        data, train, train_dataloader, val_dataloader, test, param_grid, max_epochs=1\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bebd5b9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if grid_search:\n",
    "    tft_predict(best_model, val_dataloader, n_preds=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f03dd31",
   "metadata": {},
   "source": [
    "# TEST EVAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3272e531",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_preds(\n",
    "    train,\n",
    "    test,\n",
    "    model,\n",
    "    encoder_lenght,\n",
    "    test_lenght,\n",
    "    pred_lenght,\n",
    "    quantiles: bool = True,\n",
    "):\n",
    "    # group = model.output_transformer.groups[0]\n",
    "    if quantiles:\n",
    "        try:  # for Quantileloss\n",
    "            preds = []\n",
    "            preds_data = pd.concat([train[-encoder_lenght:], test])\n",
    "            for i in range(0, test_lenght, pred_lenght):\n",
    "                new_data = preds_data[i : i + encoder_lenght + pred_lenght]\n",
    "                new_data.loc[:, group] = new_data.iloc[0, new_data.columns.get_loc(group)]\n",
    "                new_raw_predictions = model.predict(new_data, mode=\"raw\", return_x=True)\n",
    "                prediction = []\n",
    "                for i in range(pred_lenght):\n",
    "                    prediction.append(float(new_raw_predictions.output.prediction[0][i][3]))\n",
    "                preds.append(prediction)\n",
    "        except:  # for MQF2DistributionLoss\n",
    "            preds = []\n",
    "            preds_data = pd.concat([train[-encoder_lenght:], test])\n",
    "            for i in range(0, test_lenght, pred_lenght):\n",
    "                new_data = preds_data[i : i + encoder_lenght + pred_lenght]\n",
    "                new_data.loc[:, group] = new_data.iloc[0, new_data.columns.get_loc(group)]\n",
    "                prediction = model.to_prediction(new_raw_predictions.output)[0].flatten().tolist()\n",
    "                preds.append(prediction)\n",
    "    else:\n",
    "        preds = []\n",
    "        preds_data = pd.concat([train[-encoder_lenght:], test])\n",
    "        for i in range(0, test_lenght, pred_lenght):\n",
    "            new_data = preds_data[i : i + encoder_lenght + pred_lenght]\n",
    "            new_data.loc[:, group] = new_data.iloc[0, new_data.columns.get_loc(group)]\n",
    "            new_raw_predictions = model.predict(new_data, mode=\"raw\", return_x=True)\n",
    "            prediction = new_raw_predictions.output.prediction[0].flatten().tolist()\n",
    "            preds.append(prediction)\n",
    "\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1ed3276c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preds = []\n",
    "# preds_data = pd.concat([data[-n_prev_len:], test])\n",
    "# # preds_data = preds_data.ffill()\n",
    "# preds_data[\"target\"] = float(1)\n",
    "# # preds_data.drop(columns=[\"target\"], inplace=True)\n",
    "# for i in range(0, test_len, pred_len):\n",
    "#     new_data = preds_data[i : i + n_prev_len + pred_len]\n",
    "#     new_data.loc[:, group] = new_data.iloc[0, new_data.columns.get_loc(group)]\n",
    "#     new_raw_predictions = tft.predict(new_data, mode=\"raw\", return_x=True)\n",
    "#     prediction = new_raw_predictions.output.prediction[0].flatten().tolist()\n",
    "#     preds.append(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a408112",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = make_preds(\n",
    "    train=data,\n",
    "    test=test,\n",
    "    model=tft,\n",
    "    encoder_lenght=n_prev_len,\n",
    "    test_lenght=test_len,\n",
    "    pred_lenght=pred_len,\n",
    "    quantiles=True if isinstance(loss, QuantileLoss) else False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9847a87",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mThe kernel died. Error: ... View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_absolute_percentage_error, root_mean_squared_error\n",
    "\n",
    "dates = test[\"Date\"].to_list()\n",
    "preds_flat = [item for sublist in preds for item in sublist]\n",
    "\n",
    "# real_vals = list(data[-n_preds * pred_len :][\"target\"])\n",
    "real_vals = test[\"target\"].to_list()\n",
    "\n",
    "print(f\"MAE: {mean_absolute_error(real_vals, preds_flat)}\")\n",
    "print(f\"MAPE: {mean_absolute_percentage_error(real_vals, preds_flat)}\")\n",
    "print(f\"RMSE: {root_mean_squared_error(real_vals, preds_flat)}\")\n",
    "\n",
    "plt.plot(dates, preds_flat, color=\"r\")\n",
    "plt.plot(dates, real_vals, color=\"g\")\n",
    "plt.title(\"Real vs Preds\")\n",
    "plt.xlabel(\"Índice\")\n",
    "plt.ylabel(\"Valor\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96b460c4",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mThe kernel died. Error: ... View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_absolute_error, mean_absolute_percentage_error, mean_squared_error\n",
    "import matplotlib.dates as mdates\n",
    "\n",
    "# Convertir las fechas a formato de datetime si no están ya\n",
    "dates = pd.to_datetime(test[\"Date\"]).to_list()\n",
    "\n",
    "# Aplanar las predicciones si es necesario\n",
    "preds_flat = [item for sublist in preds for item in sublist]\n",
    "\n",
    "# Valores reales\n",
    "real_vals = test[\"target\"].to_list()\n",
    "\n",
    "# Métricas de error\n",
    "print(f\"MAE: {mean_absolute_error(real_vals, preds_flat)}\")\n",
    "print(f\"MAPE: {mean_absolute_percentage_error(real_vals, preds_flat)}\")\n",
    "print(f\"RMSE: {mean_squared_error(real_vals, preds_flat, squared=False)}\")\n",
    "\n",
    "# Gráfico\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(dates, real_vals, color=\"g\", label=\"Valores Reales\")\n",
    "plt.plot(dates, preds_flat, color=\"r\", label=\"Predicciones\")\n",
    "plt.title(\"Valores Reales vs Predicciones\")\n",
    "plt.xlabel(\"Fecha\")\n",
    "plt.ylabel(\"Valor (€)\")\n",
    "\n",
    "# Formato de fecha en el eje x\n",
    "plt.gca().xaxis.set_major_formatter(mdates.DateFormatter(\"%Y-%m-%d\"))\n",
    "plt.gca().xaxis.set_major_locator(mdates.AutoDateLocator())\n",
    "plt.gcf().autofmt_xdate()  # Rotar fechas para mejor visualización\n",
    "\n",
    "# Añadir leyenda\n",
    "plt.legend()\n",
    "\n",
    "# Mostrar gráfico\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f373476",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mThe kernel died. Error: ... View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "\n",
    "# Supongamos que `preds`, `test`, y `dates` ya están definidos en tu entorno\n",
    "\n",
    "# Aplanar la lista de predicciones\n",
    "preds_flat = [item for sublist in preds for item in sublist]\n",
    "\n",
    "# Convertir los valores reales a una lista\n",
    "real_vals = test[\"target\"].to_list()\n",
    "\n",
    "# Lista de fechas (timestamps)\n",
    "\n",
    "\n",
    "# Calcular el error absoluto medio\n",
    "print(f\"MAE: {mean_absolute_error(real_vals, preds_flat)}\")\n",
    "print(f\"MAPE: {mean_absolute_percentage_error(real_vals, preds_flat)}\")\n",
    "print(f\"RMSE: {root_mean_squared_error(real_vals, preds_flat)}\")\n",
    "# Crear la gráfica\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(dates, preds_flat, color=\"r\", label=\"Predicciones\", marker=\"o\", linestyle=\"--\")\n",
    "plt.plot(dates, real_vals, color=\"g\", label=\"Valores Reales\", marker=\"x\", linestyle=\"-\")\n",
    "\n",
    "# Añadir título y etiquetas\n",
    "plt.title(\"Predicciones vs Valores Reales\")\n",
    "plt.xlabel(\"Fecha\")\n",
    "plt.ylabel(\"Valor\")\n",
    "\n",
    "# Formatear las fechas en el eje x\n",
    "plt.gca().xaxis.set_major_formatter(mdates.DateFormatter(\"%Y-%m-%d\"))\n",
    "# plt.gca().xaxis.set_major_locator(mdates.HourLocator(interval=6))\n",
    "plt.gcf().autofmt_xdate()  # Rotar las etiquetas de fecha\n",
    "\n",
    "# Añadir cuadrícula y leyenda\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "\n",
    "# Mostrar la gráfica\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "081d3ac6",
   "metadata": {},
   "source": [
    "# INFERENCE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "584a21f5",
   "metadata": {},
   "source": [
    "## Retrain for inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d680c22",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mThe kernel died. Error: ... View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "features = [\n",
    "    col for col in data.columns if col != \"target\"\n",
    "]  # Columnas de características and col != \"Date\"\n",
    "\n",
    "max_prediction_length = pred_len\n",
    "max_encoder_length = n_prev_len  # 48\n",
    "# training_cutoff = data[\"Date\"].max() - pd.Timedelta(hours=max_encoder_length)\n",
    "training_cutoff = data[\"time_idx\"].max() - max_prediction_length\n",
    "\n",
    "retrain = TimeSeriesDataSet(\n",
    "    full.dropna()[lambda x: x.time_idx <= training_cutoff],\n",
    "    time_idx=\"time_idx\",\n",
    "    target=\"target\",\n",
    "    group_ids=[group],\n",
    "    min_encoder_length=max_encoder_length,  # keep encoder length long (as it is in the validation set)\n",
    "    max_encoder_length=max_encoder_length,\n",
    "    # min_prediction_length=24,\n",
    "    max_prediction_length=max_prediction_length,\n",
    "    static_categoricals=[],\n",
    "    static_reals=[],\n",
    "    time_varying_known_categoricals=[],  # group of categorical variables can be treated as one variable\n",
    "    time_varying_known_reals=[\"Date\", \"month\", \"week\", \"day\", \"time_idx\"],\n",
    "    time_varying_unknown_categoricals=[],\n",
    "    time_varying_unknown_reals=[\n",
    "        \"target\",\n",
    "        \"open\",\n",
    "        \"max\",\n",
    "        \"min\",\n",
    "        \"vol\",\n",
    "        \"var\",\n",
    "        \"SMA_5\",\n",
    "        \"EMA_5\",\n",
    "        \"SMA_10\",\n",
    "        \"EMA_10\",\n",
    "        \"SMA_15\",\n",
    "        \"EMA_15\",\n",
    "        \"SMA_20\",\n",
    "        \"EMA_20\",\n",
    "        \"RSI_6\",\n",
    "        \"RSI_10\",\n",
    "        \"RSI_14\",\n",
    "        \"Bollinger_Upper_5\",\n",
    "        \"Bollinger_Lower_5\",\n",
    "        \"Bollinger_Upper_10\",\n",
    "        \"Bollinger_Lower_10\",\n",
    "        \"Bollinger_Upper_15\",\n",
    "        \"Bollinger_Lower_15\",\n",
    "        \"Bollinger_Upper_20\",\n",
    "        \"Bollinger_Lower_20\",\n",
    "        \"MACD\",\n",
    "        \"Signal_Line\",\n",
    "        \"ATR_5\",\n",
    "        \"ATR_10\",\n",
    "        \"ATR_15\",\n",
    "        \"ATR_20\",\n",
    "        \"CCI_5\",\n",
    "        \"CCI_10\",\n",
    "        \"CCI_15\",\n",
    "        \"CCI_20\",\n",
    "        \"ROC_10\",\n",
    "        \"ROC_14\",\n",
    "        \"ROC_20\",\n",
    "        \"ROC_50\",\n",
    "        \"Stochastic_10_K\",\n",
    "        \"Stochastic_10_D\",\n",
    "        \"Stochastic_14_K\",\n",
    "        \"Stochastic_14_D\",\n",
    "        \"Stochastic_20_K\",\n",
    "        \"Stochastic_20_D\",\n",
    "        \"Stochastic_25_K\",\n",
    "        \"Stochastic_25_D\",\n",
    "        \"Stochastic_50_K\",\n",
    "        \"Stochastic_50_D\",\n",
    "        \"Williams_%R_10\",\n",
    "        \"Williams_%R_14\",\n",
    "    ],\n",
    "    # lags={\"target\": list(range(1, 5))},\n",
    "    # target_normalizer=GroupNormalizer(\"standard\", groups=[group], transformation=\"softplus\"),\n",
    "    # use softplus and normalize by group\n",
    "    add_relative_time_idx=True,\n",
    "    add_target_scales=True,\n",
    "    allow_missing_timesteps=True,\n",
    "    # add_encoder_length=True,\n",
    "    # categorical_encoders={\n",
    "    #     \"month\": pytorch_forecasting.data.encoders.NaNLabelEncoder(add_nan=True),\n",
    "    #     \"week\": pytorch_forecasting.data.encoders.NaNLabelEncoder(add_nan=True),\n",
    "    #     \"day\": pytorch_forecasting.data.encoders.NaNLabelEncoder(add_nan=True),\n",
    "    # },\n",
    ")\n",
    "\n",
    "revalidation = TimeSeriesDataSet.from_dataset(retrain, full.dropna(), predict=True, stop_randomization=True)\n",
    "\n",
    "# test = TimeSeriesDataSet.from_dataset(training, test_data, predict=True, stop_randomization=True)\n",
    "\n",
    "\n",
    "# create dataloaders for model\n",
    "\n",
    "batch_size = 64  # set this between 32 to 128\n",
    "\n",
    "retrain_dataloader = retrain.to_dataloader(\n",
    "\n",
    "    train=True, batch_size=batch_size, num_workers=7, persistent_workers=True\n",
    "\n",
    ")\n",
    "\n",
    "reval_dataloader = revalidation.to_dataloader(\n",
    "\n",
    "    train=False, batch_size=batch_size, num_workers=7, persistent_workers=True\n",
    "\n",
    ")\n",
    "\n",
    "# test_dataloader = test.to_dataloader(train=False, batch_size=batch_size, num_workers=11, persistent_workers=True)\n",
    "\n",
    "if not grid_search:\n",
    "\n",
    "    # tft_params[\"learning_rate\"] = 0.01\n",
    "\n",
    "    retft, val_loss = tft_trainer(\n",
    "\n",
    "        retrain, retrain_dataloader, reval_dataloader, max_epochs=epochs, **tft_params\n",
    "\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16c3c38f",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mThe kernel died. Error: ... View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "encoder_data = full[-n_prev_len:]\n",
    "last_row = full.iloc[-1]\n",
    "# Creamos nuevas filas\n",
    "new_rows = []\n",
    "for i in range(1, 6):\n",
    "    new_row = last_row.copy()\n",
    "    new_row[\"Date\"] += timedelta(days=i)\n",
    "    new_row[\"day\"] += i\n",
    "    new_row[\"time_idx\"] += i\n",
    "    new_rows.append(new_row)\n",
    "\n",
    "# Concatenamos las nuevas filas al DataFrame original\n",
    "decoder_data = pd.DataFrame(new_rows)\n",
    "\n",
    "new_data = pd.concat([encoder_data, decoder_data], ignore_index=True)\n",
    "new_data.loc[:, group] = new_data.iloc[0, new_data.columns.get_loc(group)]\n",
    "# new_data.loc[-pred_len: ,\"target\"] = 1\n",
    "new_raw_predictions = retft.predict(new_data, mode=\"raw\", return_x=True)\n",
    "if isinstance(loss, QuantileLoss):\n",
    "    prediction = []\n",
    "    for i in range(pred_len):\n",
    "        prediction.append(float(new_raw_predictions.output.prediction[0][i][3]))\n",
    "else:\n",
    "    prediction = new_raw_predictions.output.prediction[0].flatten().tolist()\n",
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "162b0a6e",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mThe kernel died. Error: ... View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# prediction = [11233.22265625, 11129.837890625, 11228.3486328125, 11315.59375, 11555.85546875]\n",
    "last_vals = full[-10:]\n",
    "last_vals = last_vals[[\"Date\", \"target\"]]\n",
    "fechas_azul = pd.date_range(start=\"2024-08-26\", periods=len(prediction))\n",
    "predictions = pd.DataFrame({\"Date\": fechas_azul, \"target\": prediction})\n",
    "\n",
    "plt.plot(predictions[\"Date\"], predictions[\"target\"], color=\"r\")\n",
    "plt.plot(last_vals[\"Date\"], last_vals[\"target\"], color=\"g\")\n",
    "plt.title(\"Gráfica de la lista aplanada\")\n",
    "plt.xlabel(\"Índice\")\n",
    "plt.ylabel(\"Valor\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88078c66",
   "metadata": {},
   "source": [
    "# INTERPRETABILITY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2461fd42",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mThe kernel died. Error: ... View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "interpretation = tft.interpret_output(preds.output, reduction=\"sum\") #\n",
    "tft.plot_interpretation(interpretation)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2735f9d0",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mThe kernel died. Error: ... View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
